{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1013747d",
   "metadata": {},
   "source": [
    "# Experiment Analysis Framework\n",
    "\n",
    "This notebook aggregates prior training artifacts from **neural-network-lab-python**, surfaces diagnostic visualizations, and recommends data-driven hyperparameter refinements for future experiments. It is designed to be reusable across training runs with minimal manual setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420c0e6",
   "metadata": {},
   "source": [
    "## Workflow Overview\n",
    "\n",
    "1. Validate the presence of required configs, logs, scalers, and weight checkpoints.\n",
    "2. Load active and historical configuration payloads and align them with training outcomes.\n",
    "3. Ingest `loss_history.csv`, `training_results.csv`, and particle simulation data for analytics.\n",
    "4. Reconstruct the latest model checkpoint, generate predictions, and evaluate residuals.\n",
    "5. Render visual diagnostics (loss curves, learning-rate sweeps, residual histograms, correlation heatmap).\n",
    "6. Summarize run health, recommend hyperparameter sweeps, and capture actionable next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from advanced_neural_network import AdvancedNeuralNetwork\n",
    "from data_processing import complete_data_pipeline, load_and_validate_data\n",
    "from ml_utils import compute_loss_weights\n",
    "from weight_constraints import BinaryWeightConstraintChanges, BinaryWeightConstraintMax, OscillationDampener\n",
    "\n",
    "pd.options.display.max_rows = 60\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c198bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"neural-network-lab-python\"\n",
    "\n",
    "INPUT_FEATURES = [\n",
    "    \"mass\",\n",
    "    \"initial_velocity_x\",\n",
    "    \"initial_velocity_y\",\n",
    "    \"initial_position_x\",\n",
    "    \"initial_position_y\",\n",
    "    \"charge\",\n",
    "    \"magnetic_field_strength\",\n",
    "    \"simulation_time\"\n",
    "]\n",
    "\n",
    "OUTPUT_TARGETS = [\n",
    "    \"final_velocity_x\",\n",
    "    \"final_velocity_y\",\n",
    "    \"final_position_x\",\n",
    "    \"final_position_y\",\n",
    "    \"kinetic_energy\",\n",
    "    \"trajectory_length\"\n",
    "]\n",
    "\n",
    "ANALYSIS_SEED = 42\n",
    "\n",
    "np.random.seed(ANALYSIS_SEED)\n",
    "tf.random.set_seed(ANALYSIS_SEED)\n",
    "\n",
    "\n",
    "def format_bytes(size: Optional[int]) -> Optional[str]:\n",
    "    \"\"\"Format raw byte counts into human readable text.\"\"\"\n",
    "    if size is None: return None\n",
    "\n",
    "    threshold = 1024.0\n",
    "\n",
    "    units = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\")\n",
    "\n",
    "    value = float(size)\n",
    "\n",
    "    for unit in units:\n",
    "        if value < threshold or unit == units[-1]: return f\"{value:.1f} {unit}\"\n",
    "\n",
    "        value /= threshold\n",
    "\n",
    "\n",
    "def resolve_project_paths() -> Dict[str, Path]:\n",
    "    \"\"\"Resolve key project directories relative to this notebook.\"\"\"\n",
    "    root = Path.cwd()\n",
    "\n",
    "    if root.name != PROJECT_NAME:\n",
    "        for parent in root.parents:\n",
    "            if parent.name == PROJECT_NAME: root = parent\n",
    "\n",
    "    config_dir = root / \"ml_config\"\n",
    "\n",
    "    output_dir = root / \"training_output\"\n",
    "\n",
    "    analysis_dir = output_dir / \"analysis\"\n",
    "\n",
    "    figures_dir = analysis_dir / \"figures\"\n",
    "\n",
    "    analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return {\n",
    "        \"project_root\": root,\n",
    "        \"config_dir\": config_dir,\n",
    "        \"output_dir\": output_dir,\n",
    "        \"analysis_dir\": analysis_dir,\n",
    "        \"figures_dir\": figures_dir,\n",
    "        \"data_path\": root / \"particle_data.csv\",\n",
    "        \"scaler_X\": root / \"scaler_X.pkl\",\n",
    "        \"scaler_y\": root / \"scaler_y.pkl\"\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_required_artifacts(paths: Dict[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Check presence and metadata of required artifacts.\"\"\"\n",
    "    required = {\n",
    "        \"model_config\": paths[\"config_dir\"] / \"model_config.json\",\n",
    "        \"training_config\": paths[\"config_dir\"] / \"training_config.json\",\n",
    "        \"loss_history\": paths[\"output_dir\"] / \"loss_history.csv\",\n",
    "        \"training_results\": paths[\"output_dir\"] / \"training_results.csv\",\n",
    "        \"configuration_log\": paths[\"output_dir\"] / \"configuration_log.csv\",\n",
    "        \"particle_data\": paths[\"data_path\"],\n",
    "        \"scaler_X\": paths[\"scaler_X\"],\n",
    "        \"scaler_y\": paths[\"scaler_y\"]\n",
    "    }\n",
    "\n",
    "    optional = {\n",
    "        \"analysis_dir\": paths[\"analysis_dir\"],\n",
    "        \"figures_dir\": paths[\"figures_dir\"]\n",
    "    }\n",
    "\n",
    "    notes = {\n",
    "        \"particle_data\": \"Regenerate via data pipeline if missing.\",\n",
    "        \"scaler_X\": \"Rebuilt automatically through complete_data_pipeline.\",\n",
    "        \"scaler_y\": \"Rebuilt automatically through complete_data_pipeline.\"\n",
    "    }\n",
    "\n",
    "    records: List[Dict[str, Any]] = []\n",
    "\n",
    "    def append_record(label: str, path: Path, critical: bool) -> None:\n",
    "        exists = path.exists()\n",
    "\n",
    "        size = path.stat().st_size if exists and path.is_file() else None\n",
    "\n",
    "        modified = pd.Timestamp(path.stat().st_mtime, unit=\"s\") if exists else None\n",
    "\n",
    "        records.append({\n",
    "            \"artifact\": label,\n",
    "            \"critical\": critical,\n",
    "            \"exists\": exists,\n",
    "            \"path\": str(path.relative_to(paths[\"project_root\"])) if exists else str(path),\n",
    "            \"size_bytes\": size,\n",
    "            \"size_readable\": format_bytes(size),\n",
    "            \"modified\": modified,\n",
    "            \"note\": notes.get(label)\n",
    "        })\n",
    "\n",
    "    for label, path in required.items():\n",
    "        append_record(label, path, True)\n",
    "\n",
    "    for label, path in optional.items():\n",
    "        append_record(label, path, False)\n",
    "\n",
    "    status_df = pd.DataFrame(records)\n",
    "\n",
    "    if status_df.empty: return status_df\n",
    "\n",
    "    status_df = status_df.sort_values([\"critical\", \"artifact\"], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    return status_df\n",
    "\n",
    "\n",
    "def list_checkpoint_weights(paths: Dict[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"List available weight checkpoints with epoch metadata.\"\"\"\n",
    "    pattern = \"model_weights_epoch_*.weights.h5\"\n",
    "\n",
    "    checkpoint_files = sorted(paths[\"project_root\"].glob(pattern))\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for file_path in checkpoint_files:\n",
    "        name = file_path.name\n",
    "\n",
    "        parts = name.split(\"_\")\n",
    "\n",
    "        epoch_token = parts[3] if len(parts) > 3 else parts[-1]\n",
    "\n",
    "        epoch = int(epoch_token.replace(\".weights.h5\", \"\")) if epoch_token else None\n",
    "\n",
    "        rows.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"name\": name,\n",
    "            \"path\": str(file_path.relative_to(paths[\"project_root\"])) if file_path.exists() else str(file_path),\n",
    "            \"modified\": pd.Timestamp(file_path.stat().st_mtime, unit=\"s\"),\n",
    "            \"size_bytes\": file_path.stat().st_size\n",
    "        })\n",
    "\n",
    "    checkpoint_df = pd.DataFrame(rows)\n",
    "\n",
    "    if checkpoint_df.empty: return checkpoint_df\n",
    "\n",
    "    checkpoint_df = checkpoint_df.sort_values(\"epoch\").reset_index(drop=True)\n",
    "\n",
    "    latest_epoch = checkpoint_df[\"epoch\"].max()\n",
    "\n",
    "    checkpoint_df[\"size_readable\"] = checkpoint_df[\"size_bytes\"].apply(format_bytes)\n",
    "\n",
    "    checkpoint_df[\"is_latest\"] = checkpoint_df[\"epoch\"] == latest_epoch\n",
    "\n",
    "    return checkpoint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130eb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configs(paths: Dict[str, Path]) -> Tuple[Dict[str, Any], Dict[str, Any], pd.DataFrame]:\n",
    "    \"\"\"Load active configs and historical configuration snapshots with derived metrics.\"\"\"\n",
    "    model_config_path = paths[\"config_dir\"] / \"model_config.json\"\n",
    "\n",
    "    training_config_path = paths[\"config_dir\"] / \"training_config.json\"\n",
    "\n",
    "    with model_config_path.open() as handle:\n",
    "        model_config = json.load(handle)\n",
    "\n",
    "    with training_config_path.open() as handle:\n",
    "        training_config = json.load(handle)\n",
    "\n",
    "    snapshots: List[Dict[str, Any]] = []\n",
    "\n",
    "    for config_path in sorted(paths[\"output_dir\"].glob(\"training_config_*.json\")):\n",
    "        with config_path.open() as handle:\n",
    "            payload = json.load(handle)\n",
    "\n",
    "        combined: Dict[str, Any] = {\n",
    "            \"config_id\": payload.get(\"config_id\"),\n",
    "            \"timestamp\": payload.get(\"timestamp\")\n",
    "        }\n",
    "\n",
    "        model_payload = payload.get(\"model_config\", {})\n",
    "\n",
    "        for key, value in model_payload.items():\n",
    "            combined[key] = value\n",
    "\n",
    "        training_payload = payload.get(\"training_config\", {})\n",
    "\n",
    "        for key, value in training_payload.items():\n",
    "            combined[f\"train_{key}\"] = value\n",
    "\n",
    "        summary_payload = payload.get(\"performance_summary\", {})\n",
    "\n",
    "        combined[\"best_r2\"] = summary_payload.get(\"best_r2\")\n",
    "        combined[\"final_r2\"] = summary_payload.get(\"current_r2\")\n",
    "        combined[\"best_epoch\"] = summary_payload.get(\"best_r2_epoch\")\n",
    "        combined[\"avg_epoch_time_logged\"] = summary_payload.get(\"avg_epoch_time\")\n",
    "        combined[\"total_training_time\"] = summary_payload.get(\"total_training_time\")\n",
    "        combined[\"weight_modifications_used\"] = summary_payload.get(\"weight_modifications_used\")\n",
    "        combined[\"peak_memory_mb\"] = summary_payload.get(\"peak_memory_mb\")\n",
    "\n",
    "        snapshots.append(combined)\n",
    "\n",
    "    snapshots_df = pd.DataFrame(snapshots)\n",
    "\n",
    "    if snapshots_df.empty: return model_config, training_config, snapshots_df\n",
    "\n",
    "    snapshots_df[\"timestamp\"] = pd.to_datetime(snapshots_df[\"timestamp\"])\n",
    "\n",
    "    if {\"total_training_time\", \"train_epochs\"}.issubset(snapshots_df.columns):\n",
    "        snapshots_df[\"avg_epoch_time_calc\"] = snapshots_df[\"total_training_time\"] / snapshots_df[\"train_epochs\"]\n",
    "\n",
    "    snapshots_df[\"r2_delta\"] = snapshots_df[\"best_r2\"] - snapshots_df[\"final_r2\"]\n",
    "\n",
    "    snapshots_df = snapshots_df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    return model_config, training_config, snapshots_df\n",
    "\n",
    "\n",
    "def load_training_logs(paths: Dict[str, Path]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Load loss history and training results with derived analytics.\"\"\"\n",
    "    loss_path = paths[\"output_dir\"] / \"loss_history.csv\"\n",
    "\n",
    "    results_path = paths[\"output_dir\"] / \"training_results.csv\"\n",
    "\n",
    "    loss_records = pd.read_csv(loss_path)\n",
    "\n",
    "    loss_records = loss_records.sort_values([\"epoch\"]).reset_index(drop=True)\n",
    "\n",
    "    loss_records[\"loss_ewm\"] = loss_records[\"combined_loss\"].ewm(alpha=0.15).mean()\n",
    "\n",
    "    epoch_summary = (\n",
    "        loss_records.groupby(\"epoch\").agg(\n",
    "            combined_loss_mean=(\"combined_loss\", \"mean\"),\n",
    "            combined_loss_std=(\"combined_loss\", \"std\"),\n",
    "            mae_mean=(\"mae\", \"mean\"),\n",
    "            mse_mean=(\"mse\", \"mean\")\n",
    "        ).reset_index()\n",
    "    )\n",
    "\n",
    "    results_df = pd.read_csv(results_path)\n",
    "\n",
    "    results_df[\"timestamp\"] = pd.to_datetime(results_df[\"timestamp\"])\n",
    "\n",
    "    results_df = results_df.sort_values(\"epoch\").reset_index(drop=True)\n",
    "\n",
    "    results_df[\"epoch\"] = results_df[\"epoch\"].astype(int)\n",
    "\n",
    "    results_df[\"cumulative_time\"] = results_df[\"epoch_time\"].cumsum()\n",
    "\n",
    "    results_df[\"val_loss_delta\"] = results_df[\"val_loss\"].diff()\n",
    "\n",
    "    results_df[\"train_val_gap\"] = results_df[\"val_loss\"] - results_df[\"train_loss\"]\n",
    "\n",
    "    results_df[\"val_mae_delta\"] = results_df[\"val_mae\"].diff()\n",
    "\n",
    "    results_df[\"epoch_time_rolling\"] = results_df[\"epoch_time\"].rolling(5, min_periods=1).mean()\n",
    "\n",
    "    results_df[\"memory_headroom_mb\"] = results_df[\"memory_mb\"].max() - results_df[\"memory_mb\"]\n",
    "\n",
    "    merged_metrics = results_df.merge(epoch_summary, on=\"epoch\", how=\"left\")\n",
    "\n",
    "    merged_metrics[\"val_loss_rolling\"] = merged_metrics[\"val_loss\"].rolling(5, min_periods=1).mean()\n",
    "\n",
    "    merged_metrics[\"train_loss_rolling\"] = merged_metrics[\"train_loss\"].rolling(5, min_periods=1).mean()\n",
    "\n",
    "    analytics = {\n",
    "        \"loss_records\": loss_records,\n",
    "        \"epoch_summary\": epoch_summary,\n",
    "        \"results\": results_df,\n",
    "        \"merged_metrics\": merged_metrics\n",
    "    }\n",
    "\n",
    "    return analytics\n",
    "\n",
    "\n",
    "def load_scalers(paths: Dict[str, Path]) -> Tuple[Any, Any]:\n",
    "    \"\"\"Load cached scalers, regenerating them via training pipeline if missing.\"\"\"\n",
    "    scaler_X_path = paths[\"scaler_X\"]\n",
    "\n",
    "    scaler_y_path = paths[\"scaler_y\"]\n",
    "\n",
    "    pipeline_ran = False\n",
    "\n",
    "    def ensure_pipeline() -> None:\n",
    "        nonlocal pipeline_ran\n",
    "\n",
    "        if pipeline_ran: return\n",
    "\n",
    "        complete_data_pipeline(csv_path=str(paths[\"data_path\"]))\n",
    "\n",
    "        pipeline_ran = True\n",
    "\n",
    "    try:\n",
    "        scaler_X = joblib.load(scaler_X_path)\n",
    "    except FileNotFoundError:\n",
    "        ensure_pipeline()\n",
    "\n",
    "        scaler_X = joblib.load(scaler_X_path)\n",
    "\n",
    "    try:\n",
    "        scaler_y = joblib.load(scaler_y_path)\n",
    "    except FileNotFoundError:\n",
    "        ensure_pipeline()\n",
    "\n",
    "        scaler_y = joblib.load(scaler_y_path)\n",
    "\n",
    "    return scaler_X, scaler_y\n",
    "\n",
    "\n",
    "def load_particle_data(paths: Dict[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Load particle simulation data with validation safeguards.\"\"\"\n",
    "    dataset = load_and_validate_data(csv_path=str(paths[\"data_path\"]))\n",
    "\n",
    "    if \"particle_id\" in dataset.columns:\n",
    "        dataset = dataset.sort_values(\"particle_id\").reset_index(drop=True)\n",
    "    else:\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_from_config(model_config: Dict[str, Any], training_config: Dict[str, Any]) -> tf.keras.Model:\n",
    "    \"\"\"Instantiate a compiled model that mirrors the training setup.\"\"\"\n",
    "    config_payload = dict(model_config)\n",
    "\n",
    "    config_payload.update(training_config)\n",
    "\n",
    "    config_payload.setdefault(\"enable_weight_oscillation_dampener\", True)\n",
    "\n",
    "    input_shape = (len(INPUT_FEATURES),)\n",
    "\n",
    "    output_shape = len(OUTPUT_TARGETS)\n",
    "\n",
    "    network = AdvancedNeuralNetwork(input_shape=input_shape, output_shape=output_shape, config=config_payload)\n",
    "\n",
    "    network.compile_model()\n",
    "\n",
    "    return network.model\n",
    "\n",
    "\n",
    "def load_model_checkpoint(paths: Dict[str, Path], model_config: Dict[str, Any], training_config: Dict[str, Any], checkpoint_index: pd.DataFrame, checkpoint_name: Optional[str] = None) -> Tuple[Optional[tf.keras.Model], Optional[Dict[str, Any]]]:\n",
    "    \"\"\"Load model weights from the selected checkpoint.\"\"\"\n",
    "    if checkpoint_index.empty: return None, None\n",
    "\n",
    "    if checkpoint_name is None:\n",
    "        selected_row = checkpoint_index.iloc[-1]\n",
    "    else:\n",
    "        if checkpoint_name not in checkpoint_index[\"name\"].values: return None, None\n",
    "\n",
    "        selected_row = checkpoint_index.loc[checkpoint_index[\"name\"] == checkpoint_name].iloc[0]\n",
    "\n",
    "    weights_path = paths[\"project_root\"] / selected_row[\"path\"]\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = build_model_from_config(model_config=model_config, training_config=training_config)\n",
    "\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    metadata = {\n",
    "        \"epoch\": int(selected_row[\"epoch\"]),\n",
    "        \"weights_path\": str(weights_path.relative_to(paths[\"project_root\"])),\n",
    "        \"size_bytes\": int(selected_row[\"size_bytes\"]),\n",
    "        \"size_readable\": selected_row.get(\"size_readable\"),\n",
    "        \"modified\": selected_row[\"modified\"],\n",
    "        \"parameter_count\": int(model.count_params())\n",
    "    }\n",
    "\n",
    "    return model, metadata\n",
    "\n",
    "\n",
    "def compute_predictions(model: Optional[tf.keras.Model], scaler_X: Any, scaler_y: Any, particle_df: pd.DataFrame, sample_size: int = 256) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Generate predictions and residual analytics using stored scalers.\"\"\"\n",
    "    if model is None: return pd.DataFrame(), {}\n",
    "\n",
    "    feature_subset = particle_df[INPUT_FEATURES].copy()\n",
    "\n",
    "    if sample_size and len(feature_subset) > sample_size:\n",
    "        feature_subset = feature_subset.sample(sample_size, random_state=ANALYSIS_SEED).sort_index()\n",
    "\n",
    "    scaled_inputs = scaler_X.transform(feature_subset.values) if scaler_X is not None else feature_subset.values\n",
    "\n",
    "    predictions_scaled = model.predict(scaled_inputs, verbose=0)\n",
    "\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled) if scaler_y is not None else predictions_scaled\n",
    "\n",
    "    actual_outputs = particle_df.loc[feature_subset.index, OUTPUT_TARGETS].values\n",
    "\n",
    "    residuals = predictions - actual_outputs\n",
    "\n",
    "    residual_df = pd.DataFrame(index=feature_subset.index)\n",
    "\n",
    "    if \"particle_id\" in particle_df.columns:\n",
    "        residual_df[\"particle_id\"] = particle_df.loc[feature_subset.index, \"particle_id\"]\n",
    "\n",
    "    for idx, target in enumerate(OUTPUT_TARGETS):\n",
    "        residual_df[f\"actual_{target}\"] = actual_outputs[:, idx]\n",
    "\n",
    "        residual_df[f\"pred_{target}\"] = predictions[:, idx]\n",
    "\n",
    "        residual_df[f\"residual_{target}\"] = residuals[:, idx]\n",
    "\n",
    "    residual_df[\"residual_norm\"] = np.linalg.norm(residuals, axis=1)\n",
    "\n",
    "    residual_norm_mean = residual_df[\"residual_norm\"].mean()\n",
    "\n",
    "    residual_norm_std = residual_df[\"residual_norm\"].std(ddof=0)\n",
    "\n",
    "    if residual_norm_std and residual_norm_std > 0:\n",
    "        residual_df[\"residual_norm_z\"] = (residual_df[\"residual_norm\"] - residual_norm_mean) / residual_norm_std\n",
    "\n",
    "    mae_value = float(np.mean(np.abs(residuals)))\n",
    "\n",
    "    rmse_value = float(np.sqrt(np.mean(np.square(residuals))))\n",
    "\n",
    "    target_metrics: Dict[str, Dict[str, float]] = {}\n",
    "\n",
    "    for idx, target in enumerate(OUTPUT_TARGETS):\n",
    "        target_residuals = residuals[:, idx]\n",
    "\n",
    "        target_metrics[target] = {\n",
    "            \"mae\": float(np.mean(np.abs(target_residuals))),\n",
    "            \"rmse\": float(np.sqrt(np.mean(np.square(target_residuals)))),\n",
    "            \"bias\": float(np.mean(target_residuals))\n",
    "        }\n",
    "\n",
    "    metrics: Dict[str, Any] = {\n",
    "        \"samples\": int(len(residual_df)),\n",
    "        \"mae\": mae_value,\n",
    "        \"rmse\": rmse_value,\n",
    "        \"residual_norm_median\": float(residual_df[\"residual_norm\"].median()),\n",
    "        \"residual_norm_p95\": float(residual_df[\"residual_norm\"].quantile(0.95)),\n",
    "        \"targets\": target_metrics\n",
    "    }\n",
    "\n",
    "    return residual_df, metrics\n",
    "\n",
    "\n",
    "def summarize_run_performance(results_df: pd.DataFrame, epoch_summary: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a concise summary of key performance indicators.\"\"\"\n",
    "    if results_df.empty: return pd.DataFrame()\n",
    "\n",
    "    best_epoch_idx = int(results_df[\"val_loss\"].idxmin())\n",
    "\n",
    "    best_row = results_df.loc[best_epoch_idx]\n",
    "\n",
    "    final_row = results_df.iloc[-1]\n",
    "\n",
    "    early_row = results_df.iloc[0]\n",
    "\n",
    "    improvement = float(early_row[\"val_loss\"] - best_row[\"val_loss\"])\n",
    "\n",
    "    consistency = float(epoch_summary[\"combined_loss_std\"].tail(5).mean()) if not epoch_summary.empty else float(\"nan\")\n",
    "\n",
    "    best_r2_row = results_df.loc[results_df[\"r2_score\"].idxmax()]\n",
    "\n",
    "    summary = pd.DataFrame([\n",
    "        {\"metric\": \"Best validation loss\", \"value\": best_row[\"val_loss\"], \"notes\": f\"Epoch {int(best_row['epoch'])}\"},\n",
    "        {\"metric\": \"Final validation loss\", \"value\": final_row[\"val_loss\"], \"notes\": f\"Train gap {final_row['train_val_gap']:.4f}\"},\n",
    "        {\"metric\": \"Validation improvement\", \"value\": improvement, \"notes\": \"Drop from first to best epoch\"},\n",
    "        {\"metric\": \"Validation stability (std last 5 epochs)\", \"value\": consistency, \"notes\": \"Lower is more stable\"},\n",
    "        {\"metric\": \"Average epoch time (last 10 epochs)\", \"value\": results_df[\"epoch_time\"].tail(10).mean(), \"notes\": \"Supports batch-size experiments\"},\n",
    "        {\"metric\": \"Peak R²\", \"value\": best_r2_row[\"r2_score\"], \"notes\": f\"Epoch {int(best_r2_row['epoch'])}\"},\n",
    "        {\"metric\": \"Total recorded training time\", \"value\": results_df[\"epoch_time\"].sum(), \"notes\": \"seconds\"}\n",
    "    ])\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def suggest_hyperparameters(model_config: Dict[str, Any], training_config: Dict[str, Any], config_history: pd.DataFrame, results_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Derive hyperparameter sweep recommendations from observed metrics.\"\"\"\n",
    "    if results_df.empty: return pd.DataFrame()\n",
    "\n",
    "    suggestions: List[Dict[str, Any]] = []\n",
    "\n",
    "    base_lr = float(model_config.get(\"learning_rate\", 0.001))\n",
    "\n",
    "    final_window = results_df.tail(5)\n",
    "\n",
    "    val_loss_range = float(final_window[\"val_loss\"].max() - final_window[\"val_loss\"].min())\n",
    "\n",
    "    best_epoch = int(results_df.loc[results_df[\"val_loss\"].idxmin(), \"epoch\"])\n",
    "\n",
    "    final_epoch = int(results_df.iloc[-1][\"epoch\"])\n",
    "\n",
    "    total_epochs = int(training_config.get(\"epochs\", final_epoch + 1))\n",
    "\n",
    "    if val_loss_range < 0.01 and final_epoch - best_epoch > 5:\n",
    "        proposals = sorted({round(base_lr * factor, 6) for factor in (0.5, 0.8, 1.2)})\n",
    "\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"learning_rate\",\n",
    "            \"proposed_values\": proposals,\n",
    "            \"rationale\": \"Validation loss plateaued across the last epochs; nudge the optimizer step to reintroduce progress.\",\n",
    "            \"constraints\": \"Keep BinaryWeightConstraintMax(max_binary_digits=5) engaged for stability.\"\n",
    "        })\n",
    "\n",
    "    train_val_gap = float(final_window[\"train_val_gap\"].mean())\n",
    "\n",
    "    if train_val_gap > 0.05:\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"dropout_rate\",\n",
    "            \"proposed_values\": [0.05, 0.1, 0.15],\n",
    "            \"rationale\": \"Consistent validation > training loss points to mild overfitting; mild dropout can regularize activations.\",\n",
    "            \"constraints\": \"Retain enable_weight_oscillation_dampener=True to temper weight swings.\"\n",
    "        })\n",
    "\n",
    "    avg_epoch_time = float(results_df[\"epoch_time\"].tail(10).mean())\n",
    "\n",
    "    memory_headroom = float(results_df[\"memory_headroom_mb\"].tail(10).mean())\n",
    "\n",
    "    if avg_epoch_time < 1.5 and memory_headroom > 0:\n",
    "        baseline_batch = int(training_config.get(\"batch_size\", 16))\n",
    "\n",
    "        candidate_batches = sorted({baseline_batch, 24, 32})\n",
    "\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"batch_size\",\n",
    "            \"proposed_values\": candidate_batches,\n",
    "            \"rationale\": \"Epoch time and memory logs show headroom; larger batches could reduce gradient variance.\",\n",
    "            \"constraints\": \"Validate GPU memory against peak usage before committing.\"\n",
    "        })\n",
    "\n",
    "    if final_epoch >= total_epochs - 2:\n",
    "        extension_epochs = sorted({total_epochs + 10, total_epochs + 20})\n",
    "\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"epochs\",\n",
    "            \"proposed_values\": extension_epochs,\n",
    "            \"rationale\": \"Best epoch occurs near training ceiling; extending training may unlock additional gains.\",\n",
    "            \"constraints\": \"Monitor for overfitting; stop early if val loss degrades.\"\n",
    "        })\n",
    "\n",
    "    if not config_history.empty and \"learning_rate\" in config_history.columns:\n",
    "        grouped = config_history.groupby(\"learning_rate\")[\"final_r2\"].mean().sort_values()\n",
    "\n",
    "        if len(grouped) > 1:\n",
    "            top_lr = grouped.idxmax()\n",
    "\n",
    "            if abs(top_lr - base_lr) / base_lr > 0.2:\n",
    "                suggestions.append({\n",
    "                    \"parameter\": \"learning_rate\",\n",
    "                    \"proposed_values\": [round(float(top_lr), 6)],\n",
    "                    \"rationale\": \"Historical sweep points to a different learning rate yielding higher final R².\",\n",
    "                    \"constraints\": \"Pair with BinaryWeightConstraintChanges() to keep update granularity consistent.\"\n",
    "                })\n",
    "\n",
    "    if suggestions:\n",
    "        recommendations = pd.DataFrame(suggestions)\n",
    "\n",
    "        return recommendations.drop_duplicates(subset=[\"parameter\", \"rationale\"])\n",
    "\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a3960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Project root:** `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Artifact Inventory"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artifact</th>\n",
       "      <th>critical</th>\n",
       "      <th>exists</th>\n",
       "      <th>path</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>size_readable</th>\n",
       "      <th>modified</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>configuration_log</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\configuration_log.csv</td>\n",
       "      <td>3,666.0000</td>\n",
       "      <td>3.6 KB</td>\n",
       "      <td>2025-09-30 18:49:41.074594975</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loss_history</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\loss_history.csv</td>\n",
       "      <td>1,434,016.0000</td>\n",
       "      <td>1.4 MB</td>\n",
       "      <td>2025-09-30 18:49:41.202371597</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_config</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ml_config\\model_config.json</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>263.0 B</td>\n",
       "      <td>2025-09-30 07:43:10.036819696</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>particle_data</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>particle_data.csv</td>\n",
       "      <td>251,578.0000</td>\n",
       "      <td>245.7 KB</td>\n",
       "      <td>2025-09-30 06:52:34.713520765</td>\n",
       "      <td>Regenerate via data pipeline if missing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scaler_X</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>scaler_X.pkl</td>\n",
       "      <td>807.0000</td>\n",
       "      <td>807.0 B</td>\n",
       "      <td>2025-09-30 18:38:17.606033087</td>\n",
       "      <td>Rebuilt automatically through complete_data_pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scaler_y</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>scaler_y.pkl</td>\n",
       "      <td>759.0000</td>\n",
       "      <td>759.0 B</td>\n",
       "      <td>2025-09-30 18:38:17.607032776</td>\n",
       "      <td>Rebuilt automatically through complete_data_pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>training_config</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ml_config\\training_config.json</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>37.0 B</td>\n",
       "      <td>2025-09-30 18:38:03.289540291</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>training_results</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\training_results.csv</td>\n",
       "      <td>99,525.0000</td>\n",
       "      <td>97.2 KB</td>\n",
       "      <td>2025-09-30 18:49:41.072592497</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>analysis_dir</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-30 07:11:31.113477707</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>figures_dir</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\analysis\\figures</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-30 07:12:11.038027287</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artifact  critical  exists                                   path  \\\n",
       "0  configuration_log      True    True  training_output\\configuration_log.csv   \n",
       "1       loss_history      True    True       training_output\\loss_history.csv   \n",
       "2       model_config      True    True            ml_config\\model_config.json   \n",
       "3      particle_data      True    True                      particle_data.csv   \n",
       "4           scaler_X      True    True                           scaler_X.pkl   \n",
       "5           scaler_y      True    True                           scaler_y.pkl   \n",
       "6    training_config      True    True         ml_config\\training_config.json   \n",
       "7   training_results      True    True   training_output\\training_results.csv   \n",
       "8       analysis_dir     False    True               training_output\\analysis   \n",
       "9        figures_dir     False    True       training_output\\analysis\\figures   \n",
       "\n",
       "      size_bytes size_readable                      modified  \\\n",
       "0     3,666.0000        3.6 KB 2025-09-30 18:49:41.074594975   \n",
       "1 1,434,016.0000        1.4 MB 2025-09-30 18:49:41.202371597   \n",
       "2       263.0000       263.0 B 2025-09-30 07:43:10.036819696   \n",
       "3   251,578.0000      245.7 KB 2025-09-30 06:52:34.713520765   \n",
       "4       807.0000       807.0 B 2025-09-30 18:38:17.606033087   \n",
       "5       759.0000       759.0 B 2025-09-30 18:38:17.607032776   \n",
       "6        37.0000        37.0 B 2025-09-30 18:38:03.289540291   \n",
       "7    99,525.0000       97.2 KB 2025-09-30 18:49:41.072592497   \n",
       "8            NaN          None 2025-09-30 07:11:31.113477707   \n",
       "9            NaN          None 2025-09-30 07:12:11.038027287   \n",
       "\n",
       "                                                note  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3           Regenerate via data pipeline if missing.  \n",
       "4  Rebuilt automatically through complete_data_pi...  \n",
       "5  Rebuilt automatically through complete_data_pi...  \n",
       "6                                               None  \n",
       "7                                               None  \n",
       "8                                               None  \n",
       "9                                               None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "✅ All critical artifacts are present."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = resolve_project_paths()\n",
    "\n",
    "display(Markdown(f\"**Project root:** `{paths['project_root']}`\"))\n",
    "\n",
    "artifact_status = validate_required_artifacts(paths)\n",
    "\n",
    "display(Markdown(\"### Artifact Inventory\"))\n",
    "\n",
    "display(artifact_status)\n",
    "\n",
    "missing_artifacts = artifact_status.loc[~artifact_status[\"exists\"]]\n",
    "\n",
    "if not missing_artifacts.empty:\n",
    "    display(Markdown(\"⚠️ **Missing artifacts detected. Review notes before continuing.**\"))\n",
    "\n",
    "    display(missing_artifacts)\n",
    "else:\n",
    "    display(Markdown(\"✅ All critical artifacts are present.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c7438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Active Model Configuration"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hidden_layers                         [64, 32, 16]\n",
       "activation                                    relu\n",
       "optimizer                                     adam\n",
       "learning_rate                               0.0050\n",
       "dropout_rate                                0.0500\n",
       "enable_weight_oscillation_dampener            True\n",
       "enable_binary_change_max                      True\n",
       "max_additional_binary_digits                    16\n",
       "Name: model_config, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Active Training Configuration"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "epochs        500\n",
       "batch_size     16\n",
       "Name: training_config, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Historical Configuration Snapshots"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>config_id</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>train_epochs</th>\n",
       "      <th>best_r2</th>\n",
       "      <th>final_r2</th>\n",
       "      <th>r2_delta</th>\n",
       "      <th>avg_epoch_time_logged</th>\n",
       "      <th>avg_epoch_time_calc</th>\n",
       "      <th>total_training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-30 01:38:08.986529</td>\n",
       "      <td>training_config_20250930_013808</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>1.0383</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>62.4201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-30 02:18:40.642721</td>\n",
       "      <td>training_config_20250930_021840</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "      <td>80</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.8446</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>1.1400</td>\n",
       "      <td>1.1439</td>\n",
       "      <td>91.5110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-30 02:20:25.365475</td>\n",
       "      <td>training_config_20250930_022025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "      <td>80</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>1.1985</td>\n",
       "      <td>1.2028</td>\n",
       "      <td>96.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-30 02:23:38.130602</td>\n",
       "      <td>training_config_20250930_022338</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>90</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.8608</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>1.3518</td>\n",
       "      <td>1.3554</td>\n",
       "      <td>121.9817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-30 02:27:07.080559</td>\n",
       "      <td>training_config_20250930_022707</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "      <td>0.8642</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>1.3635</td>\n",
       "      <td>1.3670</td>\n",
       "      <td>150.3698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-09-30 02:30:30.378506</td>\n",
       "      <td>training_config_20250930_023030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>1.2568</td>\n",
       "      <td>1.2605</td>\n",
       "      <td>163.8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-09-30 02:34:24.444506</td>\n",
       "      <td>training_config_20250930_023424</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>150</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>0.8559</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>1.3037</td>\n",
       "      <td>1.3066</td>\n",
       "      <td>195.9893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-09-30 02:39:11.458678</td>\n",
       "      <td>training_config_20250930_023911</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>1.2773</td>\n",
       "      <td>1.2803</td>\n",
       "      <td>204.8531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-09-30 02:50:12.309857</td>\n",
       "      <td>training_config_20250930_025012</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>170</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>1.2712</td>\n",
       "      <td>1.2750</td>\n",
       "      <td>216.7573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-09-30 02:54:36.727654</td>\n",
       "      <td>training_config_20250930_025436</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>190</td>\n",
       "      <td>0.8773</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>1.2478</td>\n",
       "      <td>1.2512</td>\n",
       "      <td>237.7279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-09-30 02:59:57.523280</td>\n",
       "      <td>training_config_20250930_025957</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>210</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>1.2592</td>\n",
       "      <td>1.2627</td>\n",
       "      <td>265.1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-09-30 03:05:41.603818</td>\n",
       "      <td>training_config_20250930_030541</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>230</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>0.8556</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>1.3921</td>\n",
       "      <td>1.3955</td>\n",
       "      <td>320.9728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-09-30 03:13:04.866569</td>\n",
       "      <td>training_config_20250930_031304</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>250</td>\n",
       "      <td>0.8719</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>1.5131</td>\n",
       "      <td>1.5214</td>\n",
       "      <td>380.3553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-09-30 03:19:01.355274</td>\n",
       "      <td>training_config_20250930_031901</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>250</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.8318</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>1.3542</td>\n",
       "      <td>1.3578</td>\n",
       "      <td>339.4579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-09-30 03:26:38.860461</td>\n",
       "      <td>training_config_20250930_032638</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>1.4134</td>\n",
       "      <td>1.4169</td>\n",
       "      <td>425.0648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-09-30 03:34:48.471485</td>\n",
       "      <td>training_config_20250930_033448</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>320</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.8484</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>1.4178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>454.8581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-09-30 03:44:22.765926</td>\n",
       "      <td>training_config_20250930_034422</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>340</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>1.5581</td>\n",
       "      <td>1.5621</td>\n",
       "      <td>531.1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-09-30 03:54:11.023652</td>\n",
       "      <td>training_config_20250930_035411</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>360</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>0.8296</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>1.5628</td>\n",
       "      <td>1.5668</td>\n",
       "      <td>564.0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-09-30 13:25:04.777656</td>\n",
       "      <td>training_config_20250930_132504</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>400</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>1.4719</td>\n",
       "      <td>1.4755</td>\n",
       "      <td>590.1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-09-30 13:37:48.324697</td>\n",
       "      <td>training_config_20250930_133748</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>460</td>\n",
       "      <td>0.8620</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>1.4008</td>\n",
       "      <td>1.4042</td>\n",
       "      <td>645.9447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-09-30 13:49:41.073591</td>\n",
       "      <td>training_config_20250930_134941</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>16</td>\n",
       "      <td>500</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>1.3619</td>\n",
       "      <td>1.3654</td>\n",
       "      <td>682.6939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp                        config_id  learning_rate  \\\n",
       "0  2025-09-30 01:38:08.986529  training_config_20250930_013808         0.0050   \n",
       "1  2025-09-30 02:18:40.642721  training_config_20250930_021840         0.0025   \n",
       "2  2025-09-30 02:20:25.365475  training_config_20250930_022025         0.0025   \n",
       "3  2025-09-30 02:23:38.130602  training_config_20250930_022338         0.0050   \n",
       "4  2025-09-30 02:27:07.080559  training_config_20250930_022707         0.0050   \n",
       "5  2025-09-30 02:30:30.378506  training_config_20250930_023030         0.0050   \n",
       "6  2025-09-30 02:34:24.444506  training_config_20250930_023424         0.0050   \n",
       "7  2025-09-30 02:39:11.458678  training_config_20250930_023911         0.0025   \n",
       "8  2025-09-30 02:50:12.309857  training_config_20250930_025012         0.0050   \n",
       "9  2025-09-30 02:54:36.727654  training_config_20250930_025436         0.0050   \n",
       "10 2025-09-30 02:59:57.523280  training_config_20250930_025957         0.0050   \n",
       "11 2025-09-30 03:05:41.603818  training_config_20250930_030541         0.0050   \n",
       "12 2025-09-30 03:13:04.866569  training_config_20250930_031304         0.0050   \n",
       "13 2025-09-30 03:19:01.355274  training_config_20250930_031901         0.0050   \n",
       "14 2025-09-30 03:26:38.860461  training_config_20250930_032638         0.0050   \n",
       "15 2025-09-30 03:34:48.471485  training_config_20250930_033448         0.0050   \n",
       "16 2025-09-30 03:44:22.765926  training_config_20250930_034422         0.0050   \n",
       "17 2025-09-30 03:54:11.023652  training_config_20250930_035411         0.0050   \n",
       "18 2025-09-30 13:25:04.777656  training_config_20250930_132504         0.0050   \n",
       "19 2025-09-30 13:37:48.324697  training_config_20250930_133748         0.0050   \n",
       "20 2025-09-30 13:49:41.073591  training_config_20250930_134941         0.0050   \n",
       "\n",
       "    dropout_rate  train_batch_size  train_epochs  best_r2  final_r2  r2_delta  \\\n",
       "0         0.0000                16            60   0.8562    0.8506    0.0056   \n",
       "1         0.0000                16            80   0.8469    0.8446    0.0023   \n",
       "2         0.0000                16            80   0.8460    0.8323    0.0138   \n",
       "3         0.0500                16            90   0.8743    0.8608    0.0134   \n",
       "4         0.0500                16           110   0.8642    0.8512    0.0130   \n",
       "5         0.0500                16           130   0.8666    0.8380    0.0286   \n",
       "6         0.0500                16           150   0.8689    0.8559    0.0130   \n",
       "7         0.0500                16           160   0.8555    0.8454    0.0101   \n",
       "8         0.0500                16           170   0.8695    0.8538    0.0156   \n",
       "9         0.0500                16           190   0.8773    0.8596    0.0177   \n",
       "10        0.0500                16           210   0.8695    0.8461    0.0234   \n",
       "11        0.0500                16           230   0.8718    0.8556    0.0162   \n",
       "12        0.0500                16           250   0.8719    0.8560    0.0159   \n",
       "13        0.0500                16           250   0.8614    0.8318    0.0296   \n",
       "14        0.0500                16           300   0.8663    0.8527    0.0136   \n",
       "15        0.0500                16           320   0.8692    0.8484    0.0208   \n",
       "16        0.0500                16           340   0.8707    0.8545    0.0163   \n",
       "17        0.0500                16           360   0.8560    0.8296    0.0264   \n",
       "18        0.0500                16           400   0.8783    0.8288    0.0495   \n",
       "19        0.0500                16           460   0.8620    0.8311    0.0309   \n",
       "20        0.0500                16           500   0.8735    0.8469    0.0266   \n",
       "\n",
       "    avg_epoch_time_logged  avg_epoch_time_calc  total_training_time  \n",
       "0                  1.0383               1.0403              62.4201  \n",
       "1                  1.1400               1.1439              91.5110  \n",
       "2                  1.1985               1.2028              96.2257  \n",
       "3                  1.3518               1.3554             121.9817  \n",
       "4                  1.3635               1.3670             150.3698  \n",
       "5                  1.2568               1.2605             163.8691  \n",
       "6                  1.3037               1.3066             195.9893  \n",
       "7                  1.2773               1.2803             204.8531  \n",
       "8                  1.2712               1.2750             216.7573  \n",
       "9                  1.2478               1.2512             237.7279  \n",
       "10                 1.2592               1.2627             265.1614  \n",
       "11                 1.3921               1.3955             320.9728  \n",
       "12                 1.5131               1.5214             380.3553  \n",
       "13                 1.3542               1.3578             339.4579  \n",
       "14                 1.4134               1.4169             425.0648  \n",
       "15                 1.4178               1.4214             454.8581  \n",
       "16                 1.5581               1.5621             531.1017  \n",
       "17                 1.5628               1.5668             564.0480  \n",
       "18                 1.4719               1.4755             590.1994  \n",
       "19                 1.4008               1.4042             645.9447  \n",
       "20                 1.3619               1.3654             682.6939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Configuration Summary Statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_rate</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_batch_size</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_epochs</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>230.4762</td>\n",
       "      <td>128.8983</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>130.0000</td>\n",
       "      <td>210.0000</td>\n",
       "      <td>320.0000</td>\n",
       "      <td>500.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_r2</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.8655</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>0.8718</td>\n",
       "      <td>0.8783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_r2</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.8484</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.8608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_delta</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_epoch_time_logged</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>1.3407</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>1.0383</td>\n",
       "      <td>1.2592</td>\n",
       "      <td>1.3542</td>\n",
       "      <td>1.4134</td>\n",
       "      <td>1.5628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_epoch_time_calc</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>1.3444</td>\n",
       "      <td>0.1322</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>1.2627</td>\n",
       "      <td>1.3578</td>\n",
       "      <td>1.4169</td>\n",
       "      <td>1.5668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_training_time</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>321.0268</td>\n",
       "      <td>194.7059</td>\n",
       "      <td>62.4201</td>\n",
       "      <td>163.8691</td>\n",
       "      <td>265.1614</td>\n",
       "      <td>454.8581</td>\n",
       "      <td>682.6939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count     mean      std     min      25%      50%  \\\n",
       "learning_rate         21.0000   0.0046   0.0009  0.0025   0.0050   0.0050   \n",
       "dropout_rate          21.0000   0.0429   0.0179  0.0000   0.0500   0.0500   \n",
       "train_batch_size      21.0000  16.0000   0.0000 16.0000  16.0000  16.0000   \n",
       "train_epochs          21.0000 230.4762 128.8983 60.0000 130.0000 210.0000   \n",
       "best_r2               21.0000   0.8655   0.0091  0.8460   0.8614   0.8689   \n",
       "final_r2              21.0000   0.8464   0.0104  0.8288   0.8380   0.8484   \n",
       "r2_delta              21.0000   0.0192   0.0104  0.0023   0.0134   0.0162   \n",
       "avg_epoch_time_logged 21.0000   1.3407   0.1317  1.0383   1.2592   1.3542   \n",
       "avg_epoch_time_calc   21.0000   1.3444   0.1322  1.0403   1.2627   1.3578   \n",
       "total_training_time   21.0000 321.0268 194.7059 62.4201 163.8691 265.1614   \n",
       "\n",
       "                           75%      max  \n",
       "learning_rate           0.0050   0.0050  \n",
       "dropout_rate            0.0500   0.0500  \n",
       "train_batch_size       16.0000  16.0000  \n",
       "train_epochs          320.0000 500.0000  \n",
       "best_r2                 0.8718   0.8783  \n",
       "final_r2                0.8545   0.8608  \n",
       "r2_delta                0.0264   0.0495  \n",
       "avg_epoch_time_logged   1.4134   1.5628  \n",
       "avg_epoch_time_calc     1.4169   1.5668  \n",
       "total_training_time   454.8581 682.6939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config, training_config, config_history = load_configs(paths)\n",
    "\n",
    "display(Markdown(\"### Active Model Configuration\"))\n",
    "\n",
    "display(pd.Series(model_config, name=\"model_config\"))\n",
    "\n",
    "display(Markdown(\"### Active Training Configuration\"))\n",
    "\n",
    "display(pd.Series(training_config, name=\"training_config\"))\n",
    "\n",
    "if not config_history.empty:\n",
    "    display(Markdown(\"### Historical Configuration Snapshots\"))\n",
    "\n",
    "    history_columns = [\n",
    "        col\n",
    "        for col in [\n",
    "            \"timestamp\", \"config_id\", \"learning_rate\", \"dropout_rate\", \"train_batch_size\", \"train_epochs\", \"best_r2\", \"final_r2\", \"r2_delta\", \"avg_epoch_time_logged\", \"avg_epoch_time_calc\", \"total_training_time\"\n",
    "        ]\n",
    "        if col in config_history.columns\n",
    "    ]\n",
    "\n",
    "    display(config_history[history_columns])\n",
    "\n",
    "    numeric_cols = [col for col in history_columns if config_history[col].dtype.kind in \"if\"]\n",
    "\n",
    "    if numeric_cols:\n",
    "        history_stats = config_history[numeric_cols].describe().transpose()\n",
    "\n",
    "        display(Markdown(\"#### Configuration Summary Statistics\"))\n",
    "\n",
    "        display(history_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4b5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Epoch-Level Performance Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_gap</th>\n",
       "      <th>val_loss_delta</th>\n",
       "      <th>epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.1778</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>1.3124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>-0.0098</td>\n",
       "      <td>-0.0106</td>\n",
       "      <td>1.3061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>0.1718</td>\n",
       "      <td>0.1647</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>1.4694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>0.1778</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>1.4071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>-0.0144</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>1.4745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>-0.0221</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>1.7862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>-0.0138</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>1.4770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>0.1606</td>\n",
       "      <td>-0.0160</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>1.4746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1691</td>\n",
       "      <td>-0.0149</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>1.7320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>0.1851</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>-0.0140</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.3508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  train_loss  val_loss  train_val_gap  val_loss_delta  epoch_time\n",
       "490    490      0.1665    0.1778         0.0113          0.0146      1.3124\n",
       "491    491      0.1771    0.1673        -0.0098         -0.0106      1.3061\n",
       "492    492      0.1718    0.1647        -0.0071         -0.0025      1.4694\n",
       "493    493      0.1725    0.1778         0.0053          0.0131      1.4071\n",
       "494    494      0.1859    0.1715        -0.0144         -0.0063      1.4745\n",
       "495    495      0.1809    0.1589        -0.0221         -0.0126      1.7862\n",
       "496    496      0.1779    0.1641        -0.0138          0.0052      1.4770\n",
       "497    497      0.1766    0.1606        -0.0160         -0.0035      1.4746\n",
       "498    498      0.1840    0.1691        -0.0149          0.0085      1.7320\n",
       "499    499      0.1851    0.1711        -0.0140          0.0020      1.3508"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Key Performance Indicators"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best validation loss</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>Epoch 129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final validation loss</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>Train gap -0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Validation improvement</td>\n",
       "      <td>0.5788</td>\n",
       "      <td>Drop from first to best epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Validation stability (std last 5 epochs)</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>Lower is more stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Average epoch time (last 10 epochs)</td>\n",
       "      <td>1.4790</td>\n",
       "      <td>Supports batch-size experiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peak R²</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>Epoch 129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total recorded training time</td>\n",
       "      <td>680.9495</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     metric    value  \\\n",
       "0                      Best validation loss   0.1409   \n",
       "1                     Final validation loss   0.1711   \n",
       "2                    Validation improvement   0.5788   \n",
       "3  Validation stability (std last 5 epochs)   0.0439   \n",
       "4       Average epoch time (last 10 epochs)   1.4790   \n",
       "5                                   Peak R²   0.8735   \n",
       "6              Total recorded training time 680.9495   \n",
       "\n",
       "                             notes  \n",
       "0                        Epoch 129  \n",
       "1                Train gap -0.0140  \n",
       "2    Drop from first to best epoch  \n",
       "3             Lower is more stable  \n",
       "4  Supports batch-size experiments  \n",
       "5                        Epoch 129  \n",
       "6                          seconds  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Loss Distribution by Epoch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>combined_loss_mean</th>\n",
       "      <th>combined_loss_std</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mse_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>489</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>490</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.1189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>0.1718</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>494</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.2374</td>\n",
       "      <td>0.1245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.2331</td>\n",
       "      <td>0.1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1851</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.2393</td>\n",
       "      <td>0.1310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  combined_loss_mean  combined_loss_std  mae_mean  mse_mean\n",
       "489    489              0.1665             0.0366    0.2235    0.1096\n",
       "490    490              0.1771             0.0334    0.2353    0.1189\n",
       "491    491              0.1718             0.0422    0.2282    0.1154\n",
       "492    492              0.1725             0.0366    0.2293    0.1156\n",
       "493    493              0.1859             0.0380    0.2414    0.1304\n",
       "494    494              0.1809             0.0459    0.2374    0.1245\n",
       "495    495              0.1779             0.0367    0.2331    0.1227\n",
       "496    496              0.1766             0.0401    0.2320    0.1211\n",
       "497    497              0.1840             0.0464    0.2375    0.1305\n",
       "498    498              0.1851             0.0505    0.2393    0.1310"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Exponential Moving Average of Combined Loss"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>combined_loss</th>\n",
       "      <th>loss_ewm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1912</td>\n",
       "      <td>0.1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>498</td>\n",
       "      <td>0.2639</td>\n",
       "      <td>0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.1911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>498</td>\n",
       "      <td>0.2059</td>\n",
       "      <td>0.1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.1827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>0.1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>498</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>0.1781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       epoch  combined_loss  loss_ewm\n",
       "19990    498         0.1459    0.1940\n",
       "19991    498         0.1912    0.1936\n",
       "19992    498         0.2639    0.2042\n",
       "19993    498         0.1173    0.1911\n",
       "19994    498         0.2059    0.1933\n",
       "19995    498         0.1809    0.1915\n",
       "19996    498         0.1701    0.1883\n",
       "19997    498         0.1513    0.1827\n",
       "19998    498         0.1542    0.1784\n",
       "19999    498         0.1763    0.1781"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analytics = load_training_logs(paths)\n",
    "\n",
    "loss_records = analytics[\"loss_records\"]\n",
    "\n",
    "epoch_summary = analytics[\"epoch_summary\"]\n",
    "\n",
    "results_df = analytics[\"results\"]\n",
    "\n",
    "merged_metrics = analytics[\"merged_metrics\"]\n",
    "\n",
    "display(Markdown(\"### Epoch-Level Performance Summary\"))\n",
    "\n",
    "display(results_df.tail(10)[[\"epoch\", \"train_loss\", \"val_loss\", \"train_val_gap\", \"val_loss_delta\", \"epoch_time\"]])\n",
    "\n",
    "performance_snapshot = summarize_run_performance(results_df, epoch_summary)\n",
    "\n",
    "display(Markdown(\"### Key Performance Indicators\"))\n",
    "\n",
    "display(performance_snapshot)\n",
    "\n",
    "display(Markdown(\"#### Loss Distribution by Epoch\"))\n",
    "\n",
    "display(epoch_summary.tail(10))\n",
    "\n",
    "display(Markdown(\"#### Exponential Moving Average of Combined Loss\"))\n",
    "\n",
    "display(loss_records.tail(10)[[\"epoch\", \"combined_loss\", \"loss_ewm\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674f3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded particle data from c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\particle_data.csv (1000 particles)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Particle Data Snapshot"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Dataset shape: **1000** rows × **15** columns"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>particle_id</th>\n",
       "      <th>mass</th>\n",
       "      <th>initial_velocity_x</th>\n",
       "      <th>initial_velocity_y</th>\n",
       "      <th>initial_position_x</th>\n",
       "      <th>initial_position_y</th>\n",
       "      <th>charge</th>\n",
       "      <th>magnetic_field_strength</th>\n",
       "      <th>simulation_time</th>\n",
       "      <th>final_velocity_x</th>\n",
       "      <th>final_velocity_y</th>\n",
       "      <th>final_position_x</th>\n",
       "      <th>final_position_y</th>\n",
       "      <th>kinetic_energy</th>\n",
       "      <th>trajectory_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.8079</td>\n",
       "      <td>-3.1487</td>\n",
       "      <td>-2.3829</td>\n",
       "      <td>3.4541</td>\n",
       "      <td>1.4399</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2939</td>\n",
       "      <td>3.6656</td>\n",
       "      <td>1.2294</td>\n",
       "      <td>-3.7246</td>\n",
       "      <td>-9.4442</td>\n",
       "      <td>1.1308</td>\n",
       "      <td>29.2917</td>\n",
       "      <td>12.9020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.5121</td>\n",
       "      <td>0.4190</td>\n",
       "      <td>-2.5302</td>\n",
       "      <td>5.9336</td>\n",
       "      <td>6.1086</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>6.1506</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>-2.3032</td>\n",
       "      <td>6.4958</td>\n",
       "      <td>-10.2526</td>\n",
       "      <td>29.9911</td>\n",
       "      <td>16.3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.3467</td>\n",
       "      <td>3.7295</td>\n",
       "      <td>4.0625</td>\n",
       "      <td>-4.9906</td>\n",
       "      <td>5.2032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3007</td>\n",
       "      <td>4.9767</td>\n",
       "      <td>2.9367</td>\n",
       "      <td>4.8254</td>\n",
       "      <td>16.4110</td>\n",
       "      <td>22.5882</td>\n",
       "      <td>117.2113</td>\n",
       "      <td>27.5730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0267</td>\n",
       "      <td>2.3222</td>\n",
       "      <td>-2.5045</td>\n",
       "      <td>2.4975</td>\n",
       "      <td>-6.9220</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6444</td>\n",
       "      <td>4.1205</td>\n",
       "      <td>2.4379</td>\n",
       "      <td>-2.4846</td>\n",
       "      <td>13.1317</td>\n",
       "      <td>-14.8400</td>\n",
       "      <td>36.5107</td>\n",
       "      <td>13.2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.6446</td>\n",
       "      <td>3.0656</td>\n",
       "      <td>-2.2805</td>\n",
       "      <td>1.4349</td>\n",
       "      <td>-7.0150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1996</td>\n",
       "      <td>7.7181</td>\n",
       "      <td>1.1290</td>\n",
       "      <td>-3.5859</td>\n",
       "      <td>-1.5585</td>\n",
       "      <td>-5.7997</td>\n",
       "      <td>11.6218</td>\n",
       "      <td>3.2307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   particle_id   mass  initial_velocity_x  initial_velocity_y  \\\n",
       "0            1 3.8079             -3.1487             -2.3829   \n",
       "1            2 9.5121              0.4190             -2.5302   \n",
       "2            3 7.3467              3.7295              4.0625   \n",
       "3            4 6.0267              2.3222             -2.5045   \n",
       "4            5 1.6446              3.0656             -2.2805   \n",
       "\n",
       "   initial_position_x  initial_position_y  charge  magnetic_field_strength  \\\n",
       "0              3.4541              1.4399       1                   1.2939   \n",
       "1              5.9336              6.1086       1                   0.4498   \n",
       "2             -4.9906              5.2032       1                   0.3007   \n",
       "3              2.4975             -6.9220       0                   1.6444   \n",
       "4              1.4349             -7.0150       1                   1.1996   \n",
       "\n",
       "   simulation_time  final_velocity_x  final_velocity_y  final_position_x  \\\n",
       "0           3.6656            1.2294           -3.7246           -9.4442   \n",
       "1           6.1506            1.0007           -2.3032            6.4958   \n",
       "2           4.9767            2.9367            4.8254           16.4110   \n",
       "3           4.1205            2.4379           -2.4846           13.1317   \n",
       "4           7.7181            1.1290           -3.5859           -1.5585   \n",
       "\n",
       "   final_position_y  kinetic_energy  trajectory_length  \n",
       "0            1.1308         29.2917            12.9020  \n",
       "1          -10.2526         29.9911            16.3709  \n",
       "2           22.5882        117.2113            27.5730  \n",
       "3          -14.8400         36.5107            13.2583  \n",
       "4           -5.7997         11.6218             3.2307  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Descriptive Statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>particle_id</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>288.8194</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>250.7500</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>750.2500</td>\n",
       "      <td>1,000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>4.9535</td>\n",
       "      <td>2.8922</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>2.4361</td>\n",
       "      <td>5.0184</td>\n",
       "      <td>7.4688</td>\n",
       "      <td>9.9972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_velocity_x</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>2.9219</td>\n",
       "      <td>-4.9678</td>\n",
       "      <td>-2.5893</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>2.6047</td>\n",
       "      <td>4.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_velocity_y</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>2.9067</td>\n",
       "      <td>-4.9999</td>\n",
       "      <td>-2.3865</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>2.5910</td>\n",
       "      <td>4.9782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_position_x</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.1925</td>\n",
       "      <td>5.7298</td>\n",
       "      <td>-9.9869</td>\n",
       "      <td>-5.1620</td>\n",
       "      <td>-0.3144</td>\n",
       "      <td>4.7508</td>\n",
       "      <td>9.9912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_position_y</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.1179</td>\n",
       "      <td>5.7362</td>\n",
       "      <td>-9.9994</td>\n",
       "      <td>-5.1005</td>\n",
       "      <td>-0.1080</td>\n",
       "      <td>4.7999</td>\n",
       "      <td>9.9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charge</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.0080</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magnetic_field_strength</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>1.0462</td>\n",
       "      <td>0.5518</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>1.0473</td>\n",
       "      <td>1.5370</td>\n",
       "      <td>1.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation_time</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>5.3997</td>\n",
       "      <td>2.5677</td>\n",
       "      <td>1.0022</td>\n",
       "      <td>3.1719</td>\n",
       "      <td>5.3375</td>\n",
       "      <td>7.5665</td>\n",
       "      <td>9.9929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_velocity_x</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>2.9209</td>\n",
       "      <td>-7.0916</td>\n",
       "      <td>-2.2262</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>2.4793</td>\n",
       "      <td>6.9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_velocity_y</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>2.9143</td>\n",
       "      <td>-7.0037</td>\n",
       "      <td>-2.3110</td>\n",
       "      <td>-0.0523</td>\n",
       "      <td>2.3679</td>\n",
       "      <td>6.5705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_x</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.1503</td>\n",
       "      <td>15.7771</td>\n",
       "      <td>-55.4273</td>\n",
       "      <td>-9.1107</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>9.4239</td>\n",
       "      <td>49.6116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_y</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.0439</td>\n",
       "      <td>16.4600</td>\n",
       "      <td>-60.2677</td>\n",
       "      <td>-9.3707</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>9.2660</td>\n",
       "      <td>64.4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kinetic_energy</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>41.9212</td>\n",
       "      <td>38.0360</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>11.9108</td>\n",
       "      <td>30.9505</td>\n",
       "      <td>63.2005</td>\n",
       "      <td>192.5211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trajectory_length</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>17.5768</td>\n",
       "      <td>12.1140</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>7.7603</td>\n",
       "      <td>15.5059</td>\n",
       "      <td>25.2653</td>\n",
       "      <td>58.6960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count     mean      std      min      25%  \\\n",
       "particle_id             1,000.0000 500.5000 288.8194   1.0000 250.7500   \n",
       "mass                    1,000.0000   4.9535   2.8922   0.1459   2.4361   \n",
       "initial_velocity_x      1,000.0000   0.0702   2.9219  -4.9678  -2.5893   \n",
       "initial_velocity_y      1,000.0000   0.0241   2.9067  -4.9999  -2.3865   \n",
       "initial_position_x      1,000.0000  -0.1925   5.7298  -9.9869  -5.1620   \n",
       "initial_position_y      1,000.0000  -0.1179   5.7362  -9.9994  -5.1005   \n",
       "charge                  1,000.0000  -0.0080   0.8091  -1.0000  -1.0000   \n",
       "magnetic_field_strength 1,000.0000   1.0462   0.5518   0.1074   0.5624   \n",
       "simulation_time         1,000.0000   5.3997   2.5677   1.0022   3.1719   \n",
       "final_velocity_x        1,000.0000   0.1078   2.9209  -7.0916  -2.2262   \n",
       "final_velocity_y        1,000.0000   0.0166   2.9143  -7.0037  -2.3110   \n",
       "final_position_x        1,000.0000  -0.1503  15.7771 -55.4273  -9.1107   \n",
       "final_position_y        1,000.0000  -0.0439  16.4600 -60.2677  -9.3707   \n",
       "kinetic_energy          1,000.0000  41.9212  38.0360   0.0075  11.9108   \n",
       "trajectory_length       1,000.0000  17.5768  12.1140   0.0513   7.7603   \n",
       "\n",
       "                             50%      75%        max  \n",
       "particle_id             500.5000 750.2500 1,000.0000  \n",
       "mass                      5.0184   7.4688     9.9972  \n",
       "initial_velocity_x        0.1873   2.6047     4.9941  \n",
       "initial_velocity_y        0.0061   2.5910     4.9782  \n",
       "initial_position_x       -0.3144   4.7508     9.9912  \n",
       "initial_position_y       -0.1080   4.7999     9.9550  \n",
       "charge                    0.0000   1.0000     1.0000  \n",
       "magnetic_field_strength   1.0473   1.5370     1.9990  \n",
       "simulation_time           5.3375   7.5665     9.9929  \n",
       "final_velocity_x          0.0838   2.4793     6.9006  \n",
       "final_velocity_y         -0.0523   2.3679     6.5705  \n",
       "final_position_x          0.6150   9.4239    49.6116  \n",
       "final_position_y          0.3257   9.2660    64.4172  \n",
       "kinetic_energy           30.9505  63.2005   192.5211  \n",
       "trajectory_length        15.5059  25.2653    58.6960  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particle_df = load_particle_data(paths)\n",
    "\n",
    "scaler_X, scaler_y = load_scalers(paths)\n",
    "\n",
    "display(Markdown(\"### Particle Data Snapshot\"))\n",
    "\n",
    "display(Markdown(f\"Dataset shape: **{particle_df.shape[0]}** rows × **{particle_df.shape[1]}** columns\"))\n",
    "\n",
    "display(particle_df.head())\n",
    "\n",
    "display(Markdown(\"#### Descriptive Statistics\"))\n",
    "\n",
    "display(particle_df.describe(include=\"all\").transpose())\n",
    "\n",
    "missing_counts = particle_df.isna().sum()\n",
    "\n",
    "if missing_counts.any():\n",
    "    display(Markdown(\"#### Missing Value Audit\"))\n",
    "\n",
    "    display(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c814b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Available Weight Checkpoints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>modified</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>size_readable</th>\n",
       "      <th>is_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model_weights_epoch_0.weights.h5</td>\n",
       "      <td>model_weights_epoch_0.weights.h5</td>\n",
       "      <td>2025-09-30 18:38:19.229242325</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>model_weights_epoch_10.weights.h5</td>\n",
       "      <td>model_weights_epoch_10.weights.h5</td>\n",
       "      <td>2025-09-30 18:38:36.287689686</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>model_weights_epoch_20.weights.h5</td>\n",
       "      <td>model_weights_epoch_20.weights.h5</td>\n",
       "      <td>2025-09-30 18:38:50.502147197</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>model_weights_epoch_30.weights.h5</td>\n",
       "      <td>model_weights_epoch_30.weights.h5</td>\n",
       "      <td>2025-09-30 18:39:05.347838879</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>model_weights_epoch_40.weights.h5</td>\n",
       "      <td>model_weights_epoch_40.weights.h5</td>\n",
       "      <td>2025-09-30 18:39:19.369039297</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>460</td>\n",
       "      <td>model_weights_epoch_460.weights.h5</td>\n",
       "      <td>model_weights_epoch_460.weights.h5</td>\n",
       "      <td>2025-09-30 18:48:46.599674463</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>470</td>\n",
       "      <td>model_weights_epoch_470.weights.h5</td>\n",
       "      <td>model_weights_epoch_470.weights.h5</td>\n",
       "      <td>2025-09-30 18:48:59.908305883</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>480</td>\n",
       "      <td>model_weights_epoch_480.weights.h5</td>\n",
       "      <td>model_weights_epoch_480.weights.h5</td>\n",
       "      <td>2025-09-30 18:49:13.712352037</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>490</td>\n",
       "      <td>model_weights_epoch_490.weights.h5</td>\n",
       "      <td>model_weights_epoch_490.weights.h5</td>\n",
       "      <td>2025-09-30 18:49:26.919478178</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>499</td>\n",
       "      <td>model_weights_epoch_499.weights.h5</td>\n",
       "      <td>model_weights_epoch_499.weights.h5</td>\n",
       "      <td>2025-09-30 18:49:40.416439056</td>\n",
       "      <td>72640</td>\n",
       "      <td>70.9 KB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch                                name  \\\n",
       "0       0    model_weights_epoch_0.weights.h5   \n",
       "1      10   model_weights_epoch_10.weights.h5   \n",
       "2      20   model_weights_epoch_20.weights.h5   \n",
       "3      30   model_weights_epoch_30.weights.h5   \n",
       "4      40   model_weights_epoch_40.weights.h5   \n",
       "..    ...                                 ...   \n",
       "64    460  model_weights_epoch_460.weights.h5   \n",
       "65    470  model_weights_epoch_470.weights.h5   \n",
       "66    480  model_weights_epoch_480.weights.h5   \n",
       "67    490  model_weights_epoch_490.weights.h5   \n",
       "68    499  model_weights_epoch_499.weights.h5   \n",
       "\n",
       "                                  path                      modified  \\\n",
       "0     model_weights_epoch_0.weights.h5 2025-09-30 18:38:19.229242325   \n",
       "1    model_weights_epoch_10.weights.h5 2025-09-30 18:38:36.287689686   \n",
       "2    model_weights_epoch_20.weights.h5 2025-09-30 18:38:50.502147197   \n",
       "3    model_weights_epoch_30.weights.h5 2025-09-30 18:39:05.347838879   \n",
       "4    model_weights_epoch_40.weights.h5 2025-09-30 18:39:19.369039297   \n",
       "..                                 ...                           ...   \n",
       "64  model_weights_epoch_460.weights.h5 2025-09-30 18:48:46.599674463   \n",
       "65  model_weights_epoch_470.weights.h5 2025-09-30 18:48:59.908305883   \n",
       "66  model_weights_epoch_480.weights.h5 2025-09-30 18:49:13.712352037   \n",
       "67  model_weights_epoch_490.weights.h5 2025-09-30 18:49:26.919478178   \n",
       "68  model_weights_epoch_499.weights.h5 2025-09-30 18:49:40.416439056   \n",
       "\n",
       "    size_bytes size_readable  is_latest  \n",
       "0        72640       70.9 KB      False  \n",
       "1        72640       70.9 KB      False  \n",
       "2        72640       70.9 KB      False  \n",
       "3        72640       70.9 KB      False  \n",
       "4        72640       70.9 KB      False  \n",
       "..         ...           ...        ...  \n",
       "64       72640       70.9 KB      False  \n",
       "65       72640       70.9 KB      False  \n",
       "66       72640       70.9 KB      False  \n",
       "67       72640       70.9 KB      False  \n",
       "68       72640       70.9 KB       True  \n",
       "\n",
       "[69 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Loaded checkpoint: **epoch 499** from `model_weights_epoch_499.weights.h5`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "epoch                                             499\n",
       "weights_path       model_weights_epoch_499.weights.h5\n",
       "size_bytes                                      72640\n",
       "size_readable                                 70.9 KB\n",
       "modified                2025-09-30 18:49:40.416439056\n",
       "parameter_count                                  3286\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_index = list_checkpoint_weights(paths)\n",
    "\n",
    "display(Markdown(\"### Available Weight Checkpoints\"))\n",
    "\n",
    "if checkpoint_index.empty:\n",
    "    display(Markdown(\"No checkpoints found. Run training to generate weight artifacts.\"))\n",
    "else:\n",
    "    display(checkpoint_index)\n",
    "\n",
    "model, checkpoint_meta = load_model_checkpoint(paths, model_config, training_config, checkpoint_index)\n",
    "\n",
    "if checkpoint_meta is not None:\n",
    "    display(Markdown(f\"Loaded checkpoint: **epoch {checkpoint_meta['epoch']}** from `{checkpoint_meta['weights_path']}`\"))\n",
    "\n",
    "    display(pd.Series(checkpoint_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Residual Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "samples                256.0000\n",
       "mae                      3.3028\n",
       "rmse                     5.6024\n",
       "residual_norm_median     9.5438\n",
       "residual_norm_p95       25.9245\n",
       "Name: residual_metrics, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Per-Target Residual Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>final_velocity_x</th>\n",
       "      <td>1.0376</td>\n",
       "      <td>1.6686</td>\n",
       "      <td>0.0187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_velocity_y</th>\n",
       "      <td>0.9816</td>\n",
       "      <td>1.5210</td>\n",
       "      <td>0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_x</th>\n",
       "      <td>3.4223</td>\n",
       "      <td>4.7229</td>\n",
       "      <td>0.6597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_y</th>\n",
       "      <td>3.5767</td>\n",
       "      <td>4.7120</td>\n",
       "      <td>-0.5081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kinetic_energy</th>\n",
       "      <td>8.0683</td>\n",
       "      <td>11.0739</td>\n",
       "      <td>-0.6615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trajectory_length</th>\n",
       "      <td>2.7304</td>\n",
       "      <td>4.0102</td>\n",
       "      <td>-0.8742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mae    rmse    bias\n",
       "final_velocity_x  1.0376  1.6686  0.0187\n",
       "final_velocity_y  0.9816  1.5210  0.0450\n",
       "final_position_x  3.4223  4.7229  0.6597\n",
       "final_position_y  3.5767  4.7120 -0.5081\n",
       "kinetic_energy    8.0683 11.0739 -0.6615\n",
       "trajectory_length 2.7304  4.0102 -0.8742"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Residual Sample"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>particle_id</th>\n",
       "      <th>actual_final_velocity_x</th>\n",
       "      <th>pred_final_velocity_x</th>\n",
       "      <th>residual_final_velocity_x</th>\n",
       "      <th>actual_final_velocity_y</th>\n",
       "      <th>pred_final_velocity_y</th>\n",
       "      <th>residual_final_velocity_y</th>\n",
       "      <th>actual_final_position_x</th>\n",
       "      <th>pred_final_position_x</th>\n",
       "      <th>residual_final_position_x</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_final_position_y</th>\n",
       "      <th>residual_final_position_y</th>\n",
       "      <th>actual_kinetic_energy</th>\n",
       "      <th>pred_kinetic_energy</th>\n",
       "      <th>residual_kinetic_energy</th>\n",
       "      <th>actual_trajectory_length</th>\n",
       "      <th>pred_trajectory_length</th>\n",
       "      <th>residual_trajectory_length</th>\n",
       "      <th>residual_norm</th>\n",
       "      <th>residual_norm_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.9367</td>\n",
       "      <td>2.3548</td>\n",
       "      <td>-0.5818</td>\n",
       "      <td>4.8254</td>\n",
       "      <td>4.9024</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>16.4110</td>\n",
       "      <td>16.3485</td>\n",
       "      <td>-0.0626</td>\n",
       "      <td>...</td>\n",
       "      <td>19.1873</td>\n",
       "      <td>-3.4009</td>\n",
       "      <td>117.2113</td>\n",
       "      <td>107.9501</td>\n",
       "      <td>-9.2612</td>\n",
       "      <td>27.5730</td>\n",
       "      <td>25.7147</td>\n",
       "      <td>-1.8583</td>\n",
       "      <td>10.0567</td>\n",
       "      <td>-0.1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.4379</td>\n",
       "      <td>2.2150</td>\n",
       "      <td>-0.2228</td>\n",
       "      <td>-2.4846</td>\n",
       "      <td>-2.2138</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>13.1317</td>\n",
       "      <td>12.5062</td>\n",
       "      <td>-0.6255</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.2250</td>\n",
       "      <td>-0.3850</td>\n",
       "      <td>36.5107</td>\n",
       "      <td>35.4289</td>\n",
       "      <td>-1.0818</td>\n",
       "      <td>13.2583</td>\n",
       "      <td>14.9364</td>\n",
       "      <td>1.6781</td>\n",
       "      <td>2.1561</td>\n",
       "      <td>-1.2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5.0235</td>\n",
       "      <td>-3.5097</td>\n",
       "      <td>-8.5332</td>\n",
       "      <td>-2.0279</td>\n",
       "      <td>2.3111</td>\n",
       "      <td>4.3390</td>\n",
       "      <td>2.4081</td>\n",
       "      <td>5.6124</td>\n",
       "      <td>3.2042</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.6328</td>\n",
       "      <td>2.6693</td>\n",
       "      <td>4.4577</td>\n",
       "      <td>13.5258</td>\n",
       "      <td>9.0680</td>\n",
       "      <td>1.4310</td>\n",
       "      <td>4.9853</td>\n",
       "      <td>3.5543</td>\n",
       "      <td>14.2793</td>\n",
       "      <td>0.3777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>4.4347</td>\n",
       "      <td>-2.8499</td>\n",
       "      <td>-7.2846</td>\n",
       "      <td>-4.7552</td>\n",
       "      <td>0.7821</td>\n",
       "      <td>5.5373</td>\n",
       "      <td>38.0604</td>\n",
       "      <td>8.0618</td>\n",
       "      <td>-29.9985</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.1097</td>\n",
       "      <td>12.6435</td>\n",
       "      <td>78.7841</td>\n",
       "      <td>54.1766</td>\n",
       "      <td>-24.6075</td>\n",
       "      <td>57.0734</td>\n",
       "      <td>33.2629</td>\n",
       "      <td>-23.8106</td>\n",
       "      <td>48.1245</td>\n",
       "      <td>4.7966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.2407</td>\n",
       "      <td>-0.6813</td>\n",
       "      <td>-0.4405</td>\n",
       "      <td>-2.1335</td>\n",
       "      <td>-2.7567</td>\n",
       "      <td>-0.6232</td>\n",
       "      <td>-4.4700</td>\n",
       "      <td>-1.7600</td>\n",
       "      <td>2.7100</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.7032</td>\n",
       "      <td>-0.0278</td>\n",
       "      <td>18.1469</td>\n",
       "      <td>24.9567</td>\n",
       "      <td>6.8098</td>\n",
       "      <td>18.2666</td>\n",
       "      <td>16.5501</td>\n",
       "      <td>-1.7165</td>\n",
       "      <td>7.5662</td>\n",
       "      <td>-0.4988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    particle_id  actual_final_velocity_x  pred_final_velocity_x  \\\n",
       "2             3                   2.9367                 2.3548   \n",
       "3             4                   2.4379                 2.2150   \n",
       "10           11                   5.0235                -3.5097   \n",
       "23           24                   4.4347                -2.8499   \n",
       "25           26                  -0.2407                -0.6813   \n",
       "\n",
       "    residual_final_velocity_x  actual_final_velocity_y  pred_final_velocity_y  \\\n",
       "2                     -0.5818                   4.8254                 4.9024   \n",
       "3                     -0.2228                  -2.4846                -2.2138   \n",
       "10                    -8.5332                  -2.0279                 2.3111   \n",
       "23                    -7.2846                  -4.7552                 0.7821   \n",
       "25                    -0.4405                  -2.1335                -2.7567   \n",
       "\n",
       "    residual_final_velocity_y  actual_final_position_x  pred_final_position_x  \\\n",
       "2                      0.0771                  16.4110                16.3485   \n",
       "3                      0.2708                  13.1317                12.5062   \n",
       "10                     4.3390                   2.4081                 5.6124   \n",
       "23                     5.5373                  38.0604                 8.0618   \n",
       "25                    -0.6232                  -4.4700                -1.7600   \n",
       "\n",
       "    residual_final_position_x  ...  pred_final_position_y  \\\n",
       "2                     -0.0626  ...                19.1873   \n",
       "3                     -0.6255  ...               -15.2250   \n",
       "10                     3.2042  ...                -6.6328   \n",
       "23                   -29.9985  ...               -20.1097   \n",
       "25                     2.7100  ...               -11.7032   \n",
       "\n",
       "    residual_final_position_y  actual_kinetic_energy  pred_kinetic_energy  \\\n",
       "2                     -3.4009               117.2113             107.9501   \n",
       "3                     -0.3850                36.5107              35.4289   \n",
       "10                     2.6693                 4.4577              13.5258   \n",
       "23                    12.6435                78.7841              54.1766   \n",
       "25                    -0.0278                18.1469              24.9567   \n",
       "\n",
       "    residual_kinetic_energy  actual_trajectory_length  pred_trajectory_length  \\\n",
       "2                   -9.2612                   27.5730                 25.7147   \n",
       "3                   -1.0818                   13.2583                 14.9364   \n",
       "10                   9.0680                    1.4310                  4.9853   \n",
       "23                 -24.6075                   57.0734                 33.2629   \n",
       "25                   6.8098                   18.2666                 16.5501   \n",
       "\n",
       "    residual_trajectory_length  residual_norm  residual_norm_z  \n",
       "2                      -1.8583        10.0567          -0.1737  \n",
       "3                       1.6781         2.1561          -1.2052  \n",
       "10                      3.5543        14.2793           0.3777  \n",
       "23                    -23.8106        48.1245           4.7966  \n",
       "25                     -1.7165         7.5662          -0.4988  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals_df, residual_metrics = compute_predictions(model, scaler_X, scaler_y, particle_df)\n",
    "\n",
    "if residual_metrics:\n",
    "    display(Markdown(\"### Residual Metrics\"))\n",
    "\n",
    "    overall_metrics = {key: value for key, value in residual_metrics.items() if key != \"targets\"}\n",
    "\n",
    "    display(pd.Series(overall_metrics, name=\"residual_metrics\"))\n",
    "\n",
    "    target_metrics = pd.DataFrame(residual_metrics[\"targets\"]).transpose()\n",
    "\n",
    "    display(Markdown(\"#### Per-Target Residual Summary\"))\n",
    "\n",
    "    display(target_metrics)\n",
    "\n",
    "if not residuals_df.empty:\n",
    "    display(Markdown(\"### Residual Sample\"))\n",
    "\n",
    "    display(residuals_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Saved loss curves to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\loss_curves.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved train/val gap chart to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\train_val_gap.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved learning-rate diagnostics to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\learning_rate_vs_r2.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved residual histogram to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\residual_norm_hist.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved residual distribution boxplot to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\residual_distribution_by_target.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved correlation heatmap to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\metric_correlation_heatmap.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figures_dir = paths[\"figures_dir\"]\n",
    "\n",
    "# Loss trend\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"train_loss\", ax=ax, label=\"Train Loss\")\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"val_loss\", ax=ax, label=\"Validation Loss\")\n",
    "val_std = results_df[\"val_loss\"].rolling(5, min_periods=1).std()\n",
    "ax.fill_between(results_df[\"epoch\"], results_df[\"val_loss\"] - val_std, results_df[\"val_loss\"] + val_std, color=\"tab:blue\", alpha=0.1)\n",
    "ax.set_title(\"Training vs Validation Loss\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "fig.tight_layout()\n",
    "loss_curve_path = figures_dir / \"loss_curves.png\"\n",
    "fig.savefig(loss_curve_path, dpi=200)\n",
    "plt.close(fig)\n",
    "display(Markdown(f\"Saved loss curves to `{loss_curve_path}`\"))\n",
    "\n",
    "# Train vs validation gap\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"train_val_gap\", ax=ax, color=\"tab:red\")\n",
    "ax.axhline(0, linestyle=\"--\", color=\"grey\", linewidth=1)\n",
    "ax.set_title(\"Train vs Validation Gap\")\n",
    "ax.set_ylabel(\"Val - Train Loss\")\n",
    "fig.tight_layout()\n",
    "gap_plot_path = figures_dir / \"train_val_gap.png\"\n",
    "fig.savefig(gap_plot_path, dpi=200)\n",
    "plt.close(fig)\n",
    "display(Markdown(f\"Saved train/val gap chart to `{gap_plot_path}`\"))\n",
    "\n",
    "# Learning rate vs final loss metrics\n",
    "if not config_history.empty:\n",
    "    lr_df = config_history.copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.scatterplot(data=lr_df, x=\"learning_rate\", y=\"final_r2\", size=\"total_training_time\", hue=\"final_r2\", palette=\"viridis\", ax=ax)\n",
    "    ax.set_title(\"Learning Rate vs Final R²\")\n",
    "    ax.set_xlabel(\"Learning Rate\")\n",
    "    ax.set_ylabel(\"Final R²\")\n",
    "    fig.tight_layout()\n",
    "    lr_plot_path = figures_dir / \"learning_rate_vs_r2.png\"\n",
    "    fig.savefig(lr_plot_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    display(Markdown(f\"Saved learning-rate diagnostics to `{lr_plot_path}`\"))\n",
    "\n",
    "# Residual histogram\n",
    "if not residuals_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.histplot(residuals_df[\"residual_norm\"], bins=30, ax=ax, kde=True, color=\"tab:orange\")\n",
    "    ax.set_title(\"Residual Norm Distribution\")\n",
    "    ax.set_xlabel(\"Residual Norm\")\n",
    "    fig.tight_layout()\n",
    "    residual_hist_path = figures_dir / \"residual_norm_hist.png\"\n",
    "    fig.savefig(residual_hist_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    display(Markdown(f\"Saved residual histogram to `{residual_hist_path}`\"))\n",
    "\n",
    "    residual_columns = [col for col in residuals_df.columns if col.startswith(\"residual_\") and any(col.endswith(target) for target in OUTPUT_TARGETS)]\n",
    "\n",
    "    if residual_columns:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        melted = residuals_df[residual_columns].melt(var_name=\"target\", value_name=\"residual\")\n",
    "        sns.boxplot(data=melted, x=\"target\", y=\"residual\", ax=ax)\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "        ax.set_title(\"Residual Distribution by Target\")\n",
    "        fig.tight_layout()\n",
    "        residual_box_path = figures_dir / \"residual_distribution_by_target.png\"\n",
    "        fig.savefig(residual_box_path, dpi=200)\n",
    "        plt.close(fig)\n",
    "        display(Markdown(f\"Saved residual distribution boxplot to `{residual_box_path}`\"))\n",
    "\n",
    "# Correlation heatmap\n",
    "heatmap_features = [\"train_loss\", \"val_loss\", \"train_mae\", \"val_mae\", \"r2_score\", \"epoch_time\", \"train_val_gap\", \"memory_headroom_mb\"]\n",
    "usable_cols = [col for col in heatmap_features if col in merged_metrics.columns]\n",
    "\n",
    "if usable_cols:\n",
    "    corr_matrix = merged_metrics[usable_cols].corr()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
    "    ax.set_title(\"Metric Correlation Heatmap\")\n",
    "    fig.tight_layout()\n",
    "    heatmap_path = figures_dir / \"metric_correlation_heatmap.png\"\n",
    "    fig.savefig(heatmap_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    display(Markdown(f\"Saved correlation heatmap to `{heatmap_path}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db242ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Recommended Hyperparameter Sweeps"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter</th>\n",
       "      <th>proposed_values</th>\n",
       "      <th>rationale</th>\n",
       "      <th>constraints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_size</td>\n",
       "      <td>[16, 24, 32]</td>\n",
       "      <td>Epoch time and memory logs show headroom; larg...</td>\n",
       "      <td>Validate GPU memory against peak usage before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>epochs</td>\n",
       "      <td>[510, 520]</td>\n",
       "      <td>Best epoch occurs near training ceiling; exten...</td>\n",
       "      <td>Monitor for overfitting; stop early if val los...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    parameter proposed_values  \\\n",
       "0  batch_size    [16, 24, 32]   \n",
       "1      epochs      [510, 520]   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  Epoch time and memory logs show headroom; larg...   \n",
       "1  Best epoch occurs near training ceiling; exten...   \n",
       "\n",
       "                                         constraints  \n",
       "0  Validate GPU memory against peak usage before ...  \n",
       "1  Monitor for overfitting; stop early if val los...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommendations_df = suggest_hyperparameters(model_config, training_config, config_history, results_df)\n",
    "\n",
    "if not recommendations_df.empty:\n",
    "    display(Markdown(\"### Recommended Hyperparameter Sweeps\"))\n",
    "\n",
    "    display(recommendations_df)\n",
    "\n",
    "else:\n",
    "    display(Markdown(\"No immediate hyperparameter adjustments detected beyond current configuration.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb52a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Insight Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Best validation loss 0.1409 at epoch 129."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Validation plateau range over last window: 0.0122."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Train/val gap at final epoch: -0.0140."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Cumulative training time logged: 680.9 seconds."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Mean absolute residual across sampled predictions: 3.3028."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- 95th percentile residual norm: 25.9245."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Hyperparameter sweep targets: batch_size, epochs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "insight_items: List[str] = []\n",
    "\n",
    "if not results_df.empty:\n",
    "    final_row = results_df.iloc[-1]\n",
    "\n",
    "    best_row = results_df.loc[results_df[\"val_loss\"].idxmin()]\n",
    "\n",
    "    insight_items.append(f\"Best validation loss {best_row['val_loss']:.4f} at epoch {int(best_row['epoch'])}.\")\n",
    "\n",
    "    insight_items.append(f\"Validation plateau range over last window: {(results_df.tail(5)['val_loss'].max() - results_df.tail(5)['val_loss'].min()):.4f}.\")\n",
    "\n",
    "    insight_items.append(f\"Train/val gap at final epoch: {final_row['train_val_gap']:.4f}.\")\n",
    "\n",
    "    insight_items.append(f\"Cumulative training time logged: {results_df['epoch_time'].sum():.1f} seconds.\")\n",
    "\n",
    "if residual_metrics:\n",
    "    insight_items.append(f\"Mean absolute residual across sampled predictions: {residual_metrics['mae']:.4f}.\")\n",
    "\n",
    "    insight_items.append(f\"95th percentile residual norm: {residual_metrics['residual_norm_p95']:.4f}.\")\n",
    "\n",
    "if not recommendations_df.empty:\n",
    "    suggested = \", \".join(recommendations_df[\"parameter\"].unique())\n",
    "\n",
    "    insight_items.append(f\"Hyperparameter sweep targets: {suggested}.\")\n",
    "\n",
    "missing_artifacts = artifact_status.loc[~artifact_status[\"exists\"] & artifact_status[\"critical\"]]\n",
    "\n",
    "if not missing_artifacts.empty:\n",
    "    missing_list = \", \".join(missing_artifacts[\"artifact\"].tolist())\n",
    "\n",
    "    insight_items.append(f\"Critical artifacts missing: {missing_list}.\")\n",
    "\n",
    "if not insight_items:\n",
    "    insight_items.append(\"Insufficient data to derive insights.\")\n",
    "\n",
    "display(Markdown(\"### Insight Summary\"))\n",
    "\n",
    "for item in insight_items:\n",
    "    display(Markdown(f\"- {item}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46cd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Validation Checklist"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "critical_artifacts_present     True\n",
       "config_history_entries           21\n",
       "loss_records                  20000\n",
       "results_records                 500\n",
       "residual_samples                256\n",
       "recommendations                   2\n",
       "figures_exported                  6\n",
       "latest_checkpoint_epoch         499\n",
       "Name: notebook_validation, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_notebook_smoke_test() -> Dict[str, Any]:\n",
    "    \"\"\"Validate that core notebook stages complete without exceptions.\"\"\"\n",
    "    status = {\n",
    "        \"critical_artifacts_present\": bool(artifact_status.loc[artifact_status[\"critical\"] & ~artifact_status[\"exists\"]].empty),\n",
    "        \"config_history_entries\": int(len(config_history)),\n",
    "        \"loss_records\": int(len(loss_records)),\n",
    "        \"results_records\": int(len(results_df)),\n",
    "        \"residual_samples\": int(len(residuals_df)),\n",
    "        \"recommendations\": int(len(recommendations_df)),\n",
    "        \"figures_exported\": len(list(paths[\"figures_dir\"].glob(\"*.png\"))),\n",
    "        \"latest_checkpoint_epoch\": int(checkpoint_meta[\"epoch\"]) if checkpoint_meta else None\n",
    "    }\n",
    "\n",
    "    return status\n",
    "\n",
    "\n",
    "smoke_test_status = run_notebook_smoke_test()\n",
    "\n",
    "display(Markdown(\"### Validation Checklist\"))\n",
    "\n",
    "display(pd.Series(smoke_test_status, name=\"notebook_validation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5177634",
   "metadata": {},
   "source": [
    "## Actionable Next Steps\n",
    "\n",
    "- Re-run the training pipeline after trialing the proposed learning-rate, dropout, and batch-size combinations; capture new config snapshots for comparison.\n",
    "- Promote saved figures under `training_output/analysis/figures/` into experiment reports or dashboards.\n",
    "- Extend this notebook with automated sweeps (GridSearch or Bayesian optimization) once additional configuration diversity is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa43bb3",
   "metadata": {},
   "source": [
    "### Reuse Tips\n",
    "\n",
    "- Parameterize `sample_size` within `compute_predictions` to scale residual analysis for larger datasets.\n",
    "- Import this notebook’s helper functions via `%run experiment_analysis_framework.ipynb` inside future analysis notebooks for rapid setup.\n",
    "- Store additional diagnostics (e.g., feature importance, SHAP values) within the `analysis` directory for cross-experiment benchmarking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
