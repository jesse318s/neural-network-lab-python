{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1013747d",
   "metadata": {},
   "source": [
    "# Experiment Analysis Framework\n",
    "\n",
    "This notebook aggregates prior training artifacts from **neural-network-lab-python**, surfaces diagnostic visualizations, and recommends data-driven hyperparameter refinements for future experiments. It is designed to be reusable across training runs with minimal manual setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420c0e6",
   "metadata": {},
   "source": [
    "## Workflow Overview\n",
    "\n",
    "1. Validate the presence of required configs, logs, scalers, and weight checkpoints.\n",
    "2. Load active and historical configuration payloads and align them with training outcomes.\n",
    "3. Ingest `loss_history.csv`, `training_results.csv`, and particle simulation data for analytics.\n",
    "4. Reconstruct the latest model checkpoint, generate predictions, and evaluate residuals.\n",
    "5. Render visual diagnostics (loss curves, learning-rate sweeps, residual histograms, correlation heatmap).\n",
    "6. Summarize run health, recommend hyperparameter sweeps, and capture actionable next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5841ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from advanced_neural_network import AdvancedNeuralNetwork\n",
    "from data_processing import complete_data_pipeline, load_and_validate_data\n",
    "from ml_utils import compute_loss_weights\n",
    "from weight_constraints import BinaryWeightConstraintChanges, BinaryWeightConstraintMax, OscillationDampener\n",
    "\n",
    "pd.options.display.max_rows = 60\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c198bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"neural-network-lab-python\"\n",
    "\n",
    "INPUT_FEATURES = [\n",
    "    \"mass\",\n",
    "    \"initial_velocity_x\",\n",
    "    \"initial_velocity_y\",\n",
    "    \"initial_position_x\",\n",
    "    \"initial_position_y\",\n",
    "    \"charge\",\n",
    "    \"magnetic_field_strength\",\n",
    "    \"simulation_time\"\n",
    "]\n",
    "\n",
    "OUTPUT_TARGETS = [\n",
    "    \"final_velocity_x\",\n",
    "    \"final_velocity_y\",\n",
    "    \"final_position_x\",\n",
    "    \"final_position_y\",\n",
    "    \"kinetic_energy\",\n",
    "    \"trajectory_length\"\n",
    "]\n",
    "\n",
    "ANALYSIS_SEED = 42\n",
    "\n",
    "np.random.seed(ANALYSIS_SEED)\n",
    "tf.random.set_seed(ANALYSIS_SEED)\n",
    "\n",
    "def resolve_project_paths() -> Dict[str, Path]:\n",
    "    \"\"\"Resolve key project directories relative to this notebook.\"\"\"\n",
    "    root = Path.cwd()\n",
    "\n",
    "    if root.name != PROJECT_NAME:\n",
    "        for parent in root.parents:\n",
    "            if parent.name == PROJECT_NAME: root = parent\n",
    "\n",
    "    config_dir = root / \"ml_config\"\n",
    "\n",
    "    output_dir = root / \"training_output\"\n",
    "\n",
    "    analysis_dir = output_dir / \"analysis\"\n",
    "\n",
    "    figures_dir = analysis_dir / \"figures\"\n",
    "\n",
    "    analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return {\n",
    "        \"project_root\": root,\n",
    "        \"config_dir\": config_dir,\n",
    "        \"output_dir\": output_dir,\n",
    "        \"analysis_dir\": analysis_dir,\n",
    "        \"figures_dir\": figures_dir,\n",
    "        \"data_path\": root / \"particle_data.csv\",\n",
    "        \"scaler_X\": root / \"scaler_X.pkl\",\n",
    "        \"scaler_y\": root / \"scaler_y.pkl\"\n",
    "    }\n",
    "\n",
    "def validate_required_artifacts(paths: Dict[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Check presence and metadata of required artifacts.\"\"\"\n",
    "    required = {\n",
    "        \"model_config\": paths[\"config_dir\"] / \"model_config.json\",\n",
    "        \"training_config\": paths[\"config_dir\"] / \"training_config.json\",\n",
    "        \"loss_history\": paths[\"output_dir\"] / \"loss_history.csv\",\n",
    "        \"training_results\": paths[\"output_dir\"] / \"training_results.csv\",\n",
    "        \"configuration_log\": paths[\"output_dir\"] / \"configuration_log.csv\",\n",
    "        \"particle_data\": paths[\"data_path\"],\n",
    "        \"scaler_X\": paths[\"scaler_X\"],\n",
    "        \"scaler_y\": paths[\"scaler_y\"]\n",
    "    }\n",
    "\n",
    "    records: List[Dict[str, Any]] = []\n",
    "\n",
    "    for label, path in required.items():\n",
    "        exists = path.exists()\n",
    "\n",
    "        size = path.stat().st_size if exists else None\n",
    "\n",
    "        records.append({\n",
    "            \"artifact\": label,\n",
    "            \"path\": str(path),\n",
    "            \"exists\": exists,\n",
    "            \"size_bytes\": size\n",
    "        })\n",
    "\n",
    "    status_df = pd.DataFrame(records)\n",
    "\n",
    "    return status_df\n",
    "\n",
    "def list_checkpoint_weights(paths: Dict[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"List available weight checkpoints with epoch metadata.\"\"\"\n",
    "    pattern = \"model_weights_epoch_*.weights.h5\"\n",
    "\n",
    "    checkpoint_files = sorted(paths[\"project_root\"].glob(pattern))\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for file_path in checkpoint_files:\n",
    "        name = file_path.name\n",
    "\n",
    "        parts = name.split(\"_\")\n",
    "\n",
    "        epoch_token = parts[3] if len(parts) > 3 else parts[-1]\n",
    "\n",
    "        epoch = int(epoch_token.replace(\".weights.h5\", \"\")) if epoch_token else None\n",
    "\n",
    "        rows.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"name\": name,\n",
    "            \"path\": str(file_path),\n",
    "            \"modified\": pd.Timestamp(file_path.stat().st_mtime, unit=\"s\"),\n",
    "            \"size_bytes\": file_path.stat().st_size\n",
    "        })\n",
    "\n",
    "    checkpoint_df = pd.DataFrame(rows)\n",
    "\n",
    "    if checkpoint_df.empty: return checkpoint_df\n",
    "\n",
    "    checkpoint_df = checkpoint_df.sort_values(\"epoch\").reset_index(drop=True)\n",
    "\n",
    "    return checkpoint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130eb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configs(paths: Dict[str, Path]) -> Tuple[Dict[str, Any], Dict[str, Any], pd.DataFrame]:\n",
    "    \"\"\"Load active configs and historical configuration snapshots.\"\"\"\n",
    "    model_config_path = paths[\"config_dir\"] / \"model_config.json\"\n",
    "\n",
    "    training_config_path = paths[\"config_dir\"] / \"training_config.json\"\n",
    "\n",
    "    with model_config_path.open() as handle:\n",
    "        model_config = json.load(handle)\n",
    "\n",
    "    with training_config_path.open() as handle:\n",
    "        training_config = json.load(handle)\n",
    "\n",
    "    snapshots: List[Dict[str, Any]] = []\n",
    "\n",
    "    for config_path in sorted(paths[\"output_dir\"].glob(\"training_config_*.json\")):\n",
    "        with config_path.open() as handle:\n",
    "            payload = json.load(handle)\n",
    "\n",
    "        combined: Dict[str, Any] = {\n",
    "            \"config_id\": payload.get(\"config_id\"),\n",
    "            \"timestamp\": payload.get(\"timestamp\")\n",
    "        }\n",
    "\n",
    "        model_payload = payload.get(\"model_config\", {})\n",
    "\n",
    "        for key, value in model_payload.items():\n",
    "            combined[key] = value\n",
    "\n",
    "        training_payload = payload.get(\"training_config\", {})\n",
    "\n",
    "        for key, value in training_payload.items():\n",
    "            combined[f\"train_{key}\"] = value\n",
    "\n",
    "        summary_payload = payload.get(\"performance_summary\", {})\n",
    "\n",
    "        combined[\"best_r2\"] = summary_payload.get(\"best_r2\")\n",
    "        combined[\"final_r2\"] = summary_payload.get(\"current_r2\")\n",
    "        combined[\"best_epoch\"] = summary_payload.get(\"best_r2_epoch\")\n",
    "        combined[\"avg_epoch_time\"] = summary_payload.get(\"avg_epoch_time\")\n",
    "        combined[\"total_training_time\"] = summary_payload.get(\"total_training_time\")\n",
    "        combined[\"weight_modifications_used\"] = summary_payload.get(\"weight_modifications_used\")\n",
    "\n",
    "        snapshots.append(combined)\n",
    "\n",
    "    snapshots_df = pd.DataFrame(snapshots)\n",
    "\n",
    "    if not snapshots_df.empty:\n",
    "        snapshots_df[\"timestamp\"] = pd.to_datetime(snapshots_df[\"timestamp\"])\n",
    "\n",
    "    return model_config, training_config, snapshots_df\n",
    "\n",
    "def load_training_logs(paths: Dict[str, Path]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Load loss history and training results with derived analytics.\"\"\"\n",
    "    loss_path = paths[\"output_dir\"] / \"loss_history.csv\"\n",
    "\n",
    "    results_path = paths[\"output_dir\"] / \"training_results.csv\"\n",
    "\n",
    "    loss_records = pd.read_csv(loss_path)\n",
    "\n",
    "    epoch_summary = (\n",
    "        loss_records.groupby(\"epoch\").agg(\n",
    "            combined_loss_mean=(\"combined_loss\", \"mean\"),\n",
    "            combined_loss_std=(\"combined_loss\", \"std\"),\n",
    "            mae_mean=(\"mae\", \"mean\"),\n",
    "            mse_mean=(\"mse\", \"mean\")\n",
    "        ).reset_index()\n",
    "    )\n",
    "\n",
    "    results_df = pd.read_csv(results_path)\n",
    "\n",
    "    results_df[\"timestamp\"] = pd.to_datetime(results_df[\"timestamp\"])\n",
    "\n",
    "    results_df[\"epoch\"] = results_df[\"epoch\"].astype(int)\n",
    "\n",
    "    results_df[\"val_loss_delta\"] = results_df[\"val_loss\"].diff()\n",
    "\n",
    "    results_df[\"train_val_gap\"] = results_df[\"val_loss\"] - results_df[\"train_loss\"]\n",
    "\n",
    "    merged_metrics = results_df.merge(epoch_summary, on=\"epoch\", how=\"left\")\n",
    "\n",
    "    merged_metrics[\"val_loss_rolling\"] = merged_metrics[\"val_loss\"].rolling(5, min_periods=1).mean()\n",
    "\n",
    "    merged_metrics[\"train_loss_rolling\"] = merged_metrics[\"train_loss\"].rolling(5, min_periods=1).mean()\n",
    "\n",
    "    analytics = {\n",
    "        \"loss_records\": loss_records,\n",
    "        \"epoch_summary\": epoch_summary,\n",
    "        \"results\": results_df,\n",
    "        \"merged_metrics\": merged_metrics\n",
    "    }\n",
    "\n",
    "    return analytics\n",
    "\n",
    "def load_scalers(paths: Dict[str, Path]) -> Tuple[Any, Any]:\n",
    "    \"\"\"Load cached scalers, regenerating them via training pipeline if missing.\"\"\"\n",
    "    scaler_X_path = paths[\"scaler_X\"]\n",
    "\n",
    "    scaler_y_path = paths[\"scaler_y\"]\n",
    "\n",
    "    try:\n",
    "        scaler_X = joblib.load(scaler_X_path)\n",
    "    except FileNotFoundError:\n",
    "        complete_data_pipeline(csv_path=str(paths[\"data_path\"]))\n",
    "\n",
    "        scaler_X = joblib.load(scaler_X_path)\n",
    "\n",
    "    try:\n",
    "        scaler_y = joblib.load(scaler_y_path)\n",
    "    except FileNotFoundError:\n",
    "        complete_data_pipeline(csv_path=str(paths[\"data_path\"]))\n",
    "\n",
    "        scaler_y = joblib.load(scaler_y_path)\n",
    "\n",
    "    return scaler_X, scaler_y\n",
    "\n",
    "def load_particle_data(paths: Dict[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Load particle simulation data with validation safeguards.\"\"\"\n",
    "    dataset = load_and_validate_data(csv_path=str(paths[\"data_path\"]))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "149c0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_from_config(model_config: Dict[str, Any], training_config: Dict[str, Any]) -> tf.keras.Model:\n",
    "    \"\"\"Instantiate a compiled model that mirrors the training setup.\"\"\"\n",
    "    config_payload = dict(model_config)\n",
    "\n",
    "    config_payload.update(training_config)\n",
    "\n",
    "    config_payload.setdefault(\"enable_weight_oscillation_dampener\", True)\n",
    "\n",
    "    input_shape = (len(INPUT_FEATURES),)\n",
    "\n",
    "    output_shape = len(OUTPUT_TARGETS)\n",
    "\n",
    "    network = AdvancedNeuralNetwork(input_shape=input_shape, output_shape=output_shape, config=config_payload)\n",
    "\n",
    "    network.compile_model()\n",
    "\n",
    "    return network.model\n",
    "\n",
    "def load_model_checkpoint(paths: Dict[str, Path], model_config: Dict[str, Any], training_config: Dict[str, Any], checkpoint_index: pd.DataFrame, checkpoint_name: Optional[str] = None) -> Tuple[Optional[tf.keras.Model], Optional[Dict[str, Any]]]:\n",
    "    \"\"\"Load model weights from the selected checkpoint.\"\"\"\n",
    "    if checkpoint_index.empty: return None, None\n",
    "\n",
    "    selected_row = checkpoint_index.iloc[-1] if checkpoint_name is None else checkpoint_index.loc[checkpoint_index[\"name\"] == checkpoint_name].iloc[0]\n",
    "\n",
    "    weights_path = Path(selected_row[\"path\"])\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = build_model_from_config(model_config=model_config, training_config=training_config)\n",
    "\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    metadata = {\n",
    "        \"epoch\": int(selected_row[\"epoch\"]),\n",
    "        \"weights_path\": str(weights_path),\n",
    "        \"size_bytes\": int(selected_row[\"size_bytes\"]),\n",
    "        \"modified\": selected_row[\"modified\"]\n",
    "    }\n",
    "\n",
    "    return model, metadata\n",
    "\n",
    "def compute_predictions(model: Optional[tf.keras.Model], scaler_X: Any, scaler_y: Any, particle_df: pd.DataFrame, sample_size: int = 256) -> Tuple[pd.DataFrame, Dict[str, float]]:\n",
    "    \"\"\"Generate predictions and residual analytics using stored scalers.\"\"\"\n",
    "    if model is None: return pd.DataFrame(), {}\n",
    "\n",
    "    feature_subset = particle_df[INPUT_FEATURES].copy()\n",
    "\n",
    "    if sample_size and len(feature_subset) > sample_size:\n",
    "        feature_subset = feature_subset.sample(sample_size, random_state=ANALYSIS_SEED)\n",
    "\n",
    "    scaled_inputs = scaler_X.transform(feature_subset.values) if scaler_X is not None else feature_subset.values\n",
    "\n",
    "    predictions_scaled = model.predict(scaled_inputs, verbose=0)\n",
    "\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled) if scaler_y is not None else predictions_scaled\n",
    "\n",
    "    actual_outputs = particle_df.loc[feature_subset.index, OUTPUT_TARGETS].values\n",
    "\n",
    "    residuals = predictions - actual_outputs\n",
    "\n",
    "    residual_df = pd.DataFrame(index=feature_subset.index)\n",
    "\n",
    "    if \"particle_id\" in particle_df.columns:\n",
    "        residual_df[\"particle_id\"] = particle_df.loc[feature_subset.index, \"particle_id\"]\n",
    "\n",
    "    for idx, target in enumerate(OUTPUT_TARGETS):\n",
    "        residual_df[f\"actual_{target}\"] = actual_outputs[:, idx]\n",
    "\n",
    "        residual_df[f\"pred_{target}\"] = predictions[:, idx]\n",
    "\n",
    "        residual_df[f\"residual_{target}\"] = residuals[:, idx]\n",
    "\n",
    "    residual_df[\"residual_norm\"] = np.linalg.norm(residuals, axis=1)\n",
    "\n",
    "    mae_value = float(np.mean(np.abs(residuals)))\n",
    "\n",
    "    rmse_value = float(np.sqrt(np.mean(np.square(residuals))))\n",
    "\n",
    "    metrics = {\n",
    "        \"samples\": int(len(residual_df)),\n",
    "        \"mae\": mae_value,\n",
    "        \"rmse\": rmse_value\n",
    "    }\n",
    "\n",
    "    return residual_df, metrics\n",
    "\n",
    "def summarize_run_performance(results_df: pd.DataFrame, epoch_summary: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a concise summary of key performance indicators.\"\"\"\n",
    "    if results_df.empty: return pd.DataFrame()\n",
    "\n",
    "    best_epoch_idx = int(results_df[\"val_loss\"].idxmin())\n",
    "\n",
    "    best_row = results_df.loc[best_epoch_idx]\n",
    "\n",
    "    final_row = results_df.iloc[-1]\n",
    "\n",
    "    early_row = results_df.iloc[0]\n",
    "\n",
    "    improvement = float(early_row[\"val_loss\"] - best_row[\"val_loss\"])\n",
    "\n",
    "    consistency = float(epoch_summary[\"combined_loss_std\"].tail(5).mean()) if not epoch_summary.empty else float(\"nan\")\n",
    "\n",
    "    summary = pd.DataFrame([\n",
    "        {\"metric\": \"Best validation loss\", \"value\": best_row[\"val_loss\"], \"notes\": f\"Epoch {int(best_row['epoch'])}\"},\n",
    "        {\"metric\": \"Final validation loss\", \"value\": final_row[\"val_loss\"], \"notes\": f\"Train gap {final_row['train_val_gap']:.4f}\"},\n",
    "        {\"metric\": \"Validation improvement\", \"value\": improvement, \"notes\": \"Drop from first to best epoch\"},\n",
    "        {\"metric\": \"Validation stability (std last 5 epochs)\", \"value\": consistency, \"notes\": \"Lower is more stable\"},\n",
    "        {\"metric\": \"Average epoch time (last 10 epochs)\", \"value\": results_df[\"epoch_time\"].tail(10).mean(), \"notes\": \"Supports batch-size experiments\"}\n",
    "    ])\n",
    "\n",
    "    return summary\n",
    "\n",
    "def suggest_hyperparameters(model_config: Dict[str, Any], training_config: Dict[str, Any], config_history: pd.DataFrame, results_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Derive hyperparameter sweep recommendations from observed metrics.\"\"\"\n",
    "    if results_df.empty: return pd.DataFrame()\n",
    "\n",
    "    suggestions: List[Dict[str, Any]] = []\n",
    "\n",
    "    base_lr = float(model_config.get(\"learning_rate\", 0.001))\n",
    "\n",
    "    final_window = results_df.tail(5)\n",
    "\n",
    "    val_loss_range = float(final_window[\"val_loss\"].max() - final_window[\"val_loss\"].min())\n",
    "\n",
    "    best_epoch = int(results_df.loc[results_df[\"val_loss\"].idxmin(), \"epoch\"])\n",
    "\n",
    "    final_epoch = int(results_df.iloc[-1][\"epoch\"])\n",
    "\n",
    "    if val_loss_range < 0.01 and final_epoch - best_epoch > 5:\n",
    "        proposals = [round(base_lr * factor, 6) for factor in (0.5, 0.8, 1.2)]\n",
    "\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"learning_rate\",\n",
    "            \"proposed_values\": proposals,\n",
    "            \"rationale\": \"Validation loss plateaued across the last epochs; nudging the optimizer step can reintroduce progress.\",\n",
    "            \"constraints\": \"Keep BinaryWeightConstraintMax(max_binary_digits=5) to preserve numerical stability.\"\n",
    "        })\n",
    "\n",
    "    train_val_gap = float(final_window[\"val_loss\"].mean() - final_window[\"train_loss\"].mean())\n",
    "\n",
    "    if train_val_gap > 0.05:\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"dropout_rate\",\n",
    "            \"proposed_values\": [0.1, 0.15, 0.2],\n",
    "            \"rationale\": \"Consistent validation > training loss points to mild overfitting; light dropout can regularize activations.\",\n",
    "            \"constraints\": \"Ensure enable_weight_oscillation_dampener remains True to counter oscillatory weight updates.\"\n",
    "        })\n",
    "\n",
    "    avg_epoch_time = float(results_df[\"epoch_time\"].tail(10).mean())\n",
    "\n",
    "    if avg_epoch_time < 1.5:\n",
    "        baseline_batch = int(training_config.get(\"batch_size\", 16))\n",
    "\n",
    "        candidate_batches = sorted({baseline_batch, 24, 32})\n",
    "\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"batch_size\",\n",
    "            \"proposed_values\": candidate_batches,\n",
    "            \"rationale\": \"Headroom in epoch time suggests larger batches could reduce gradient noise without memory pressure.\",\n",
    "            \"constraints\": \"Verify GPU memory against recorded peak 361 MB before scaling further.\"\n",
    "        })\n",
    "\n",
    "    if suggestions:\n",
    "        recommendations = pd.DataFrame(suggestions)\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0a3960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Project root:** `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artifact</th>\n",
       "      <th>path</th>\n",
       "      <th>exists</th>\n",
       "      <th>size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_config</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>True</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training_config</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loss_history</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>True</td>\n",
       "      <td>170257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training_results</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>True</td>\n",
       "      <td>11952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>configuration_log</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>True</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>particle_data</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scaler_X</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>True</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scaler_y</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>True</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artifact                                               path  \\\n",
       "0       model_config  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "1    training_config  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "2       loss_history  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "3   training_results  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "4  configuration_log  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "5      particle_data  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "6           scaler_X  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "7           scaler_y  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "\n",
       "   exists  size_bytes  \n",
       "0    True         186  \n",
       "1    True          36  \n",
       "2    True      170257  \n",
       "3    True       11952  \n",
       "4    True         604  \n",
       "5    True        2747  \n",
       "6    True         807  \n",
       "7    True         759  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = resolve_project_paths()\n",
    "\n",
    "display(Markdown(f\"**Project root:** `{paths['project_root']}`\"))\n",
    "\n",
    "artifact_status = validate_required_artifacts(paths)\n",
    "\n",
    "display(artifact_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e8c7438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Active Model Configuration"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hidden_layers                         [64, 32, 16]\n",
       "activation                                    relu\n",
       "optimizer                                     adam\n",
       "learning_rate                               0.0050\n",
       "dropout_rate                                0.0000\n",
       "enable_weight_oscillation_dampener            True\n",
       "Name: model_config, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Active Training Configuration"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "epochs        60\n",
       "batch_size    16\n",
       "Name: training_config, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Historical Configuration Snapshots"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>enable_weight_oscillation_dampener</th>\n",
       "      <th>train_epochs</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>best_r2</th>\n",
       "      <th>final_r2</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>avg_epoch_time</th>\n",
       "      <th>total_training_time</th>\n",
       "      <th>weight_modifications_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training_config_20250929_235603</td>\n",
       "      <td>2025-09-29 23:56:03.826720</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>0.8539</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0948</td>\n",
       "      <td>65.8267</td>\n",
       "      <td>[oscillation_dampening]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training_config_20250929_235859</td>\n",
       "      <td>2025-09-29 23:58:59.524273</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>44</td>\n",
       "      <td>1.1421</td>\n",
       "      <td>68.7918</td>\n",
       "      <td>[oscillation_dampening]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training_config_20250930_000903</td>\n",
       "      <td>2025-09-30 00:09:03.426591</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0550</td>\n",
       "      <td>63.5310</td>\n",
       "      <td>[oscillation_dampening]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         config_id                  timestamp hidden_layers  \\\n",
       "0  training_config_20250929_235603 2025-09-29 23:56:03.826720  [64, 32, 16]   \n",
       "1  training_config_20250929_235859 2025-09-29 23:58:59.524273  [64, 32, 16]   \n",
       "2  training_config_20250930_000903 2025-09-30 00:09:03.426591  [64, 32, 16]   \n",
       "\n",
       "  activation optimizer  learning_rate  dropout_rate  \\\n",
       "0       relu      adam         0.0050        0.0000   \n",
       "1       relu      adam         0.0050        0.0000   \n",
       "2       relu      adam         0.0050        0.0000   \n",
       "\n",
       "   enable_weight_oscillation_dampener  train_epochs  train_batch_size  \\\n",
       "0                                True            60                16   \n",
       "1                                True            60                16   \n",
       "2                                True            60                16   \n",
       "\n",
       "   best_r2  final_r2  best_epoch  avg_epoch_time  total_training_time  \\\n",
       "0   0.8539    0.8432          35          1.0948              65.8267   \n",
       "1   0.8372    0.8145          44          1.1421              68.7918   \n",
       "2   0.8464    0.8326          30          1.0550              63.5310   \n",
       "\n",
       "  weight_modifications_used  \n",
       "0   [oscillation_dampening]  \n",
       "1   [oscillation_dampening]  \n",
       "2   [oscillation_dampening]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config, training_config, config_history = load_configs(paths)\n",
    "\n",
    "display(Markdown(\"### Active Model Configuration\"))\n",
    "\n",
    "display(pd.Series(model_config, name=\"model_config\"))\n",
    "\n",
    "display(Markdown(\"### Active Training Configuration\"))\n",
    "\n",
    "display(pd.Series(training_config, name=\"training_config\"))\n",
    "\n",
    "if not config_history.empty:\n",
    "    display(Markdown(\"### Historical Configuration Snapshots\"))\n",
    "\n",
    "    display(config_history.sort_values(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ba4b5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Epoch-Level Performance Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>epoch_time</th>\n",
       "      <th>memory_mb</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>val_loss_delta</th>\n",
       "      <th>train_val_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>1.0623</td>\n",
       "      <td>361.0898</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>2025-09-30 00:08:53.290409</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.2755</td>\n",
       "      <td>0.4207</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>1.0482</td>\n",
       "      <td>361.2695</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>2025-09-30 00:08:54.369054</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>0.4197</td>\n",
       "      <td>-0.0009</td>\n",
       "      <td>0.0512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>1.0862</td>\n",
       "      <td>361.2930</td>\n",
       "      <td>0.8314</td>\n",
       "      <td>2025-09-30 00:08:55.455266</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>0.1828</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.2909</td>\n",
       "      <td>0.4314</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>1.0535</td>\n",
       "      <td>361.3086</td>\n",
       "      <td>0.8332</td>\n",
       "      <td>2025-09-30 00:08:56.508718</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2783</td>\n",
       "      <td>0.4272</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0346</td>\n",
       "      <td>361.3320</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>2025-09-30 00:08:57.543269</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.1806</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>1.0591</td>\n",
       "      <td>361.3750</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>2025-09-30 00:08:58.602346</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.1683</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0477</td>\n",
       "      <td>361.4375</td>\n",
       "      <td>0.8441</td>\n",
       "      <td>2025-09-30 00:08:59.650084</td>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.1686</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.2755</td>\n",
       "      <td>0.4147</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0548</td>\n",
       "      <td>361.4844</td>\n",
       "      <td>0.8099</td>\n",
       "      <td>2025-09-30 00:09:00.704926</td>\n",
       "      <td>0.1152</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>361.4844</td>\n",
       "      <td>0.8359</td>\n",
       "      <td>2025-09-30 00:09:01.759037</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.2724</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>1.0483</td>\n",
       "      <td>361.4844</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>2025-09-30 00:09:02.807311</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.2818</td>\n",
       "      <td>0.4289</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  epoch_time  memory_mb  r2_score                  timestamp  \\\n",
       "50     50      1.0623   361.0898    0.8390 2025-09-30 00:08:53.290409   \n",
       "51     51      1.0482   361.2695    0.8395 2025-09-30 00:08:54.369054   \n",
       "52     52      1.0862   361.2930    0.8314 2025-09-30 00:08:55.455266   \n",
       "53     53      1.0535   361.3086    0.8332 2025-09-30 00:08:56.508718   \n",
       "54     54      1.0346   361.3320    0.8364 2025-09-30 00:08:57.543269   \n",
       "55     55      1.0591   361.3750    0.8463 2025-09-30 00:08:58.602346   \n",
       "56     56      1.0477   361.4375    0.8441 2025-09-30 00:08:59.650084   \n",
       "57     57      1.0548   361.4844    0.8099 2025-09-30 00:09:00.704926   \n",
       "58     58      1.0541   361.4844    0.8359 2025-09-30 00:09:01.759037   \n",
       "59     59      1.0483   361.4844    0.8326 2025-09-30 00:09:02.807311   \n",
       "\n",
       "    train_loss  train_mae  train_mse  val_loss  val_mae  val_rmse  \\\n",
       "50      0.1231     0.1783     0.0678    0.1770   0.2755    0.4207   \n",
       "51      0.1249     0.1792     0.0705    0.1761   0.2726    0.4197   \n",
       "52      0.1272     0.1828     0.0715    0.1861   0.2909    0.4314   \n",
       "53      0.1260     0.1810     0.0710    0.1825   0.2783    0.4272   \n",
       "54      0.1248     0.1806     0.0689    0.1786   0.2749    0.4227   \n",
       "55      0.1203     0.1743     0.0663    0.1683   0.2649    0.4102   \n",
       "56      0.1161     0.1686     0.0637    0.1720   0.2755    0.4147   \n",
       "57      0.1152     0.1685     0.0619    0.2064   0.2827    0.4543   \n",
       "58      0.1237     0.1780     0.0693    0.1801   0.2724    0.4244   \n",
       "59      0.1160     0.1703     0.0617    0.1840   0.2818    0.4289   \n",
       "\n",
       "    val_loss_delta  train_val_gap  \n",
       "50         -0.0003         0.0539  \n",
       "51         -0.0009         0.0512  \n",
       "52          0.0100         0.0589  \n",
       "53         -0.0036         0.0565  \n",
       "54         -0.0039         0.0539  \n",
       "55         -0.0104         0.0480  \n",
       "56          0.0037         0.0559  \n",
       "57          0.0344         0.0912  \n",
       "58         -0.0262         0.0565  \n",
       "59          0.0038         0.0680  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Key Performance Indicators"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best validation loss</td>\n",
       "      <td>0.1683</td>\n",
       "      <td>Epoch 55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final validation loss</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>Train gap 0.0680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Validation improvement</td>\n",
       "      <td>0.3962</td>\n",
       "      <td>Drop from first to best epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Validation stability (std last 5 epochs)</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>Lower is more stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Average epoch time (last 10 epochs)</td>\n",
       "      <td>1.0549</td>\n",
       "      <td>Supports batch-size experiments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     metric  value  \\\n",
       "0                      Best validation loss 0.1683   \n",
       "1                     Final validation loss 0.1840   \n",
       "2                    Validation improvement 0.3962   \n",
       "3  Validation stability (std last 5 epochs) 0.0248   \n",
       "4       Average epoch time (last 10 epochs) 1.0549   \n",
       "\n",
       "                             notes  \n",
       "0                         Epoch 55  \n",
       "1                 Train gap 0.0680  \n",
       "2    Drop from first to best epoch  \n",
       "3             Lower is more stable  \n",
       "4  Supports batch-size experiments  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analytics = load_training_logs(paths)\n",
    "\n",
    "loss_records = analytics[\"loss_records\"]\n",
    "\n",
    "epoch_summary = analytics[\"epoch_summary\"]\n",
    "\n",
    "results_df = analytics[\"results\"]\n",
    "\n",
    "merged_metrics = analytics[\"merged_metrics\"]\n",
    "\n",
    "display(Markdown(\"### Epoch-Level Performance Summary\"))\n",
    "\n",
    "display(results_df.tail(10))\n",
    "\n",
    "performance_snapshot = summarize_run_performance(results_df, epoch_summary)\n",
    "\n",
    "display(Markdown(\"### Key Performance Indicators\"))\n",
    "\n",
    "display(performance_snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4674f3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded particle data from c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\particle_data.csv (10 particles)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Particle Data Snapshot"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>particle_id</th>\n",
       "      <th>mass</th>\n",
       "      <th>initial_velocity_x</th>\n",
       "      <th>initial_velocity_y</th>\n",
       "      <th>initial_position_x</th>\n",
       "      <th>initial_position_y</th>\n",
       "      <th>charge</th>\n",
       "      <th>magnetic_field_strength</th>\n",
       "      <th>simulation_time</th>\n",
       "      <th>final_velocity_x</th>\n",
       "      <th>final_velocity_y</th>\n",
       "      <th>final_position_x</th>\n",
       "      <th>final_position_y</th>\n",
       "      <th>kinetic_energy</th>\n",
       "      <th>trajectory_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.8079</td>\n",
       "      <td>-4.7942</td>\n",
       "      <td>1.1185</td>\n",
       "      <td>2.1509</td>\n",
       "      <td>-7.5592</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>8.2198</td>\n",
       "      <td>-3.4993</td>\n",
       "      <td>-3.6076</td>\n",
       "      <td>-28.4755</td>\n",
       "      <td>19.5505</td>\n",
       "      <td>48.0940</td>\n",
       "      <td>40.9013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.5121</td>\n",
       "      <td>4.6991</td>\n",
       "      <td>-3.6051</td>\n",
       "      <td>-6.5895</td>\n",
       "      <td>-0.0965</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>1.6710</td>\n",
       "      <td>4.6573</td>\n",
       "      <td>-3.6790</td>\n",
       "      <td>1.3369</td>\n",
       "      <td>-6.3952</td>\n",
       "      <td>167.5366</td>\n",
       "      <td>10.1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.3467</td>\n",
       "      <td>3.3244</td>\n",
       "      <td>-2.0786</td>\n",
       "      <td>-8.6990</td>\n",
       "      <td>-9.3122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>9.8820</td>\n",
       "      <td>3.4632</td>\n",
       "      <td>-2.0477</td>\n",
       "      <td>22.8996</td>\n",
       "      <td>-29.9656</td>\n",
       "      <td>59.4604</td>\n",
       "      <td>37.7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0267</td>\n",
       "      <td>-2.8766</td>\n",
       "      <td>-1.3364</td>\n",
       "      <td>8.9777</td>\n",
       "      <td>8.1864</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>7.9502</td>\n",
       "      <td>-2.7367</td>\n",
       "      <td>-1.2832</td>\n",
       "      <td>-12.8532</td>\n",
       "      <td>-2.3969</td>\n",
       "      <td>27.5301</td>\n",
       "      <td>24.2610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.6446</td>\n",
       "      <td>-3.1818</td>\n",
       "      <td>-0.4393</td>\n",
       "      <td>9.3126</td>\n",
       "      <td>-4.8244</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>2.7884</td>\n",
       "      <td>-2.6453</td>\n",
       "      <td>-0.4595</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>-6.0678</td>\n",
       "      <td>5.9275</td>\n",
       "      <td>8.9675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   particle_id   mass  initial_velocity_x  initial_velocity_y  \\\n",
       "0            1 3.8079             -4.7942              1.1185   \n",
       "1            2 9.5121              4.6991             -3.6051   \n",
       "2            3 7.3467              3.3244             -2.0786   \n",
       "3            4 6.0267             -2.8766             -1.3364   \n",
       "4            5 1.6446             -3.1818             -0.4393   \n",
       "\n",
       "   initial_position_x  initial_position_y  charge  magnetic_field_strength  \\\n",
       "0              2.1509             -7.5592       1                   0.4724   \n",
       "1             -6.5895             -0.0965       0                   0.1859   \n",
       "2             -8.6990             -9.3122       0                   0.7181   \n",
       "3              8.9777              8.1864       0                   0.8385   \n",
       "4              9.3126             -4.8244       0                   0.6156   \n",
       "\n",
       "   simulation_time  final_velocity_x  final_velocity_y  final_position_x  \\\n",
       "0           8.2198           -3.4993           -3.6076          -28.4755   \n",
       "1           1.6710            4.6573           -3.6790            1.3369   \n",
       "2           9.8820            3.4632           -2.0477           22.8996   \n",
       "3           7.9502           -2.7367           -1.2832          -12.8532   \n",
       "4           2.7884           -2.6453           -0.4595            0.4317   \n",
       "\n",
       "   final_position_y  kinetic_energy  trajectory_length  \n",
       "0           19.5505         48.0940            40.9013  \n",
       "1           -6.3952        167.5366            10.1244  \n",
       "2          -29.9656         59.4604            37.7496  \n",
       "3           -2.3969         27.5301            24.2610  \n",
       "4           -6.0678          5.9275             8.9675  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>particle_id</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>5.5000</td>\n",
       "      <td>3.0277</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.2500</td>\n",
       "      <td>5.5000</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>5.2494</td>\n",
       "      <td>3.1271</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>2.1854</td>\n",
       "      <td>6.0389</td>\n",
       "      <td>7.2875</td>\n",
       "      <td>9.5121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_velocity_x</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>-1.0473</td>\n",
       "      <td>3.0237</td>\n",
       "      <td>-4.7942</td>\n",
       "      <td>-3.0936</td>\n",
       "      <td>-2.0226</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>4.6991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_velocity_y</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>-0.9961</td>\n",
       "      <td>2.3386</td>\n",
       "      <td>-4.5355</td>\n",
       "      <td>-2.7721</td>\n",
       "      <td>-0.8878</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>2.8518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_position_x</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>6.8619</td>\n",
       "      <td>-8.6990</td>\n",
       "      <td>-5.9191</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>5.5471</td>\n",
       "      <td>9.3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_position_y</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>-1.9089</td>\n",
       "      <td>5.4081</td>\n",
       "      <td>-9.3122</td>\n",
       "      <td>-5.9333</td>\n",
       "      <td>-1.9311</td>\n",
       "      <td>0.8010</td>\n",
       "      <td>8.1864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charge</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.4830</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magnetic_field_strength</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>0.4193</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.5082</td>\n",
       "      <td>0.6760</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>1.6746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation_time</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>6.2764</td>\n",
       "      <td>3.1645</td>\n",
       "      <td>1.0497</td>\n",
       "      <td>3.9318</td>\n",
       "      <td>7.7512</td>\n",
       "      <td>8.1524</td>\n",
       "      <td>9.8820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_velocity_x</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>-0.9149</td>\n",
       "      <td>2.8501</td>\n",
       "      <td>-3.4993</td>\n",
       "      <td>-2.7138</td>\n",
       "      <td>-2.0649</td>\n",
       "      <td>-0.1479</td>\n",
       "      <td>4.6573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_velocity_y</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>-1.5963</td>\n",
       "      <td>2.2627</td>\n",
       "      <td>-4.3828</td>\n",
       "      <td>-3.5126</td>\n",
       "      <td>-1.6655</td>\n",
       "      <td>-0.4744</td>\n",
       "      <td>3.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_x</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>-5.4057</td>\n",
       "      <td>15.0585</td>\n",
       "      <td>-28.4755</td>\n",
       "      <td>-16.7166</td>\n",
       "      <td>-2.7263</td>\n",
       "      <td>2.5641</td>\n",
       "      <td>22.8996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_y</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>-7.9925</td>\n",
       "      <td>19.6419</td>\n",
       "      <td>-43.0996</td>\n",
       "      <td>-22.4031</td>\n",
       "      <td>-4.2323</td>\n",
       "      <td>4.9310</td>\n",
       "      <td>19.5505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kinetic_energy</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>41.8767</td>\n",
       "      <td>52.2784</td>\n",
       "      <td>0.3406</td>\n",
       "      <td>5.1417</td>\n",
       "      <td>22.1916</td>\n",
       "      <td>56.6188</td>\n",
       "      <td>167.5366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trajectory_length</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>20.6614</td>\n",
       "      <td>15.6147</td>\n",
       "      <td>2.2369</td>\n",
       "      <td>8.2997</td>\n",
       "      <td>17.1927</td>\n",
       "      <td>35.6773</td>\n",
       "      <td>40.9013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count    mean     std      min      25%     50%  \\\n",
       "particle_id             10.0000  5.5000  3.0277   1.0000   3.2500  5.5000   \n",
       "mass                    10.0000  5.2494  3.1271   0.6750   2.1854  6.0389   \n",
       "initial_velocity_x      10.0000 -1.0473  3.0237  -4.7942  -3.0936 -2.0226   \n",
       "initial_velocity_y      10.0000 -0.9961  2.3386  -4.5355  -2.7721 -0.8878   \n",
       "initial_position_x      10.0000  0.1854  6.8619  -8.6990  -5.9191  0.4770   \n",
       "initial_position_y      10.0000 -1.9089  5.4081  -9.3122  -5.9333 -1.9311   \n",
       "charge                  10.0000  0.3000  0.4830   0.0000   0.0000  0.0000   \n",
       "magnetic_field_strength 10.0000  0.7416  0.4193   0.1859   0.5082  0.6760   \n",
       "simulation_time         10.0000  6.2764  3.1645   1.0497   3.9318  7.7512   \n",
       "final_velocity_x        10.0000 -0.9149  2.8501  -3.4993  -2.7138 -2.0649   \n",
       "final_velocity_y        10.0000 -1.5963  2.2627  -4.3828  -3.5126 -1.6655   \n",
       "final_position_x        10.0000 -5.4057 15.0585 -28.4755 -16.7166 -2.7263   \n",
       "final_position_y        10.0000 -7.9925 19.6419 -43.0996 -22.4031 -4.2323   \n",
       "kinetic_energy          10.0000 41.8767 52.2784   0.3406   5.1417 22.1916   \n",
       "trajectory_length       10.0000 20.6614 15.6147   2.2369   8.2997 17.1927   \n",
       "\n",
       "                            75%      max  \n",
       "particle_id              7.7500  10.0000  \n",
       "mass                     7.2875   9.5121  \n",
       "initial_velocity_x       0.0155   4.6991  \n",
       "initial_velocity_y       0.7287   2.8518  \n",
       "initial_position_x       5.5471   9.3126  \n",
       "initial_position_y       0.8010   8.1864  \n",
       "charge                   0.7500   1.0000  \n",
       "magnetic_field_strength  0.8233   1.6746  \n",
       "simulation_time          8.1524   9.8820  \n",
       "final_velocity_x        -0.1479   4.6573  \n",
       "final_velocity_y        -0.4744   3.0004  \n",
       "final_position_x         2.5641  22.8996  \n",
       "final_position_y         4.9310  19.5505  \n",
       "kinetic_energy          56.6188 167.5366  \n",
       "trajectory_length       35.6773  40.9013  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particle_df = load_particle_data(paths)\n",
    "\n",
    "scaler_X, scaler_y = load_scalers(paths)\n",
    "\n",
    "display(Markdown(\"### Particle Data Snapshot\"))\n",
    "\n",
    "display(particle_df.head())\n",
    "\n",
    "display(particle_df.describe(include=\"all\").transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c814b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Available Weight Checkpoints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>modified</th>\n",
       "      <th>size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model_weights_epoch_0.weights.h5</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>2025-09-30 05:08:00.758926153</td>\n",
       "      <td>68880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>model_weights_epoch_10.weights.h5</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>2025-09-30 05:08:11.309141397</td>\n",
       "      <td>68880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>model_weights_epoch_20.weights.h5</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>2025-09-30 05:08:21.791495562</td>\n",
       "      <td>68880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>model_weights_epoch_30.weights.h5</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>2025-09-30 05:08:32.316653490</td>\n",
       "      <td>68880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>model_weights_epoch_40.weights.h5</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>2025-09-30 05:08:42.764005184</td>\n",
       "      <td>68880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>model_weights_epoch_50.weights.h5</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>2025-09-30 05:08:53.320873976</td>\n",
       "      <td>68880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>model_weights_epoch_59.weights.h5</td>\n",
       "      <td>c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...</td>\n",
       "      <td>2025-09-30 05:09:02.842465639</td>\n",
       "      <td>68880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch                               name  \\\n",
       "0      0   model_weights_epoch_0.weights.h5   \n",
       "1     10  model_weights_epoch_10.weights.h5   \n",
       "2     20  model_weights_epoch_20.weights.h5   \n",
       "3     30  model_weights_epoch_30.weights.h5   \n",
       "4     40  model_weights_epoch_40.weights.h5   \n",
       "5     50  model_weights_epoch_50.weights.h5   \n",
       "6     59  model_weights_epoch_59.weights.h5   \n",
       "\n",
       "                                                path  \\\n",
       "0  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "1  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "2  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "3  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "4  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "5  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "6  c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...   \n",
       "\n",
       "                       modified  size_bytes  \n",
       "0 2025-09-30 05:08:00.758926153       68880  \n",
       "1 2025-09-30 05:08:11.309141397       68880  \n",
       "2 2025-09-30 05:08:21.791495562       68880  \n",
       "3 2025-09-30 05:08:32.316653490       68880  \n",
       "4 2025-09-30 05:08:42.764005184       68880  \n",
       "5 2025-09-30 05:08:53.320873976       68880  \n",
       "6 2025-09-30 05:09:02.842465639       68880  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Loaded checkpoint: **epoch 59** from `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\model_weights_epoch_59.weights.h5`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "epoch                                                          59\n",
       "weights_path    c:\\Users\\jesse\\OneDrive\\Documents\\Programming ...\n",
       "size_bytes                                                  68880\n",
       "modified                            2025-09-30 05:09:02.842465639\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_index = list_checkpoint_weights(paths)\n",
    "\n",
    "display(Markdown(\"### Available Weight Checkpoints\"))\n",
    "\n",
    "display(checkpoint_index)\n",
    "\n",
    "model, checkpoint_meta = load_model_checkpoint(paths, model_config, training_config, checkpoint_index)\n",
    "\n",
    "if checkpoint_meta is not None:\n",
    "    display(Markdown(f\"Loaded checkpoint: **epoch {checkpoint_meta['epoch']}** from `{checkpoint_meta['weights_path']}`\"))\n",
    "\n",
    "    display(pd.Series(checkpoint_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e2cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Residual Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "samples   10.0000\n",
       "mae        2.9416\n",
       "rmse       4.9856\n",
       "Name: residual_metrics, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Residual Sample"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>particle_id</th>\n",
       "      <th>actual_final_velocity_x</th>\n",
       "      <th>pred_final_velocity_x</th>\n",
       "      <th>residual_final_velocity_x</th>\n",
       "      <th>actual_final_velocity_y</th>\n",
       "      <th>pred_final_velocity_y</th>\n",
       "      <th>residual_final_velocity_y</th>\n",
       "      <th>actual_final_position_x</th>\n",
       "      <th>pred_final_position_x</th>\n",
       "      <th>residual_final_position_x</th>\n",
       "      <th>actual_final_position_y</th>\n",
       "      <th>pred_final_position_y</th>\n",
       "      <th>residual_final_position_y</th>\n",
       "      <th>actual_kinetic_energy</th>\n",
       "      <th>pred_kinetic_energy</th>\n",
       "      <th>residual_kinetic_energy</th>\n",
       "      <th>actual_trajectory_length</th>\n",
       "      <th>pred_trajectory_length</th>\n",
       "      <th>residual_trajectory_length</th>\n",
       "      <th>residual_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.4993</td>\n",
       "      <td>-1.7679</td>\n",
       "      <td>1.7314</td>\n",
       "      <td>-3.6076</td>\n",
       "      <td>-3.3072</td>\n",
       "      <td>0.3004</td>\n",
       "      <td>-28.4755</td>\n",
       "      <td>-25.9221</td>\n",
       "      <td>2.5535</td>\n",
       "      <td>19.5505</td>\n",
       "      <td>25.0822</td>\n",
       "      <td>5.5317</td>\n",
       "      <td>48.0940</td>\n",
       "      <td>41.3907</td>\n",
       "      <td>-6.7034</td>\n",
       "      <td>40.9013</td>\n",
       "      <td>43.5427</td>\n",
       "      <td>2.6414</td>\n",
       "      <td>9.5979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.6573</td>\n",
       "      <td>4.6524</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>-3.6790</td>\n",
       "      <td>-2.6700</td>\n",
       "      <td>1.0090</td>\n",
       "      <td>1.3369</td>\n",
       "      <td>4.6395</td>\n",
       "      <td>3.3026</td>\n",
       "      <td>-6.3952</td>\n",
       "      <td>-4.9603</td>\n",
       "      <td>1.4349</td>\n",
       "      <td>167.5366</td>\n",
       "      <td>139.4686</td>\n",
       "      <td>-28.0680</td>\n",
       "      <td>10.1244</td>\n",
       "      <td>9.0320</td>\n",
       "      <td>-1.0923</td>\n",
       "      <td>28.3371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.4632</td>\n",
       "      <td>4.2090</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>-2.0477</td>\n",
       "      <td>-2.8503</td>\n",
       "      <td>-0.8026</td>\n",
       "      <td>22.8996</td>\n",
       "      <td>28.1209</td>\n",
       "      <td>5.2212</td>\n",
       "      <td>-29.9656</td>\n",
       "      <td>-34.3307</td>\n",
       "      <td>-4.3651</td>\n",
       "      <td>59.4604</td>\n",
       "      <td>65.4358</td>\n",
       "      <td>5.9755</td>\n",
       "      <td>37.7496</td>\n",
       "      <td>40.4263</td>\n",
       "      <td>2.6767</td>\n",
       "      <td>9.5072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.7367</td>\n",
       "      <td>-2.3808</td>\n",
       "      <td>0.3558</td>\n",
       "      <td>-1.2832</td>\n",
       "      <td>-0.8082</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>-12.8532</td>\n",
       "      <td>-16.2292</td>\n",
       "      <td>-3.3760</td>\n",
       "      <td>-2.3969</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>2.5292</td>\n",
       "      <td>27.5301</td>\n",
       "      <td>29.0890</td>\n",
       "      <td>1.5589</td>\n",
       "      <td>24.2610</td>\n",
       "      <td>26.2540</td>\n",
       "      <td>1.9930</td>\n",
       "      <td>4.9547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-2.6453</td>\n",
       "      <td>-2.3451</td>\n",
       "      <td>0.3002</td>\n",
       "      <td>-0.4595</td>\n",
       "      <td>-0.2851</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>-0.4138</td>\n",
       "      <td>-0.8455</td>\n",
       "      <td>-6.0678</td>\n",
       "      <td>-6.2952</td>\n",
       "      <td>-0.2275</td>\n",
       "      <td>5.9275</td>\n",
       "      <td>9.0566</td>\n",
       "      <td>3.1290</td>\n",
       "      <td>8.9675</td>\n",
       "      <td>7.0576</td>\n",
       "      <td>-1.9099</td>\n",
       "      <td>3.7849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   particle_id  actual_final_velocity_x  pred_final_velocity_x  \\\n",
       "0            1                  -3.4993                -1.7679   \n",
       "1            2                   4.6573                 4.6524   \n",
       "2            3                   3.4632                 4.2090   \n",
       "3            4                  -2.7367                -2.3808   \n",
       "4            5                  -2.6453                -2.3451   \n",
       "\n",
       "   residual_final_velocity_x  actual_final_velocity_y  pred_final_velocity_y  \\\n",
       "0                     1.7314                  -3.6076                -3.3072   \n",
       "1                    -0.0050                  -3.6790                -2.6700   \n",
       "2                     0.7458                  -2.0477                -2.8503   \n",
       "3                     0.3558                  -1.2832                -0.8082   \n",
       "4                     0.3002                  -0.4595                -0.2851   \n",
       "\n",
       "   residual_final_velocity_y  actual_final_position_x  pred_final_position_x  \\\n",
       "0                     0.3004                 -28.4755               -25.9221   \n",
       "1                     1.0090                   1.3369                 4.6395   \n",
       "2                    -0.8026                  22.8996                28.1209   \n",
       "3                     0.4750                 -12.8532               -16.2292   \n",
       "4                     0.1744                   0.4317                -0.4138   \n",
       "\n",
       "   residual_final_position_x  actual_final_position_y  pred_final_position_y  \\\n",
       "0                     2.5535                  19.5505                25.0822   \n",
       "1                     3.3026                  -6.3952                -4.9603   \n",
       "2                     5.2212                 -29.9656               -34.3307   \n",
       "3                    -3.3760                  -2.3969                 0.1324   \n",
       "4                    -0.8455                  -6.0678                -6.2952   \n",
       "\n",
       "   residual_final_position_y  actual_kinetic_energy  pred_kinetic_energy  \\\n",
       "0                     5.5317                48.0940              41.3907   \n",
       "1                     1.4349               167.5366             139.4686   \n",
       "2                    -4.3651                59.4604              65.4358   \n",
       "3                     2.5292                27.5301              29.0890   \n",
       "4                    -0.2275                 5.9275               9.0566   \n",
       "\n",
       "   residual_kinetic_energy  actual_trajectory_length  pred_trajectory_length  \\\n",
       "0                  -6.7034                   40.9013                 43.5427   \n",
       "1                 -28.0680                   10.1244                  9.0320   \n",
       "2                   5.9755                   37.7496                 40.4263   \n",
       "3                   1.5589                   24.2610                 26.2540   \n",
       "4                   3.1290                    8.9675                  7.0576   \n",
       "\n",
       "   residual_trajectory_length  residual_norm  \n",
       "0                      2.6414         9.5979  \n",
       "1                     -1.0923        28.3371  \n",
       "2                      2.6767         9.5072  \n",
       "3                      1.9930         4.9547  \n",
       "4                     -1.9099         3.7849  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals_df, residual_metrics = compute_predictions(model, scaler_X, scaler_y, particle_df)\n",
    "\n",
    "if residual_metrics:\n",
    "    display(Markdown(\"### Residual Metrics\"))\n",
    "\n",
    "    display(pd.Series(residual_metrics, name=\"residual_metrics\"))\n",
    "\n",
    "if not residuals_df.empty:\n",
    "    display(Markdown(\"### Residual Sample\"))\n",
    "\n",
    "    display(residuals_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c36e227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Saved loss curves to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\loss_curves.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved learning-rate diagnostics to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\learning_rate_vs_r2.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved residual histogram to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\residual_norm_hist.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved correlation heatmap to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\metric_correlation_heatmap.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figures_dir = paths[\"figures_dir\"]\n",
    "\n",
    "# Loss trend\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"train_loss\", ax=ax, label=\"Train Loss\")\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"val_loss\", ax=ax, label=\"Validation Loss\")\n",
    "ax.fill_between(results_df[\"epoch\"], results_df[\"val_loss\"] - results_df[\"val_loss\"].rolling(5, min_periods=1).std(), results_df[\"val_loss\"] + results_df[\"val_loss\"].rolling(5, min_periods=1).std(), color=\"tab:blue\", alpha=0.1)\n",
    "ax.set_title(\"Training vs Validation Loss\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "fig.tight_layout()\n",
    "loss_curve_path = figures_dir / \"loss_curves.png\"\n",
    "fig.savefig(loss_curve_path, dpi=200)\n",
    "plt.close(fig)\n",
    "display(Markdown(f\"Saved loss curves to `{loss_curve_path}`\"))\n",
    "\n",
    "# Learning rate vs final loss\n",
    "if not config_history.empty:\n",
    "    lr_df = config_history.copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.scatterplot(data=lr_df, x=\"learning_rate\", y=\"final_r2\", size=\"total_training_time\", hue=\"final_r2\", palette=\"viridis\", ax=ax)\n",
    "    ax.set_title(\"Learning Rate vs Final R²\")\n",
    "    ax.set_xlabel(\"Learning Rate\")\n",
    "    ax.set_ylabel(\"Final R²\")\n",
    "    fig.tight_layout()\n",
    "    lr_plot_path = figures_dir / \"learning_rate_vs_r2.png\"\n",
    "    fig.savefig(lr_plot_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    display(Markdown(f\"Saved learning-rate diagnostics to `{lr_plot_path}`\"))\n",
    "\n",
    "# Residual histogram\n",
    "if not residuals_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.histplot(residuals_df[\"residual_norm\"], bins=30, ax=ax, kde=True, color=\"tab:orange\")\n",
    "    ax.set_title(\"Residual Norm Distribution\")\n",
    "    ax.set_xlabel(\"Residual Norm\")\n",
    "    fig.tight_layout()\n",
    "    residual_hist_path = figures_dir / \"residual_norm_hist.png\"\n",
    "    fig.savefig(residual_hist_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    display(Markdown(f\"Saved residual histogram to `{residual_hist_path}`\"))\n",
    "\n",
    "# Correlation heatmap\n",
    "heatmap_features = [\"train_loss\", \"val_loss\", \"train_mae\", \"val_mae\", \"r2_score\", \"epoch_time\", \"train_val_gap\"]\n",
    "usable_cols = [col for col in heatmap_features if col in merged_metrics.columns]\n",
    "\n",
    "if usable_cols:\n",
    "    corr_matrix = merged_metrics[usable_cols].corr()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
    "    ax.set_title(\"Metric Correlation Heatmap\")\n",
    "    fig.tight_layout()\n",
    "    heatmap_path = figures_dir / \"metric_correlation_heatmap.png\"\n",
    "    fig.savefig(heatmap_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    display(Markdown(f\"Saved correlation heatmap to `{heatmap_path}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db242ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Recommended Hyperparameter Sweeps"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter</th>\n",
       "      <th>proposed_values</th>\n",
       "      <th>rationale</th>\n",
       "      <th>constraints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dropout_rate</td>\n",
       "      <td>[0.1, 0.15, 0.2]</td>\n",
       "      <td>Consistent validation &gt; training loss points t...</td>\n",
       "      <td>Ensure enable_weight_oscillation_dampener rema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_size</td>\n",
       "      <td>[16, 24, 32]</td>\n",
       "      <td>Headroom in epoch time suggests larger batches...</td>\n",
       "      <td>Verify GPU memory against recorded peak 361 MB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      parameter   proposed_values  \\\n",
       "0  dropout_rate  [0.1, 0.15, 0.2]   \n",
       "1    batch_size      [16, 24, 32]   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  Consistent validation > training loss points t...   \n",
       "1  Headroom in epoch time suggests larger batches...   \n",
       "\n",
       "                                         constraints  \n",
       "0  Ensure enable_weight_oscillation_dampener rema...  \n",
       "1  Verify GPU memory against recorded peak 361 MB...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommendations_df = suggest_hyperparameters(model_config, training_config, config_history, results_df)\n",
    "\n",
    "if not recommendations_df.empty:\n",
    "    display(Markdown(\"### Recommended Hyperparameter Sweeps\"))\n",
    "\n",
    "    display(recommendations_df)\n",
    "\n",
    "else:\n",
    "    display(Markdown(\"No immediate hyperparameter adjustments detected beyond current configuration.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48cb52a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Insight Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Best validation loss 0.1683 at epoch 55."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Validation plateau range over last window: 0.0381."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Train/val gap at final epoch: 0.0680."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Mean absolute residual across sampled predictions: 2.9416."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "insight_items: List[str] = []\n",
    "\n",
    "if not results_df.empty:\n",
    "    final_row = results_df.iloc[-1]\n",
    "\n",
    "    best_row = results_df.loc[results_df[\"val_loss\"].idxmin()]\n",
    "\n",
    "    insight_items.append(f\"Best validation loss {best_row['val_loss']:.4f} at epoch {int(best_row['epoch'])}.\")\n",
    "\n",
    "    insight_items.append(f\"Validation plateau range over last window: {(results_df.tail(5)['val_loss'].max() - results_df.tail(5)['val_loss'].min()):.4f}.\")\n",
    "\n",
    "    insight_items.append(f\"Train/val gap at final epoch: {final_row['train_val_gap']:.4f}.\")\n",
    "\n",
    "if residual_metrics:\n",
    "    insight_items.append(f\"Mean absolute residual across sampled predictions: {residual_metrics['mae']:.4f}.\")\n",
    "\n",
    "if not insight_items:\n",
    "    insight_items.append(\"Insufficient data to derive insights.\")\n",
    "\n",
    "display(Markdown(\"### Insight Summary\"))\n",
    "\n",
    "for item in insight_items:\n",
    "    display(Markdown(f\"- {item}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c46cd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Validation Checklist"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "artifacts_present         True\n",
       "config_history_entries       3\n",
       "loss_records              2400\n",
       "results_records             60\n",
       "residual_samples            10\n",
       "recommendations              2\n",
       "Name: notebook_validation, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_notebook_smoke_test() -> Dict[str, Any]:\n",
    "    \"\"\"Validate that core notebook stages complete without exceptions.\"\"\"\n",
    "    status = {\n",
    "        \"artifacts_present\": artifact_status[\"exists\"].all(),\n",
    "        \"config_history_entries\": int(len(config_history)),\n",
    "        \"loss_records\": int(len(loss_records)),\n",
    "        \"results_records\": int(len(results_df)),\n",
    "        \"residual_samples\": int(len(residuals_df)),\n",
    "        \"recommendations\": int(len(recommendations_df))\n",
    "    }\n",
    "\n",
    "    return status\n",
    "\n",
    "smoke_test_status = run_notebook_smoke_test()\n",
    "\n",
    "display(Markdown(\"### Validation Checklist\"))\n",
    "\n",
    "display(pd.Series(smoke_test_status, name=\"notebook_validation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5177634",
   "metadata": {},
   "source": [
    "## Actionable Next Steps\n",
    "\n",
    "- Re-run the training pipeline after trialing the proposed learning-rate, dropout, and batch-size combinations; capture new config snapshots for comparison.\n",
    "- Promote saved figures under `training_output/analysis/figures/` into experiment reports or dashboards.\n",
    "- Extend this notebook with automated sweeps (GridSearch or Bayesian optimization) once additional configuration diversity is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa43bb3",
   "metadata": {},
   "source": [
    "### Reuse Tips\n",
    "\n",
    "- Parameterize `sample_size` within `compute_predictions` to scale residual analysis for larger datasets.\n",
    "- Import this notebook’s helper functions via `%run experiment_analysis_framework.ipynb` inside future analysis notebooks for rapid setup.\n",
    "- Store additional diagnostics (e.g., feature importance, SHAP values) within the `analysis` directory for cross-experiment benchmarking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
