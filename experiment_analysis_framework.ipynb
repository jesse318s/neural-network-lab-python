{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1013747d",
   "metadata": {},
   "source": [
    "# Experiment Analysis Framework\n",
    "\n",
    "This notebook aggregates prior training artifacts from **neural-network-lab-python**, surfaces diagnostic visualizations, and recommends data-driven hyperparameter refinements for future experiments. It is designed to be reusable across training runs with minimal manual setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420c0e6",
   "metadata": {},
   "source": [
    "## Workflow Overview\n",
    "\n",
    "1. Validate the presence of required configs, logs, scalers, and weight checkpoints.\n",
    "2. Load active and historical configuration payloads and align them with training outcomes.\n",
    "3. Ingest `loss_history.csv`, `training_results.csv`, and particle simulation data for analytics.\n",
    "4. Reconstruct the latest model checkpoint, generate predictions, and evaluate residuals.\n",
    "5. Render visual diagnostics (loss curves, learning-rate sweeps, residual histograms, correlation heatmap).\n",
    "6. Summarize run health, recommend hyperparameter sweeps, and capture actionable next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5841ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from advanced_neural_network import AdvancedNeuralNetwork\n",
    "from data_processing import complete_data_pipeline, load_and_validate_data\n",
    "from ml_utils import compute_loss_weights\n",
    "from weight_constraints import BinaryWeightConstraintChanges, BinaryWeightConstraintMax, OscillationDampener\n",
    "\n",
    "pd.options.display.max_rows = 60\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c198bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"neural-network-lab-python\"\n",
    "\n",
    "INPUT_FEATURES = [\n",
    "    \"mass\",\n",
    "    \"initial_velocity_x\",\n",
    "    \"initial_velocity_y\",\n",
    "    \"initial_position_x\",\n",
    "    \"initial_position_y\",\n",
    "    \"charge\",\n",
    "    \"magnetic_field_strength\",\n",
    "    \"simulation_time\"\n",
    "]\n",
    "\n",
    "OUTPUT_TARGETS = [\n",
    "    \"final_velocity_x\",\n",
    "    \"final_velocity_y\",\n",
    "    \"final_position_x\",\n",
    "    \"final_position_y\",\n",
    "    \"kinetic_energy\",\n",
    "    \"trajectory_length\"\n",
    "]\n",
    "\n",
    "ANALYSIS_SEED = 42\n",
    "\n",
    "np.random.seed(ANALYSIS_SEED)\n",
    "tf.random.set_seed(ANALYSIS_SEED)\n",
    "\n",
    "\n",
    "def format_bytes(size: Optional[int]) -> Optional[str]:\n",
    "    \"\"\"Format raw byte counts into human readable text.\"\"\"\n",
    "    if size is None: return None\n",
    "\n",
    "    threshold = 1024.0\n",
    "\n",
    "    units = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\")\n",
    "\n",
    "    value = float(size)\n",
    "\n",
    "    for unit in units:\n",
    "        if value < threshold or unit == units[-1]: return f\"{value:.1f} {unit}\"\n",
    "\n",
    "        value /= threshold\n",
    "\n",
    "\n",
    "def resolve_project_paths() -> Dict[str, Path]:\n",
    "    \"\"\"Resolve key project directories relative to this notebook.\"\"\"\n",
    "    root = Path.cwd()\n",
    "\n",
    "    if root.name != PROJECT_NAME:\n",
    "        for parent in root.parents:\n",
    "            if parent.name == PROJECT_NAME: root = parent\n",
    "\n",
    "    config_dir = root / \"ml_config\"\n",
    "\n",
    "    output_dir = root / \"training_output\"\n",
    "\n",
    "    analysis_dir = output_dir / \"analysis\"\n",
    "\n",
    "    figures_dir = analysis_dir / \"figures\"\n",
    "\n",
    "    analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return {\n",
    "        \"project_root\": root,\n",
    "        \"config_dir\": config_dir,\n",
    "        \"output_dir\": output_dir,\n",
    "        \"analysis_dir\": analysis_dir,\n",
    "        \"figures_dir\": figures_dir,\n",
    "        \"data_path\": root / \"particle_data.csv\",\n",
    "        \"scaler_X\": root / \"scaler_X.pkl\",\n",
    "        \"scaler_y\": root / \"scaler_y.pkl\"\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_required_artifacts(paths: Dict[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Check presence and metadata of required artifacts.\"\"\"\n",
    "    required = {\n",
    "        \"model_config\": paths[\"config_dir\"] / \"model_config.json\",\n",
    "        \"training_config\": paths[\"config_dir\"] / \"training_config.json\",\n",
    "        \"loss_history\": paths[\"output_dir\"] / \"loss_history.csv\",\n",
    "        \"training_results\": paths[\"output_dir\"] / \"training_results.csv\",\n",
    "        \"configuration_log\": paths[\"output_dir\"] / \"configuration_log.csv\",\n",
    "        \"particle_data\": paths[\"data_path\"],\n",
    "        \"scaler_X\": paths[\"scaler_X\"],\n",
    "        \"scaler_y\": paths[\"scaler_y\"]\n",
    "    }\n",
    "\n",
    "    optional = {\n",
    "        \"analysis_dir\": paths[\"analysis_dir\"],\n",
    "        \"figures_dir\": paths[\"figures_dir\"]\n",
    "    }\n",
    "\n",
    "    notes = {\n",
    "        \"particle_data\": \"Regenerate via data pipeline if missing.\",\n",
    "        \"scaler_X\": \"Rebuilt automatically through complete_data_pipeline.\",\n",
    "        \"scaler_y\": \"Rebuilt automatically through complete_data_pipeline.\"\n",
    "    }\n",
    "\n",
    "    records: List[Dict[str, Any]] = []\n",
    "\n",
    "    def append_record(label: str, path: Path, critical: bool) -> None:\n",
    "        exists = path.exists()\n",
    "\n",
    "        size = path.stat().st_size if exists and path.is_file() else None\n",
    "\n",
    "        modified = pd.Timestamp(path.stat().st_mtime, unit=\"s\") if exists else None\n",
    "\n",
    "        records.append({\n",
    "            \"artifact\": label,\n",
    "            \"critical\": critical,\n",
    "            \"exists\": exists,\n",
    "            \"path\": str(path.relative_to(paths[\"project_root\"])) if exists else str(path),\n",
    "            \"size_bytes\": size,\n",
    "            \"size_readable\": format_bytes(size),\n",
    "            \"modified\": modified,\n",
    "            \"note\": notes.get(label)\n",
    "        })\n",
    "\n",
    "    for label, path in required.items():\n",
    "        append_record(label, path, True)\n",
    "\n",
    "    for label, path in optional.items():\n",
    "        append_record(label, path, False)\n",
    "\n",
    "    status_df = pd.DataFrame(records)\n",
    "\n",
    "    if status_df.empty: return status_df\n",
    "\n",
    "    status_df = status_df.sort_values([\"critical\", \"artifact\"], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    return status_df\n",
    "\n",
    "\n",
    "def list_checkpoint_weights(paths: Dict[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"List available weight checkpoints with epoch metadata.\"\"\"\n",
    "    pattern = \"model_weights_epoch_*.weights.h5\"\n",
    "\n",
    "    checkpoint_files = sorted(paths[\"project_root\"].glob(pattern))\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for file_path in checkpoint_files:\n",
    "        name = file_path.name\n",
    "\n",
    "        parts = name.split(\"_\")\n",
    "\n",
    "        epoch_token = parts[3] if len(parts) > 3 else parts[-1]\n",
    "\n",
    "        epoch = int(epoch_token.replace(\".weights.h5\", \"\")) if epoch_token else None\n",
    "\n",
    "        rows.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"name\": name,\n",
    "            \"path\": str(file_path.relative_to(paths[\"project_root\"])) if file_path.exists() else str(file_path),\n",
    "            \"modified\": pd.Timestamp(file_path.stat().st_mtime, unit=\"s\"),\n",
    "            \"size_bytes\": file_path.stat().st_size\n",
    "        })\n",
    "\n",
    "    checkpoint_df = pd.DataFrame(rows)\n",
    "\n",
    "    if checkpoint_df.empty: return checkpoint_df\n",
    "\n",
    "    checkpoint_df = checkpoint_df.sort_values(\"epoch\").reset_index(drop=True)\n",
    "\n",
    "    latest_epoch = checkpoint_df[\"epoch\"].max()\n",
    "\n",
    "    checkpoint_df[\"size_readable\"] = checkpoint_df[\"size_bytes\"].apply(format_bytes)\n",
    "\n",
    "    checkpoint_df[\"is_latest\"] = checkpoint_df[\"epoch\"] == latest_epoch\n",
    "\n",
    "    return checkpoint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130eb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_configs(paths: Dict[str, Path]) -> Tuple[Dict[str, Any], Dict[str, Any], pd.DataFrame]:\n",
    "    \"\"\"Load active configs and historical configuration snapshots with derived metrics.\"\"\"\n",
    "    model_config_path = paths[\"config_dir\"] / \"model_config.json\"\n",
    "\n",
    "    training_config_path = paths[\"config_dir\"] / \"training_config.json\"\n",
    "\n",
    "    with model_config_path.open() as handle:\n",
    "        model_config = json.load(handle)\n",
    "\n",
    "    with training_config_path.open() as handle:\n",
    "        training_config = json.load(handle)\n",
    "\n",
    "    snapshots: List[Dict[str, Any]] = []\n",
    "\n",
    "    for config_path in sorted(paths[\"output_dir\"].glob(\"training_config_*.json\")):\n",
    "        with config_path.open() as handle:\n",
    "            payload = json.load(handle)\n",
    "\n",
    "        combined: Dict[str, Any] = {\n",
    "            \"config_id\": payload.get(\"config_id\"),\n",
    "            \"timestamp\": payload.get(\"timestamp\")\n",
    "        }\n",
    "\n",
    "        model_payload = payload.get(\"model_config\", {})\n",
    "\n",
    "        for key, value in model_payload.items():\n",
    "            combined[key] = value\n",
    "\n",
    "        training_payload = payload.get(\"training_config\", {})\n",
    "\n",
    "        for key, value in training_payload.items():\n",
    "            combined[f\"train_{key}\"] = value\n",
    "\n",
    "        summary_payload = payload.get(\"performance_summary\", {})\n",
    "\n",
    "        combined[\"best_r2\"] = summary_payload.get(\"best_r2\")\n",
    "        combined[\"final_r2\"] = summary_payload.get(\"current_r2\")\n",
    "        combined[\"best_epoch\"] = summary_payload.get(\"best_r2_epoch\")\n",
    "        combined[\"avg_epoch_time_logged\"] = summary_payload.get(\"avg_epoch_time\")\n",
    "        combined[\"total_training_time\"] = summary_payload.get(\"total_training_time\")\n",
    "        combined[\"weight_modifications_used\"] = summary_payload.get(\"weight_modifications_used\")\n",
    "        combined[\"peak_memory_mb\"] = summary_payload.get(\"peak_memory_mb\")\n",
    "\n",
    "        snapshots.append(combined)\n",
    "\n",
    "    snapshots_df = pd.DataFrame(snapshots)\n",
    "\n",
    "    if snapshots_df.empty: return model_config, training_config, snapshots_df\n",
    "\n",
    "    snapshots_df[\"timestamp\"] = pd.to_datetime(snapshots_df[\"timestamp\"])\n",
    "\n",
    "    if {\"total_training_time\", \"train_epochs\"}.issubset(snapshots_df.columns):\n",
    "        snapshots_df[\"avg_epoch_time_calc\"] = snapshots_df[\"total_training_time\"] / snapshots_df[\"train_epochs\"]\n",
    "\n",
    "    snapshots_df[\"r2_delta\"] = snapshots_df[\"best_r2\"] - snapshots_df[\"final_r2\"]\n",
    "\n",
    "    snapshots_df = snapshots_df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    return model_config, training_config, snapshots_df\n",
    "\n",
    "\n",
    "def load_training_logs(paths: Dict[str, Path]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Load loss history and training results with derived analytics.\"\"\"\n",
    "    loss_path = paths[\"output_dir\"] / \"loss_history.csv\"\n",
    "\n",
    "    results_path = paths[\"output_dir\"] / \"training_results.csv\"\n",
    "\n",
    "    loss_records = pd.read_csv(loss_path)\n",
    "\n",
    "    loss_records = loss_records.sort_values([\"epoch\"]).reset_index(drop=True)\n",
    "\n",
    "    loss_records[\"loss_ewm\"] = loss_records[\"combined_loss\"].ewm(alpha=0.15).mean()\n",
    "\n",
    "    epoch_summary = (\n",
    "        loss_records.groupby(\"epoch\").agg(\n",
    "            combined_loss_mean=(\"combined_loss\", \"mean\"),\n",
    "            combined_loss_std=(\"combined_loss\", \"std\"),\n",
    "            mae_mean=(\"mae\", \"mean\"),\n",
    "            mse_mean=(\"mse\", \"mean\")\n",
    "        ).reset_index()\n",
    "    )\n",
    "\n",
    "    results_df = pd.read_csv(results_path)\n",
    "\n",
    "    results_df[\"timestamp\"] = pd.to_datetime(results_df[\"timestamp\"])\n",
    "\n",
    "    results_df = results_df.sort_values(\"epoch\").reset_index(drop=True)\n",
    "\n",
    "    results_df[\"epoch\"] = results_df[\"epoch\"].astype(int)\n",
    "\n",
    "    results_df[\"cumulative_time\"] = results_df[\"epoch_time\"].cumsum()\n",
    "\n",
    "    results_df[\"val_loss_delta\"] = results_df[\"val_loss\"].diff()\n",
    "\n",
    "    results_df[\"train_val_gap\"] = results_df[\"val_loss\"] - results_df[\"train_loss\"]\n",
    "\n",
    "    results_df[\"val_mae_delta\"] = results_df[\"val_mae\"].diff()\n",
    "\n",
    "    results_df[\"epoch_time_rolling\"] = results_df[\"epoch_time\"].rolling(5, min_periods=1).mean()\n",
    "\n",
    "    results_df[\"memory_headroom_mb\"] = results_df[\"memory_mb\"].max() - results_df[\"memory_mb\"]\n",
    "\n",
    "    merged_metrics = results_df.merge(epoch_summary, on=\"epoch\", how=\"left\")\n",
    "\n",
    "    merged_metrics[\"val_loss_rolling\"] = merged_metrics[\"val_loss\"].rolling(5, min_periods=1).mean()\n",
    "\n",
    "    merged_metrics[\"train_loss_rolling\"] = merged_metrics[\"train_loss\"].rolling(5, min_periods=1).mean()\n",
    "\n",
    "    analytics = {\n",
    "        \"loss_records\": loss_records,\n",
    "        \"epoch_summary\": epoch_summary,\n",
    "        \"results\": results_df,\n",
    "        \"merged_metrics\": merged_metrics\n",
    "    }\n",
    "\n",
    "    return analytics\n",
    "\n",
    "\n",
    "def load_scalers(paths: Dict[str, Path]) -> Tuple[Any, Any]:\n",
    "    \"\"\"Load cached scalers, regenerating them via training pipeline if missing.\"\"\"\n",
    "    scaler_X_path = paths[\"scaler_X\"]\n",
    "\n",
    "    scaler_y_path = paths[\"scaler_y\"]\n",
    "\n",
    "    pipeline_ran = False\n",
    "\n",
    "    def ensure_pipeline() -> None:\n",
    "        nonlocal pipeline_ran\n",
    "\n",
    "        if pipeline_ran: return\n",
    "\n",
    "        complete_data_pipeline(csv_path=str(paths[\"data_path\"]))\n",
    "\n",
    "        pipeline_ran = True\n",
    "\n",
    "    try:\n",
    "        scaler_X = joblib.load(scaler_X_path)\n",
    "    except FileNotFoundError:\n",
    "        ensure_pipeline()\n",
    "\n",
    "        scaler_X = joblib.load(scaler_X_path)\n",
    "\n",
    "    try:\n",
    "        scaler_y = joblib.load(scaler_y_path)\n",
    "    except FileNotFoundError:\n",
    "        ensure_pipeline()\n",
    "\n",
    "        scaler_y = joblib.load(scaler_y_path)\n",
    "\n",
    "    return scaler_X, scaler_y\n",
    "\n",
    "\n",
    "def load_particle_data(paths: Dict[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Load particle simulation data with validation safeguards.\"\"\"\n",
    "    dataset = load_and_validate_data(csv_path=str(paths[\"data_path\"]))\n",
    "\n",
    "    if \"particle_id\" in dataset.columns:\n",
    "        dataset = dataset.sort_values(\"particle_id\").reset_index(drop=True)\n",
    "    else:\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149c0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_from_config(model_config: Dict[str, Any], training_config: Dict[str, Any]) -> tf.keras.Model:\n",
    "    \"\"\"Instantiate a compiled model that mirrors the training setup.\"\"\"\n",
    "    config_payload = dict(model_config)\n",
    "\n",
    "    config_payload.update(training_config)\n",
    "\n",
    "    config_payload.setdefault(\"enable_weight_oscillation_dampener\", True)\n",
    "\n",
    "    input_shape = (len(INPUT_FEATURES),)\n",
    "\n",
    "    output_shape = len(OUTPUT_TARGETS)\n",
    "\n",
    "    network = AdvancedNeuralNetwork(input_shape=input_shape, output_shape=output_shape, config=config_payload)\n",
    "\n",
    "    network.compile_model()\n",
    "\n",
    "    return network.model\n",
    "\n",
    "\n",
    "def load_model_checkpoint(paths: Dict[str, Path], model_config: Dict[str, Any], training_config: Dict[str, Any], checkpoint_index: pd.DataFrame, checkpoint_name: Optional[str] = None) -> Tuple[Optional[tf.keras.Model], Optional[Dict[str, Any]]]:\n",
    "    \"\"\"Load model weights from the selected checkpoint.\"\"\"\n",
    "    if checkpoint_index.empty: return None, None\n",
    "\n",
    "    if checkpoint_name is None:\n",
    "        selected_row = checkpoint_index.iloc[-1]\n",
    "    else:\n",
    "        if checkpoint_name not in checkpoint_index[\"name\"].values: return None, None\n",
    "\n",
    "        selected_row = checkpoint_index.loc[checkpoint_index[\"name\"] == checkpoint_name].iloc[0]\n",
    "\n",
    "    weights_path = paths[\"project_root\"] / selected_row[\"path\"]\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = build_model_from_config(model_config=model_config, training_config=training_config)\n",
    "\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    metadata = {\n",
    "        \"epoch\": int(selected_row[\"epoch\"]),\n",
    "        \"weights_path\": str(weights_path.relative_to(paths[\"project_root\"])),\n",
    "        \"size_bytes\": int(selected_row[\"size_bytes\"]),\n",
    "        \"size_readable\": selected_row.get(\"size_readable\"),\n",
    "        \"modified\": selected_row[\"modified\"],\n",
    "        \"parameter_count\": int(model.count_params())\n",
    "    }\n",
    "\n",
    "    return model, metadata\n",
    "\n",
    "\n",
    "def compute_predictions(model: Optional[tf.keras.Model], scaler_X: Any, scaler_y: Any, particle_df: pd.DataFrame, sample_size: int = 256) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Generate predictions and residual analytics using stored scalers.\"\"\"\n",
    "    if model is None: return pd.DataFrame(), {}\n",
    "\n",
    "    feature_subset = particle_df[INPUT_FEATURES].copy()\n",
    "\n",
    "    if sample_size and len(feature_subset) > sample_size:\n",
    "        feature_subset = feature_subset.sample(sample_size, random_state=ANALYSIS_SEED).sort_index()\n",
    "\n",
    "    scaled_inputs = scaler_X.transform(feature_subset.values) if scaler_X is not None else feature_subset.values\n",
    "\n",
    "    predictions_scaled = model.predict(scaled_inputs, verbose=0)\n",
    "\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled) if scaler_y is not None else predictions_scaled\n",
    "\n",
    "    actual_outputs = particle_df.loc[feature_subset.index, OUTPUT_TARGETS].values\n",
    "\n",
    "    residuals = predictions - actual_outputs\n",
    "\n",
    "    residual_df = pd.DataFrame(index=feature_subset.index)\n",
    "\n",
    "    if \"particle_id\" in particle_df.columns:\n",
    "        residual_df[\"particle_id\"] = particle_df.loc[feature_subset.index, \"particle_id\"]\n",
    "\n",
    "    for idx, target in enumerate(OUTPUT_TARGETS):\n",
    "        residual_df[f\"actual_{target}\"] = actual_outputs[:, idx]\n",
    "\n",
    "        residual_df[f\"pred_{target}\"] = predictions[:, idx]\n",
    "\n",
    "        residual_df[f\"residual_{target}\"] = residuals[:, idx]\n",
    "\n",
    "    residual_df[\"residual_norm\"] = np.linalg.norm(residuals, axis=1)\n",
    "\n",
    "    residual_norm_mean = residual_df[\"residual_norm\"].mean()\n",
    "\n",
    "    residual_norm_std = residual_df[\"residual_norm\"].std(ddof=0)\n",
    "\n",
    "    if residual_norm_std and residual_norm_std > 0:\n",
    "        residual_df[\"residual_norm_z\"] = (residual_df[\"residual_norm\"] - residual_norm_mean) / residual_norm_std\n",
    "\n",
    "    mae_value = float(np.mean(np.abs(residuals)))\n",
    "\n",
    "    rmse_value = float(np.sqrt(np.mean(np.square(residuals))))\n",
    "\n",
    "    target_metrics: Dict[str, Dict[str, float]] = {}\n",
    "\n",
    "    for idx, target in enumerate(OUTPUT_TARGETS):\n",
    "        target_residuals = residuals[:, idx]\n",
    "\n",
    "        target_metrics[target] = {\n",
    "            \"mae\": float(np.mean(np.abs(target_residuals))),\n",
    "            \"rmse\": float(np.sqrt(np.mean(np.square(target_residuals)))),\n",
    "            \"bias\": float(np.mean(target_residuals))\n",
    "        }\n",
    "\n",
    "    metrics: Dict[str, Any] = {\n",
    "        \"samples\": int(len(residual_df)),\n",
    "        \"mae\": mae_value,\n",
    "        \"rmse\": rmse_value,\n",
    "        \"residual_norm_median\": float(residual_df[\"residual_norm\"].median()),\n",
    "        \"residual_norm_p95\": float(residual_df[\"residual_norm\"].quantile(0.95)),\n",
    "        \"targets\": target_metrics\n",
    "    }\n",
    "\n",
    "    return residual_df, metrics\n",
    "\n",
    "\n",
    "def summarize_run_performance(results_df: pd.DataFrame, epoch_summary: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create a concise summary of key performance indicators.\"\"\"\n",
    "    if results_df.empty: return pd.DataFrame()\n",
    "\n",
    "    best_epoch_idx = int(results_df[\"val_loss\"].idxmin())\n",
    "\n",
    "    best_row = results_df.loc[best_epoch_idx]\n",
    "\n",
    "    final_row = results_df.iloc[-1]\n",
    "\n",
    "    early_row = results_df.iloc[0]\n",
    "\n",
    "    improvement = float(early_row[\"val_loss\"] - best_row[\"val_loss\"])\n",
    "\n",
    "    consistency = float(epoch_summary[\"combined_loss_std\"].tail(5).mean()) if not epoch_summary.empty else float(\"nan\")\n",
    "\n",
    "    best_r2_row = results_df.loc[results_df[\"r2_score\"].idxmax()]\n",
    "\n",
    "    summary = pd.DataFrame([\n",
    "        {\"metric\": \"Best validation loss\", \"value\": best_row[\"val_loss\"], \"notes\": f\"Epoch {int(best_row['epoch'])}\"},\n",
    "        {\"metric\": \"Final validation loss\", \"value\": final_row[\"val_loss\"], \"notes\": f\"Train gap {final_row['train_val_gap']:.4f}\"},\n",
    "        {\"metric\": \"Validation improvement\", \"value\": improvement, \"notes\": \"Drop from first to best epoch\"},\n",
    "        {\"metric\": \"Validation stability (std last 5 epochs)\", \"value\": consistency, \"notes\": \"Lower is more stable\"},\n",
    "        {\"metric\": \"Average epoch time (last 10 epochs)\", \"value\": results_df[\"epoch_time\"].tail(10).mean(), \"notes\": \"Supports batch-size experiments\"},\n",
    "        {\"metric\": \"Peak R²\", \"value\": best_r2_row[\"r2_score\"], \"notes\": f\"Epoch {int(best_r2_row['epoch'])}\"},\n",
    "        {\"metric\": \"Total recorded training time\", \"value\": results_df[\"epoch_time\"].sum(), \"notes\": \"seconds\"}\n",
    "    ])\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def suggest_hyperparameters(model_config: Dict[str, Any], training_config: Dict[str, Any], config_history: pd.DataFrame, results_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Derive hyperparameter sweep recommendations from observed metrics.\"\"\"\n",
    "    if results_df.empty: return pd.DataFrame()\n",
    "\n",
    "    suggestions: List[Dict[str, Any]] = []\n",
    "\n",
    "    base_lr = float(model_config.get(\"learning_rate\", 0.001))\n",
    "\n",
    "    final_window = results_df.tail(5)\n",
    "\n",
    "    val_loss_range = float(final_window[\"val_loss\"].max() - final_window[\"val_loss\"].min())\n",
    "\n",
    "    best_epoch = int(results_df.loc[results_df[\"val_loss\"].idxmin(), \"epoch\"])\n",
    "\n",
    "    final_epoch = int(results_df.iloc[-1][\"epoch\"])\n",
    "\n",
    "    total_epochs = int(training_config.get(\"epochs\", final_epoch + 1))\n",
    "\n",
    "    if val_loss_range < 0.01 and final_epoch - best_epoch > 5:\n",
    "        proposals = sorted({round(base_lr * factor, 6) for factor in (0.5, 0.8, 1.2)})\n",
    "\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"learning_rate\",\n",
    "            \"proposed_values\": proposals,\n",
    "            \"rationale\": \"Validation loss plateaued across the last epochs; nudge the optimizer step to reintroduce progress.\",\n",
    "            \"constraints\": \"Keep BinaryWeightConstraintMax(max_binary_digits=5) engaged for stability.\"\n",
    "        })\n",
    "\n",
    "    train_val_gap = float(final_window[\"train_val_gap\"].mean())\n",
    "\n",
    "    if train_val_gap > 0.05:\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"dropout_rate\",\n",
    "            \"proposed_values\": [0.05, 0.1, 0.15],\n",
    "            \"rationale\": \"Consistent validation > training loss points to mild overfitting; mild dropout can regularize activations.\",\n",
    "            \"constraints\": \"Retain enable_weight_oscillation_dampener=True to temper weight swings.\"\n",
    "        })\n",
    "\n",
    "    avg_epoch_time = float(results_df[\"epoch_time\"].tail(10).mean())\n",
    "\n",
    "    memory_headroom = float(results_df[\"memory_headroom_mb\"].tail(10).mean())\n",
    "\n",
    "    if avg_epoch_time < 1.5 and memory_headroom > 0:\n",
    "        baseline_batch = int(training_config.get(\"batch_size\", 16))\n",
    "\n",
    "        candidate_batches = sorted({baseline_batch, 24, 32})\n",
    "\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"batch_size\",\n",
    "            \"proposed_values\": candidate_batches,\n",
    "            \"rationale\": \"Epoch time and memory logs show headroom; larger batches could reduce gradient variance.\",\n",
    "            \"constraints\": \"Validate GPU memory against peak usage before committing.\"\n",
    "        })\n",
    "\n",
    "    if final_epoch >= total_epochs - 2:\n",
    "        extension_epochs = sorted({total_epochs + 10, total_epochs + 20})\n",
    "\n",
    "        suggestions.append({\n",
    "            \"parameter\": \"epochs\",\n",
    "            \"proposed_values\": extension_epochs,\n",
    "            \"rationale\": \"Best epoch occurs near training ceiling; extending training may unlock additional gains.\",\n",
    "            \"constraints\": \"Monitor for overfitting; stop early if val loss degrades.\"\n",
    "        })\n",
    "\n",
    "    if not config_history.empty and \"learning_rate\" in config_history.columns:\n",
    "        grouped = config_history.groupby(\"learning_rate\")[\"final_r2\"].mean().sort_values()\n",
    "\n",
    "        if len(grouped) > 1:\n",
    "            top_lr = grouped.idxmax()\n",
    "\n",
    "            if abs(top_lr - base_lr) / base_lr > 0.2:\n",
    "                suggestions.append({\n",
    "                    \"parameter\": \"learning_rate\",\n",
    "                    \"proposed_values\": [round(float(top_lr), 6)],\n",
    "                    \"rationale\": \"Historical sweep points to a different learning rate yielding higher final R².\",\n",
    "                    \"constraints\": \"Pair with BinaryWeightConstraintChanges() to keep update granularity consistent.\"\n",
    "                })\n",
    "\n",
    "    if suggestions:\n",
    "        recommendations = pd.DataFrame(suggestions)\n",
    "\n",
    "        return recommendations.drop_duplicates(subset=[\"parameter\", \"rationale\"])\n",
    "\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e0a3960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Project root:** `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Artifact Inventory"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artifact</th>\n",
       "      <th>critical</th>\n",
       "      <th>exists</th>\n",
       "      <th>path</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>size_readable</th>\n",
       "      <th>modified</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>configuration_log</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\configuration_log.csv</td>\n",
       "      <td>293.0000</td>\n",
       "      <td>293.0 B</td>\n",
       "      <td>2025-09-30 06:38:08.988535643</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loss_history</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\loss_history.csv</td>\n",
       "      <td>170,094.0000</td>\n",
       "      <td>166.1 KB</td>\n",
       "      <td>2025-09-30 06:38:08.999539375</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_config</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ml_config\\model_config.json</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>186.0 B</td>\n",
       "      <td>2025-09-30 06:30:21.232262135</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>particle_data</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>particle_data.csv</td>\n",
       "      <td>251,578.0000</td>\n",
       "      <td>245.7 KB</td>\n",
       "      <td>2025-09-30 06:52:34.713520765</td>\n",
       "      <td>Regenerate via data pipeline if missing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scaler_X</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>scaler_X.pkl</td>\n",
       "      <td>807.0000</td>\n",
       "      <td>807.0 B</td>\n",
       "      <td>2025-09-30 06:37:05.124765158</td>\n",
       "      <td>Rebuilt automatically through complete_data_pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scaler_y</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>scaler_y.pkl</td>\n",
       "      <td>759.0000</td>\n",
       "      <td>759.0 B</td>\n",
       "      <td>2025-09-30 06:37:05.125785350</td>\n",
       "      <td>Rebuilt automatically through complete_data_pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>training_config</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ml_config\\training_config.json</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>36.0 B</td>\n",
       "      <td>2025-09-30 06:31:19.691145182</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>training_results</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\training_results.csv</td>\n",
       "      <td>11,966.0000</td>\n",
       "      <td>11.7 KB</td>\n",
       "      <td>2025-09-30 06:38:08.986529589</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>analysis_dir</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\analysis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-30 07:11:31.113477707</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>figures_dir</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>training_output\\analysis\\figures</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-30 07:11:31.113477707</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artifact  critical  exists                                   path  \\\n",
       "0  configuration_log      True    True  training_output\\configuration_log.csv   \n",
       "1       loss_history      True    True       training_output\\loss_history.csv   \n",
       "2       model_config      True    True            ml_config\\model_config.json   \n",
       "3      particle_data      True    True                      particle_data.csv   \n",
       "4           scaler_X      True    True                           scaler_X.pkl   \n",
       "5           scaler_y      True    True                           scaler_y.pkl   \n",
       "6    training_config      True    True         ml_config\\training_config.json   \n",
       "7   training_results      True    True   training_output\\training_results.csv   \n",
       "8       analysis_dir     False    True               training_output\\analysis   \n",
       "9        figures_dir     False    True       training_output\\analysis\\figures   \n",
       "\n",
       "    size_bytes size_readable                      modified  \\\n",
       "0     293.0000       293.0 B 2025-09-30 06:38:08.988535643   \n",
       "1 170,094.0000      166.1 KB 2025-09-30 06:38:08.999539375   \n",
       "2     186.0000       186.0 B 2025-09-30 06:30:21.232262135   \n",
       "3 251,578.0000      245.7 KB 2025-09-30 06:52:34.713520765   \n",
       "4     807.0000       807.0 B 2025-09-30 06:37:05.124765158   \n",
       "5     759.0000       759.0 B 2025-09-30 06:37:05.125785350   \n",
       "6      36.0000        36.0 B 2025-09-30 06:31:19.691145182   \n",
       "7  11,966.0000       11.7 KB 2025-09-30 06:38:08.986529589   \n",
       "8          NaN          None 2025-09-30 07:11:31.113477707   \n",
       "9          NaN          None 2025-09-30 07:11:31.113477707   \n",
       "\n",
       "                                                note  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3           Regenerate via data pipeline if missing.  \n",
       "4  Rebuilt automatically through complete_data_pi...  \n",
       "5  Rebuilt automatically through complete_data_pi...  \n",
       "6                                               None  \n",
       "7                                               None  \n",
       "8                                               None  \n",
       "9                                               None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "✅ All critical artifacts are present."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = resolve_project_paths()\n",
    "\n",
    "display(Markdown(f\"**Project root:** `{paths['project_root']}`\"))\n",
    "\n",
    "artifact_status = validate_required_artifacts(paths)\n",
    "\n",
    "display(Markdown(\"### Artifact Inventory\"))\n",
    "\n",
    "display(artifact_status)\n",
    "\n",
    "missing_artifacts = artifact_status.loc[~artifact_status[\"exists\"]]\n",
    "\n",
    "if not missing_artifacts.empty:\n",
    "    display(Markdown(\"⚠️ **Missing artifacts detected. Review notes before continuing.**\"))\n",
    "\n",
    "    display(missing_artifacts)\n",
    "else:\n",
    "    display(Markdown(\"✅ All critical artifacts are present.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e8c7438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Active Model Configuration"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hidden_layers                         [64, 32, 16]\n",
       "activation                                    relu\n",
       "optimizer                                     adam\n",
       "learning_rate                               0.0050\n",
       "dropout_rate                                0.0000\n",
       "enable_weight_oscillation_dampener            True\n",
       "Name: model_config, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Active Training Configuration"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "epochs        60\n",
       "batch_size    16\n",
       "Name: training_config, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Historical Configuration Snapshots"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>config_id</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>train_epochs</th>\n",
       "      <th>best_r2</th>\n",
       "      <th>final_r2</th>\n",
       "      <th>r2_delta</th>\n",
       "      <th>avg_epoch_time_logged</th>\n",
       "      <th>avg_epoch_time_calc</th>\n",
       "      <th>total_training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-30 01:38:08.986529</td>\n",
       "      <td>training_config_20250930_013808</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>1.0383</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>62.4201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp                        config_id  learning_rate  \\\n",
       "0 2025-09-30 01:38:08.986529  training_config_20250930_013808         0.0050   \n",
       "\n",
       "   dropout_rate  train_batch_size  train_epochs  best_r2  final_r2  r2_delta  \\\n",
       "0        0.0000                16            60   0.8562    0.8506    0.0056   \n",
       "\n",
       "   avg_epoch_time_logged  avg_epoch_time_calc  total_training_time  \n",
       "0                 1.0383               1.0403              62.4201  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Configuration Summary Statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_rate</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_batch_size</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_epochs</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>60.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_r2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.8562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_r2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.8506</td>\n",
       "      <td>0.8506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_delta</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_epoch_time_logged</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0383</td>\n",
       "      <td>1.0383</td>\n",
       "      <td>1.0383</td>\n",
       "      <td>1.0383</td>\n",
       "      <td>1.0383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_epoch_time_calc</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>1.0403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_training_time</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>62.4201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.4201</td>\n",
       "      <td>62.4201</td>\n",
       "      <td>62.4201</td>\n",
       "      <td>62.4201</td>\n",
       "      <td>62.4201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count    mean  std     min     25%     50%     75%  \\\n",
       "learning_rate         1.0000  0.0050  NaN  0.0050  0.0050  0.0050  0.0050   \n",
       "dropout_rate          1.0000  0.0000  NaN  0.0000  0.0000  0.0000  0.0000   \n",
       "train_batch_size      1.0000 16.0000  NaN 16.0000 16.0000 16.0000 16.0000   \n",
       "train_epochs          1.0000 60.0000  NaN 60.0000 60.0000 60.0000 60.0000   \n",
       "best_r2               1.0000  0.8562  NaN  0.8562  0.8562  0.8562  0.8562   \n",
       "final_r2              1.0000  0.8506  NaN  0.8506  0.8506  0.8506  0.8506   \n",
       "r2_delta              1.0000  0.0056  NaN  0.0056  0.0056  0.0056  0.0056   \n",
       "avg_epoch_time_logged 1.0000  1.0383  NaN  1.0383  1.0383  1.0383  1.0383   \n",
       "avg_epoch_time_calc   1.0000  1.0403  NaN  1.0403  1.0403  1.0403  1.0403   \n",
       "total_training_time   1.0000 62.4201  NaN 62.4201 62.4201 62.4201 62.4201   \n",
       "\n",
       "                          max  \n",
       "learning_rate          0.0050  \n",
       "dropout_rate           0.0000  \n",
       "train_batch_size      16.0000  \n",
       "train_epochs          60.0000  \n",
       "best_r2                0.8562  \n",
       "final_r2               0.8506  \n",
       "r2_delta               0.0056  \n",
       "avg_epoch_time_logged  1.0383  \n",
       "avg_epoch_time_calc    1.0403  \n",
       "total_training_time   62.4201  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config, training_config, config_history = load_configs(paths)\n",
    "\n",
    "display(Markdown(\"### Active Model Configuration\"))\n",
    "\n",
    "display(pd.Series(model_config, name=\"model_config\"))\n",
    "\n",
    "display(Markdown(\"### Active Training Configuration\"))\n",
    "\n",
    "display(pd.Series(training_config, name=\"training_config\"))\n",
    "\n",
    "if not config_history.empty:\n",
    "    display(Markdown(\"### Historical Configuration Snapshots\"))\n",
    "\n",
    "    history_columns = [\n",
    "        col\n",
    "        for col in [\n",
    "            \"timestamp\", \"config_id\", \"learning_rate\", \"dropout_rate\", \"train_batch_size\", \"train_epochs\", \"best_r2\", \"final_r2\", \"r2_delta\", \"avg_epoch_time_logged\", \"avg_epoch_time_calc\", \"total_training_time\"\n",
    "        ]\n",
    "        if col in config_history.columns\n",
    "    ]\n",
    "\n",
    "    display(config_history[history_columns])\n",
    "\n",
    "    numeric_cols = [col for col in history_columns if config_history[col].dtype.kind in \"if\"]\n",
    "\n",
    "    if numeric_cols:\n",
    "        history_stats = config_history[numeric_cols].describe().transpose()\n",
    "\n",
    "        display(Markdown(\"#### Configuration Summary Statistics\"))\n",
    "\n",
    "        display(history_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ba4b5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Epoch-Level Performance Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_val_gap</th>\n",
       "      <th>val_loss_delta</th>\n",
       "      <th>epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>1.0307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>1.0466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.1722</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>1.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>1.0407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>1.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.1682</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>1.0297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>1.0284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>-0.0085</td>\n",
       "      <td>1.0294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>1.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>-0.0058</td>\n",
       "      <td>1.0273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  train_val_gap  val_loss_delta  epoch_time\n",
       "50     50      0.1316    0.1735         0.0419         -0.0013      1.0307\n",
       "51     51      0.1276    0.1752         0.0476          0.0016      1.0466\n",
       "52     52      0.1251    0.1722         0.0471         -0.0029      1.0700\n",
       "53     53      0.1229    0.1708         0.0480         -0.0014      1.0407\n",
       "54     54      0.1254    0.1708         0.0454         -0.0001      1.0258\n",
       "55     55      0.1199    0.1682         0.0483         -0.0026      1.0297\n",
       "56     56      0.1200    0.1730         0.0530          0.0048      1.0284\n",
       "57     57      0.1241    0.1645         0.0404         -0.0085      1.0294\n",
       "58     58      0.1213    0.1724         0.0511          0.0079      1.0308\n",
       "59     59      0.1232    0.1666         0.0435         -0.0058      1.0273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Key Performance Indicators"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best validation loss</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>Epoch 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final validation loss</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>Train gap 0.0435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Validation improvement</td>\n",
       "      <td>0.6107</td>\n",
       "      <td>Drop from first to best epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Validation stability (std last 5 epochs)</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>Lower is more stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Average epoch time (last 10 epochs)</td>\n",
       "      <td>1.0360</td>\n",
       "      <td>Supports batch-size experiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peak R²</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>Epoch 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Total recorded training time</td>\n",
       "      <td>62.2994</td>\n",
       "      <td>seconds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     metric   value  \\\n",
       "0                      Best validation loss  0.1598   \n",
       "1                     Final validation loss  0.1666   \n",
       "2                    Validation improvement  0.6107   \n",
       "3  Validation stability (std last 5 epochs)  0.0267   \n",
       "4       Average epoch time (last 10 epochs)  1.0360   \n",
       "5                                   Peak R²  0.8562   \n",
       "6              Total recorded training time 62.2994   \n",
       "\n",
       "                             notes  \n",
       "0                         Epoch 30  \n",
       "1                 Train gap 0.0435  \n",
       "2    Drop from first to best epoch  \n",
       "3             Lower is more stable  \n",
       "4  Supports batch-size experiments  \n",
       "5                         Epoch 30  \n",
       "6                          seconds  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Loss Distribution by Epoch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>combined_loss_mean</th>\n",
       "      <th>combined_loss_std</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mse_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.1877</td>\n",
       "      <td>0.0755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.1817</td>\n",
       "      <td>0.0734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.0718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>0.0695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>0.0710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.0678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.0666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>0.0684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.1753</td>\n",
       "      <td>0.0673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.0684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  combined_loss_mean  combined_loss_std  mae_mean  mse_mean\n",
       "49     49              0.1316             0.0270    0.1877    0.0755\n",
       "50     50              0.1276             0.0275    0.1817    0.0734\n",
       "51     51              0.1251             0.0296    0.1784    0.0718\n",
       "52     52              0.1229             0.0296    0.1763    0.0695\n",
       "53     53              0.1254             0.0219    0.1798    0.0710\n",
       "54     54              0.1199             0.0254    0.1721    0.0678\n",
       "55     55              0.1200             0.0252    0.1733    0.0666\n",
       "56     56              0.1241             0.0279    0.1798    0.0684\n",
       "57     57              0.1213             0.0255    0.1753    0.0673\n",
       "58     58              0.1232             0.0295    0.1779    0.0684"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Exponential Moving Average of Combined Loss"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>combined_loss</th>\n",
       "      <th>loss_ewm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>0.1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>58</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>58</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      epoch  combined_loss  loss_ewm\n",
       "2390     58         0.1508    0.1344\n",
       "2391     58         0.1288    0.1335\n",
       "2392     58         0.1299    0.1330\n",
       "2393     58         0.1138    0.1301\n",
       "2394     58         0.0981    0.1253\n",
       "2395     58         0.1148    0.1237\n",
       "2396     58         0.1348    0.1254\n",
       "2397     58         0.1053    0.1224\n",
       "2398     58         0.1068    0.1201\n",
       "2399     58         0.1730    0.1280"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analytics = load_training_logs(paths)\n",
    "\n",
    "loss_records = analytics[\"loss_records\"]\n",
    "\n",
    "epoch_summary = analytics[\"epoch_summary\"]\n",
    "\n",
    "results_df = analytics[\"results\"]\n",
    "\n",
    "merged_metrics = analytics[\"merged_metrics\"]\n",
    "\n",
    "display(Markdown(\"### Epoch-Level Performance Summary\"))\n",
    "\n",
    "display(results_df.tail(10)[[\"epoch\", \"train_loss\", \"val_loss\", \"train_val_gap\", \"val_loss_delta\", \"epoch_time\"]])\n",
    "\n",
    "performance_snapshot = summarize_run_performance(results_df, epoch_summary)\n",
    "\n",
    "display(Markdown(\"### Key Performance Indicators\"))\n",
    "\n",
    "display(performance_snapshot)\n",
    "\n",
    "display(Markdown(\"#### Loss Distribution by Epoch\"))\n",
    "\n",
    "display(epoch_summary.tail(10))\n",
    "\n",
    "display(Markdown(\"#### Exponential Moving Average of Combined Loss\"))\n",
    "\n",
    "display(loss_records.tail(10)[[\"epoch\", \"combined_loss\", \"loss_ewm\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4674f3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded particle data from c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\particle_data.csv (1000 particles)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Particle Data Snapshot"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Dataset shape: **1000** rows × **15** columns"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>particle_id</th>\n",
       "      <th>mass</th>\n",
       "      <th>initial_velocity_x</th>\n",
       "      <th>initial_velocity_y</th>\n",
       "      <th>initial_position_x</th>\n",
       "      <th>initial_position_y</th>\n",
       "      <th>charge</th>\n",
       "      <th>magnetic_field_strength</th>\n",
       "      <th>simulation_time</th>\n",
       "      <th>final_velocity_x</th>\n",
       "      <th>final_velocity_y</th>\n",
       "      <th>final_position_x</th>\n",
       "      <th>final_position_y</th>\n",
       "      <th>kinetic_energy</th>\n",
       "      <th>trajectory_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.8079</td>\n",
       "      <td>-3.1487</td>\n",
       "      <td>-2.3829</td>\n",
       "      <td>3.4541</td>\n",
       "      <td>1.4399</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2939</td>\n",
       "      <td>3.6656</td>\n",
       "      <td>1.2294</td>\n",
       "      <td>-3.7246</td>\n",
       "      <td>-9.4442</td>\n",
       "      <td>1.1308</td>\n",
       "      <td>29.2917</td>\n",
       "      <td>12.9020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.5121</td>\n",
       "      <td>0.4190</td>\n",
       "      <td>-2.5302</td>\n",
       "      <td>5.9336</td>\n",
       "      <td>6.1086</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>6.1506</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>-2.3032</td>\n",
       "      <td>6.4958</td>\n",
       "      <td>-10.2526</td>\n",
       "      <td>29.9911</td>\n",
       "      <td>16.3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.3467</td>\n",
       "      <td>3.7295</td>\n",
       "      <td>4.0625</td>\n",
       "      <td>-4.9906</td>\n",
       "      <td>5.2032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3007</td>\n",
       "      <td>4.9767</td>\n",
       "      <td>2.9367</td>\n",
       "      <td>4.8254</td>\n",
       "      <td>16.4110</td>\n",
       "      <td>22.5882</td>\n",
       "      <td>117.2113</td>\n",
       "      <td>27.5730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0267</td>\n",
       "      <td>2.3222</td>\n",
       "      <td>-2.5045</td>\n",
       "      <td>2.4975</td>\n",
       "      <td>-6.9220</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6444</td>\n",
       "      <td>4.1205</td>\n",
       "      <td>2.4379</td>\n",
       "      <td>-2.4846</td>\n",
       "      <td>13.1317</td>\n",
       "      <td>-14.8400</td>\n",
       "      <td>36.5107</td>\n",
       "      <td>13.2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.6446</td>\n",
       "      <td>3.0656</td>\n",
       "      <td>-2.2805</td>\n",
       "      <td>1.4349</td>\n",
       "      <td>-7.0150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1996</td>\n",
       "      <td>7.7181</td>\n",
       "      <td>1.1290</td>\n",
       "      <td>-3.5859</td>\n",
       "      <td>-1.5585</td>\n",
       "      <td>-5.7997</td>\n",
       "      <td>11.6218</td>\n",
       "      <td>3.2307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   particle_id   mass  initial_velocity_x  initial_velocity_y  \\\n",
       "0            1 3.8079             -3.1487             -2.3829   \n",
       "1            2 9.5121              0.4190             -2.5302   \n",
       "2            3 7.3467              3.7295              4.0625   \n",
       "3            4 6.0267              2.3222             -2.5045   \n",
       "4            5 1.6446              3.0656             -2.2805   \n",
       "\n",
       "   initial_position_x  initial_position_y  charge  magnetic_field_strength  \\\n",
       "0              3.4541              1.4399       1                   1.2939   \n",
       "1              5.9336              6.1086       1                   0.4498   \n",
       "2             -4.9906              5.2032       1                   0.3007   \n",
       "3              2.4975             -6.9220       0                   1.6444   \n",
       "4              1.4349             -7.0150       1                   1.1996   \n",
       "\n",
       "   simulation_time  final_velocity_x  final_velocity_y  final_position_x  \\\n",
       "0           3.6656            1.2294           -3.7246           -9.4442   \n",
       "1           6.1506            1.0007           -2.3032            6.4958   \n",
       "2           4.9767            2.9367            4.8254           16.4110   \n",
       "3           4.1205            2.4379           -2.4846           13.1317   \n",
       "4           7.7181            1.1290           -3.5859           -1.5585   \n",
       "\n",
       "   final_position_y  kinetic_energy  trajectory_length  \n",
       "0            1.1308         29.2917            12.9020  \n",
       "1          -10.2526         29.9911            16.3709  \n",
       "2           22.5882        117.2113            27.5730  \n",
       "3          -14.8400         36.5107            13.2583  \n",
       "4           -5.7997         11.6218             3.2307  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Descriptive Statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>particle_id</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>288.8194</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>250.7500</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>750.2500</td>\n",
       "      <td>1,000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>4.9535</td>\n",
       "      <td>2.8922</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>2.4361</td>\n",
       "      <td>5.0184</td>\n",
       "      <td>7.4688</td>\n",
       "      <td>9.9972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_velocity_x</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>2.9219</td>\n",
       "      <td>-4.9678</td>\n",
       "      <td>-2.5893</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>2.6047</td>\n",
       "      <td>4.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_velocity_y</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>2.9067</td>\n",
       "      <td>-4.9999</td>\n",
       "      <td>-2.3865</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>2.5910</td>\n",
       "      <td>4.9782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_position_x</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.1925</td>\n",
       "      <td>5.7298</td>\n",
       "      <td>-9.9869</td>\n",
       "      <td>-5.1620</td>\n",
       "      <td>-0.3144</td>\n",
       "      <td>4.7508</td>\n",
       "      <td>9.9912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_position_y</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.1179</td>\n",
       "      <td>5.7362</td>\n",
       "      <td>-9.9994</td>\n",
       "      <td>-5.1005</td>\n",
       "      <td>-0.1080</td>\n",
       "      <td>4.7999</td>\n",
       "      <td>9.9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charge</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.0080</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magnetic_field_strength</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>1.0462</td>\n",
       "      <td>0.5518</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>1.0473</td>\n",
       "      <td>1.5370</td>\n",
       "      <td>1.9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simulation_time</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>5.3997</td>\n",
       "      <td>2.5677</td>\n",
       "      <td>1.0022</td>\n",
       "      <td>3.1719</td>\n",
       "      <td>5.3375</td>\n",
       "      <td>7.5665</td>\n",
       "      <td>9.9929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_velocity_x</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>2.9209</td>\n",
       "      <td>-7.0916</td>\n",
       "      <td>-2.2262</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>2.4793</td>\n",
       "      <td>6.9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_velocity_y</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>2.9143</td>\n",
       "      <td>-7.0037</td>\n",
       "      <td>-2.3110</td>\n",
       "      <td>-0.0523</td>\n",
       "      <td>2.3679</td>\n",
       "      <td>6.5705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_x</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.1503</td>\n",
       "      <td>15.7771</td>\n",
       "      <td>-55.4273</td>\n",
       "      <td>-9.1107</td>\n",
       "      <td>0.6150</td>\n",
       "      <td>9.4239</td>\n",
       "      <td>49.6116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_y</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>-0.0439</td>\n",
       "      <td>16.4600</td>\n",
       "      <td>-60.2677</td>\n",
       "      <td>-9.3707</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>9.2660</td>\n",
       "      <td>64.4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kinetic_energy</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>41.9212</td>\n",
       "      <td>38.0360</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>11.9108</td>\n",
       "      <td>30.9505</td>\n",
       "      <td>63.2005</td>\n",
       "      <td>192.5211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trajectory_length</th>\n",
       "      <td>1,000.0000</td>\n",
       "      <td>17.5768</td>\n",
       "      <td>12.1140</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>7.7603</td>\n",
       "      <td>15.5059</td>\n",
       "      <td>25.2653</td>\n",
       "      <td>58.6960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             count     mean      std      min      25%  \\\n",
       "particle_id             1,000.0000 500.5000 288.8194   1.0000 250.7500   \n",
       "mass                    1,000.0000   4.9535   2.8922   0.1459   2.4361   \n",
       "initial_velocity_x      1,000.0000   0.0702   2.9219  -4.9678  -2.5893   \n",
       "initial_velocity_y      1,000.0000   0.0241   2.9067  -4.9999  -2.3865   \n",
       "initial_position_x      1,000.0000  -0.1925   5.7298  -9.9869  -5.1620   \n",
       "initial_position_y      1,000.0000  -0.1179   5.7362  -9.9994  -5.1005   \n",
       "charge                  1,000.0000  -0.0080   0.8091  -1.0000  -1.0000   \n",
       "magnetic_field_strength 1,000.0000   1.0462   0.5518   0.1074   0.5624   \n",
       "simulation_time         1,000.0000   5.3997   2.5677   1.0022   3.1719   \n",
       "final_velocity_x        1,000.0000   0.1078   2.9209  -7.0916  -2.2262   \n",
       "final_velocity_y        1,000.0000   0.0166   2.9143  -7.0037  -2.3110   \n",
       "final_position_x        1,000.0000  -0.1503  15.7771 -55.4273  -9.1107   \n",
       "final_position_y        1,000.0000  -0.0439  16.4600 -60.2677  -9.3707   \n",
       "kinetic_energy          1,000.0000  41.9212  38.0360   0.0075  11.9108   \n",
       "trajectory_length       1,000.0000  17.5768  12.1140   0.0513   7.7603   \n",
       "\n",
       "                             50%      75%        max  \n",
       "particle_id             500.5000 750.2500 1,000.0000  \n",
       "mass                      5.0184   7.4688     9.9972  \n",
       "initial_velocity_x        0.1873   2.6047     4.9941  \n",
       "initial_velocity_y        0.0061   2.5910     4.9782  \n",
       "initial_position_x       -0.3144   4.7508     9.9912  \n",
       "initial_position_y       -0.1080   4.7999     9.9550  \n",
       "charge                    0.0000   1.0000     1.0000  \n",
       "magnetic_field_strength   1.0473   1.5370     1.9990  \n",
       "simulation_time           5.3375   7.5665     9.9929  \n",
       "final_velocity_x          0.0838   2.4793     6.9006  \n",
       "final_velocity_y         -0.0523   2.3679     6.5705  \n",
       "final_position_x          0.6150   9.4239    49.6116  \n",
       "final_position_y          0.3257   9.2660    64.4172  \n",
       "kinetic_energy           30.9505  63.2005   192.5211  \n",
       "trajectory_length        15.5059  25.2653    58.6960  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particle_df = load_particle_data(paths)\n",
    "\n",
    "scaler_X, scaler_y = load_scalers(paths)\n",
    "\n",
    "display(Markdown(\"### Particle Data Snapshot\"))\n",
    "\n",
    "display(Markdown(f\"Dataset shape: **{particle_df.shape[0]}** rows × **{particle_df.shape[1]}** columns\"))\n",
    "\n",
    "display(particle_df.head())\n",
    "\n",
    "display(Markdown(\"#### Descriptive Statistics\"))\n",
    "\n",
    "display(particle_df.describe(include=\"all\").transpose())\n",
    "\n",
    "missing_counts = particle_df.isna().sum()\n",
    "\n",
    "if missing_counts.any():\n",
    "    display(Markdown(\"#### Missing Value Audit\"))\n",
    "\n",
    "    display(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c814b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Available Weight Checkpoints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>modified</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>size_readable</th>\n",
       "      <th>is_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>model_weights_epoch_0.weights.h5</td>\n",
       "      <td>model_weights_epoch_0.weights.h5</td>\n",
       "      <td>2025-09-30 06:37:07.229432821</td>\n",
       "      <td>68880</td>\n",
       "      <td>67.3 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>model_weights_epoch_10.weights.h5</td>\n",
       "      <td>model_weights_epoch_10.weights.h5</td>\n",
       "      <td>2025-09-30 06:37:17.715074539</td>\n",
       "      <td>68880</td>\n",
       "      <td>67.3 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>model_weights_epoch_20.weights.h5</td>\n",
       "      <td>model_weights_epoch_20.weights.h5</td>\n",
       "      <td>2025-09-30 06:37:28.059985638</td>\n",
       "      <td>68880</td>\n",
       "      <td>67.3 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>model_weights_epoch_30.weights.h5</td>\n",
       "      <td>model_weights_epoch_30.weights.h5</td>\n",
       "      <td>2025-09-30 06:37:38.392863989</td>\n",
       "      <td>68880</td>\n",
       "      <td>67.3 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>model_weights_epoch_40.weights.h5</td>\n",
       "      <td>model_weights_epoch_40.weights.h5</td>\n",
       "      <td>2025-09-30 06:37:48.750868082</td>\n",
       "      <td>68880</td>\n",
       "      <td>67.3 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>model_weights_epoch_50.weights.h5</td>\n",
       "      <td>model_weights_epoch_50.weights.h5</td>\n",
       "      <td>2025-09-30 06:37:59.056569815</td>\n",
       "      <td>68880</td>\n",
       "      <td>67.3 KB</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>model_weights_epoch_59.weights.h5</td>\n",
       "      <td>model_weights_epoch_59.weights.h5</td>\n",
       "      <td>2025-09-30 06:38:08.402722359</td>\n",
       "      <td>68880</td>\n",
       "      <td>67.3 KB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch                               name  \\\n",
       "0      0   model_weights_epoch_0.weights.h5   \n",
       "1     10  model_weights_epoch_10.weights.h5   \n",
       "2     20  model_weights_epoch_20.weights.h5   \n",
       "3     30  model_weights_epoch_30.weights.h5   \n",
       "4     40  model_weights_epoch_40.weights.h5   \n",
       "5     50  model_weights_epoch_50.weights.h5   \n",
       "6     59  model_weights_epoch_59.weights.h5   \n",
       "\n",
       "                                path                      modified  \\\n",
       "0   model_weights_epoch_0.weights.h5 2025-09-30 06:37:07.229432821   \n",
       "1  model_weights_epoch_10.weights.h5 2025-09-30 06:37:17.715074539   \n",
       "2  model_weights_epoch_20.weights.h5 2025-09-30 06:37:28.059985638   \n",
       "3  model_weights_epoch_30.weights.h5 2025-09-30 06:37:38.392863989   \n",
       "4  model_weights_epoch_40.weights.h5 2025-09-30 06:37:48.750868082   \n",
       "5  model_weights_epoch_50.weights.h5 2025-09-30 06:37:59.056569815   \n",
       "6  model_weights_epoch_59.weights.h5 2025-09-30 06:38:08.402722359   \n",
       "\n",
       "   size_bytes size_readable  is_latest  \n",
       "0       68880       67.3 KB      False  \n",
       "1       68880       67.3 KB      False  \n",
       "2       68880       67.3 KB      False  \n",
       "3       68880       67.3 KB      False  \n",
       "4       68880       67.3 KB      False  \n",
       "5       68880       67.3 KB      False  \n",
       "6       68880       67.3 KB       True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Loaded checkpoint: **epoch 59** from `model_weights_epoch_59.weights.h5`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "epoch                                             59\n",
       "weights_path       model_weights_epoch_59.weights.h5\n",
       "size_bytes                                     68880\n",
       "size_readable                                67.3 KB\n",
       "modified               2025-09-30 06:38:08.402722359\n",
       "parameter_count                                 3286\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_index = list_checkpoint_weights(paths)\n",
    "\n",
    "display(Markdown(\"### Available Weight Checkpoints\"))\n",
    "\n",
    "if checkpoint_index.empty:\n",
    "    display(Markdown(\"No checkpoints found. Run training to generate weight artifacts.\"))\n",
    "else:\n",
    "    display(checkpoint_index)\n",
    "\n",
    "model, checkpoint_meta = load_model_checkpoint(paths, model_config, training_config, checkpoint_index)\n",
    "\n",
    "if checkpoint_meta is not None:\n",
    "    display(Markdown(f\"Loaded checkpoint: **epoch {checkpoint_meta['epoch']}** from `{checkpoint_meta['weights_path']}`\"))\n",
    "\n",
    "    display(pd.Series(checkpoint_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e2cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Residual Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "samples                256.0000\n",
       "mae                      3.3062\n",
       "rmse                     5.4683\n",
       "residual_norm_median     9.8454\n",
       "residual_norm_p95       25.3330\n",
       "Name: residual_metrics, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Per-Target Residual Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>final_velocity_x</th>\n",
       "      <td>1.0718</td>\n",
       "      <td>1.7269</td>\n",
       "      <td>0.2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_velocity_y</th>\n",
       "      <td>1.0433</td>\n",
       "      <td>1.5471</td>\n",
       "      <td>0.3186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_x</th>\n",
       "      <td>3.4550</td>\n",
       "      <td>5.1210</td>\n",
       "      <td>-1.1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_position_y</th>\n",
       "      <td>3.3631</td>\n",
       "      <td>4.5617</td>\n",
       "      <td>0.3023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kinetic_energy</th>\n",
       "      <td>7.8591</td>\n",
       "      <td>10.3532</td>\n",
       "      <td>1.0427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trajectory_length</th>\n",
       "      <td>3.0451</td>\n",
       "      <td>4.4517</td>\n",
       "      <td>-0.8533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mae    rmse    bias\n",
       "final_velocity_x  1.0718  1.7269  0.2652\n",
       "final_velocity_y  1.0433  1.5471  0.3186\n",
       "final_position_x  3.4550  5.1210 -1.1989\n",
       "final_position_y  3.3631  4.5617  0.3023\n",
       "kinetic_energy    7.8591 10.3532  1.0427\n",
       "trajectory_length 3.0451  4.4517 -0.8533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Residual Sample"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>particle_id</th>\n",
       "      <th>actual_final_velocity_x</th>\n",
       "      <th>pred_final_velocity_x</th>\n",
       "      <th>residual_final_velocity_x</th>\n",
       "      <th>actual_final_velocity_y</th>\n",
       "      <th>pred_final_velocity_y</th>\n",
       "      <th>residual_final_velocity_y</th>\n",
       "      <th>actual_final_position_x</th>\n",
       "      <th>pred_final_position_x</th>\n",
       "      <th>residual_final_position_x</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_final_position_y</th>\n",
       "      <th>residual_final_position_y</th>\n",
       "      <th>actual_kinetic_energy</th>\n",
       "      <th>pred_kinetic_energy</th>\n",
       "      <th>residual_kinetic_energy</th>\n",
       "      <th>actual_trajectory_length</th>\n",
       "      <th>pred_trajectory_length</th>\n",
       "      <th>residual_trajectory_length</th>\n",
       "      <th>residual_norm</th>\n",
       "      <th>residual_norm_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.9367</td>\n",
       "      <td>3.7807</td>\n",
       "      <td>0.8441</td>\n",
       "      <td>4.8254</td>\n",
       "      <td>5.5746</td>\n",
       "      <td>0.7492</td>\n",
       "      <td>16.4110</td>\n",
       "      <td>13.6179</td>\n",
       "      <td>-2.7931</td>\n",
       "      <td>...</td>\n",
       "      <td>22.5701</td>\n",
       "      <td>-0.0181</td>\n",
       "      <td>117.2113</td>\n",
       "      <td>114.4474</td>\n",
       "      <td>-2.7639</td>\n",
       "      <td>27.5730</td>\n",
       "      <td>26.4079</td>\n",
       "      <td>-1.1650</td>\n",
       "      <td>4.2511</td>\n",
       "      <td>-1.0267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.4379</td>\n",
       "      <td>1.9726</td>\n",
       "      <td>-0.4653</td>\n",
       "      <td>-2.4846</td>\n",
       "      <td>-2.4309</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>13.1317</td>\n",
       "      <td>11.2817</td>\n",
       "      <td>-1.8500</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.2750</td>\n",
       "      <td>2.5650</td>\n",
       "      <td>36.5107</td>\n",
       "      <td>36.0641</td>\n",
       "      <td>-0.4466</td>\n",
       "      <td>13.2583</td>\n",
       "      <td>12.6361</td>\n",
       "      <td>-0.6222</td>\n",
       "      <td>3.2876</td>\n",
       "      <td>-1.1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5.0235</td>\n",
       "      <td>-1.2838</td>\n",
       "      <td>-6.3073</td>\n",
       "      <td>-2.0279</td>\n",
       "      <td>3.1259</td>\n",
       "      <td>5.1539</td>\n",
       "      <td>2.4081</td>\n",
       "      <td>3.4200</td>\n",
       "      <td>1.0119</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.7919</td>\n",
       "      <td>4.5102</td>\n",
       "      <td>4.4577</td>\n",
       "      <td>10.0779</td>\n",
       "      <td>5.6202</td>\n",
       "      <td>1.4310</td>\n",
       "      <td>4.6644</td>\n",
       "      <td>3.2335</td>\n",
       "      <td>11.3908</td>\n",
       "      <td>-0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>4.4347</td>\n",
       "      <td>-0.7410</td>\n",
       "      <td>-5.1757</td>\n",
       "      <td>-4.7552</td>\n",
       "      <td>-2.7330</td>\n",
       "      <td>2.0222</td>\n",
       "      <td>38.0604</td>\n",
       "      <td>19.8920</td>\n",
       "      <td>-18.1684</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.9702</td>\n",
       "      <td>-1.2170</td>\n",
       "      <td>78.7841</td>\n",
       "      <td>86.2364</td>\n",
       "      <td>7.4523</td>\n",
       "      <td>57.0734</td>\n",
       "      <td>38.5759</td>\n",
       "      <td>-18.4975</td>\n",
       "      <td>27.5707</td>\n",
       "      <td>2.3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.2407</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>-2.1335</td>\n",
       "      <td>-2.8738</td>\n",
       "      <td>-0.7403</td>\n",
       "      <td>-4.4700</td>\n",
       "      <td>-5.7005</td>\n",
       "      <td>-1.2305</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.6113</td>\n",
       "      <td>-2.9359</td>\n",
       "      <td>18.1469</td>\n",
       "      <td>40.4567</td>\n",
       "      <td>22.3099</td>\n",
       "      <td>18.2666</td>\n",
       "      <td>17.9767</td>\n",
       "      <td>-0.2899</td>\n",
       "      <td>22.5501</td>\n",
       "      <td>1.5915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    particle_id  actual_final_velocity_x  pred_final_velocity_x  \\\n",
       "2             3                   2.9367                 3.7807   \n",
       "3             4                   2.4379                 1.9726   \n",
       "10           11                   5.0235                -1.2838   \n",
       "23           24                   4.4347                -0.7410   \n",
       "25           26                  -0.2407                -0.1280   \n",
       "\n",
       "    residual_final_velocity_x  actual_final_velocity_y  pred_final_velocity_y  \\\n",
       "2                      0.8441                   4.8254                 5.5746   \n",
       "3                     -0.4653                  -2.4846                -2.4309   \n",
       "10                    -6.3073                  -2.0279                 3.1259   \n",
       "23                    -5.1757                  -4.7552                -2.7330   \n",
       "25                     0.1128                  -2.1335                -2.8738   \n",
       "\n",
       "    residual_final_velocity_y  actual_final_position_x  pred_final_position_x  \\\n",
       "2                      0.7492                  16.4110                13.6179   \n",
       "3                      0.0537                  13.1317                11.2817   \n",
       "10                     5.1539                   2.4081                 3.4200   \n",
       "23                     2.0222                  38.0604                19.8920   \n",
       "25                    -0.7403                  -4.4700                -5.7005   \n",
       "\n",
       "    residual_final_position_x  ...  pred_final_position_y  \\\n",
       "2                     -2.7931  ...                22.5701   \n",
       "3                     -1.8500  ...               -12.2750   \n",
       "10                     1.0119  ...                -4.7919   \n",
       "23                   -18.1684  ...               -33.9702   \n",
       "25                    -1.2305  ...               -14.6113   \n",
       "\n",
       "    residual_final_position_y  actual_kinetic_energy  pred_kinetic_energy  \\\n",
       "2                     -0.0181               117.2113             114.4474   \n",
       "3                      2.5650                36.5107              36.0641   \n",
       "10                     4.5102                 4.4577              10.0779   \n",
       "23                    -1.2170                78.7841              86.2364   \n",
       "25                    -2.9359                18.1469              40.4567   \n",
       "\n",
       "    residual_kinetic_energy  actual_trajectory_length  pred_trajectory_length  \\\n",
       "2                   -2.7639                   27.5730                 26.4079   \n",
       "3                   -0.4466                   13.2583                 12.6361   \n",
       "10                   5.6202                    1.4310                  4.6644   \n",
       "23                   7.4523                   57.0734                 38.5759   \n",
       "25                  22.3099                   18.2666                 17.9767   \n",
       "\n",
       "    residual_trajectory_length  residual_norm  residual_norm_z  \n",
       "2                      -1.1650         4.2511          -1.0267  \n",
       "3                      -0.6222         3.2876          -1.1645  \n",
       "10                      3.2335        11.3908          -0.0051  \n",
       "23                    -18.4975        27.5707           2.3099  \n",
       "25                     -0.2899        22.5501           1.5915  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals_df, residual_metrics = compute_predictions(model, scaler_X, scaler_y, particle_df)\n",
    "\n",
    "if residual_metrics:\n",
    "    display(Markdown(\"### Residual Metrics\"))\n",
    "\n",
    "    overall_metrics = {key: value for key, value in residual_metrics.items() if key != \"targets\"}\n",
    "\n",
    "    display(pd.Series(overall_metrics, name=\"residual_metrics\"))\n",
    "\n",
    "    target_metrics = pd.DataFrame(residual_metrics[\"targets\"]).transpose()\n",
    "\n",
    "    display(Markdown(\"#### Per-Target Residual Summary\"))\n",
    "\n",
    "    display(target_metrics)\n",
    "\n",
    "if not residuals_df.empty:\n",
    "    display(Markdown(\"### Residual Sample\"))\n",
    "\n",
    "    display(residuals_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c36e227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Saved loss curves to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\loss_curves.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved train/val gap chart to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\train_val_gap.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved learning-rate diagnostics to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\learning_rate_vs_r2.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved residual histogram to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\residual_norm_hist.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved residual distribution boxplot to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\residual_distribution_by_target.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Saved correlation heatmap to `c:\\Users\\jesse\\OneDrive\\Documents\\Programming Projects\\Neural Network Lab - Python\\neural-network-lab-python\\training_output\\analysis\\figures\\metric_correlation_heatmap.png`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figures_dir = paths[\"figures_dir\"]\n",
    "\n",
    "# Loss trend\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"train_loss\", ax=ax, label=\"Train Loss\")\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"val_loss\", ax=ax, label=\"Validation Loss\")\n",
    "val_std = results_df[\"val_loss\"].rolling(5, min_periods=1).std()\n",
    "ax.fill_between(results_df[\"epoch\"], results_df[\"val_loss\"] - val_std, results_df[\"val_loss\"] + val_std, color=\"tab:blue\", alpha=0.1)\n",
    "ax.set_title(\"Training vs Validation Loss\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "fig.tight_layout()\n",
    "loss_curve_path = figures_dir / \"loss_curves.png\"\n",
    "fig.savefig(loss_curve_path, dpi=200)\n",
    "plt.close(fig)\n",
    "display(Markdown(f\"Saved loss curves to `{loss_curve_path}`\"))\n",
    "\n",
    "# Train vs validation gap\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"train_val_gap\", ax=ax, color=\"tab:red\")\n",
    "ax.axhline(0, linestyle=\"--\", color=\"grey\", linewidth=1)\n",
    "ax.set_title(\"Train vs Validation Gap\")\n",
    "ax.set_ylabel(\"Val - Train Loss\")\n",
    "fig.tight_layout()\n",
    "gap_plot_path = figures_dir / \"train_val_gap.png\"\n",
    "fig.savefig(gap_plot_path, dpi=200)\n",
    "plt.close(fig)\n",
    "display(Markdown(f\"Saved train/val gap chart to `{gap_plot_path}`\"))\n",
    "\n",
    "# Learning rate vs final loss metrics\n",
    "if not config_history.empty:\n",
    "    lr_df = config_history.copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.scatterplot(data=lr_df, x=\"learning_rate\", y=\"final_r2\", size=\"total_training_time\", hue=\"final_r2\", palette=\"viridis\", ax=ax)\n",
    "    ax.set_title(\"Learning Rate vs Final R²\")\n",
    "    ax.set_xlabel(\"Learning Rate\")\n",
    "    ax.set_ylabel(\"Final R²\")\n",
    "    fig.tight_layout()\n",
    "    lr_plot_path = figures_dir / \"learning_rate_vs_r2.png\"\n",
    "    fig.savefig(lr_plot_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    display(Markdown(f\"Saved learning-rate diagnostics to `{lr_plot_path}`\"))\n",
    "\n",
    "# Residual histogram\n",
    "if not residuals_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.histplot(residuals_df[\"residual_norm\"], bins=30, ax=ax, kde=True, color=\"tab:orange\")\n",
    "    ax.set_title(\"Residual Norm Distribution\")\n",
    "    ax.set_xlabel(\"Residual Norm\")\n",
    "    fig.tight_layout()\n",
    "    residual_hist_path = figures_dir / \"residual_norm_hist.png\"\n",
    "    fig.savefig(residual_hist_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    display(Markdown(f\"Saved residual histogram to `{residual_hist_path}`\"))\n",
    "\n",
    "    residual_columns = [col for col in residuals_df.columns if col.startswith(\"residual_\") and any(col.endswith(target) for target in OUTPUT_TARGETS)]\n",
    "\n",
    "    if residual_columns:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        melted = residuals_df[residual_columns].melt(var_name=\"target\", value_name=\"residual\")\n",
    "        sns.boxplot(data=melted, x=\"target\", y=\"residual\", ax=ax)\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "        ax.set_title(\"Residual Distribution by Target\")\n",
    "        fig.tight_layout()\n",
    "        residual_box_path = figures_dir / \"residual_distribution_by_target.png\"\n",
    "        fig.savefig(residual_box_path, dpi=200)\n",
    "        plt.close(fig)\n",
    "        display(Markdown(f\"Saved residual distribution boxplot to `{residual_box_path}`\"))\n",
    "\n",
    "# Correlation heatmap\n",
    "heatmap_features = [\"train_loss\", \"val_loss\", \"train_mae\", \"val_mae\", \"r2_score\", \"epoch_time\", \"train_val_gap\", \"memory_headroom_mb\"]\n",
    "usable_cols = [col for col in heatmap_features if col in merged_metrics.columns]\n",
    "\n",
    "if usable_cols:\n",
    "    corr_matrix = merged_metrics[usable_cols].corr()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
    "    ax.set_title(\"Metric Correlation Heatmap\")\n",
    "    fig.tight_layout()\n",
    "    heatmap_path = figures_dir / \"metric_correlation_heatmap.png\"\n",
    "    fig.savefig(heatmap_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "    display(Markdown(f\"Saved correlation heatmap to `{heatmap_path}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db242ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Recommended Hyperparameter Sweeps"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter</th>\n",
       "      <th>proposed_values</th>\n",
       "      <th>rationale</th>\n",
       "      <th>constraints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>[0.0025, 0.004, 0.006]</td>\n",
       "      <td>Validation loss plateaued across the last epoc...</td>\n",
       "      <td>Keep BinaryWeightConstraintMax(max_binary_digi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_size</td>\n",
       "      <td>[16, 24, 32]</td>\n",
       "      <td>Epoch time and memory logs show headroom; larg...</td>\n",
       "      <td>Validate GPU memory against peak usage before ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>epochs</td>\n",
       "      <td>[70, 80]</td>\n",
       "      <td>Best epoch occurs near training ceiling; exten...</td>\n",
       "      <td>Monitor for overfitting; stop early if val los...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       parameter         proposed_values  \\\n",
       "0  learning_rate  [0.0025, 0.004, 0.006]   \n",
       "1     batch_size            [16, 24, 32]   \n",
       "2         epochs                [70, 80]   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  Validation loss plateaued across the last epoc...   \n",
       "1  Epoch time and memory logs show headroom; larg...   \n",
       "2  Best epoch occurs near training ceiling; exten...   \n",
       "\n",
       "                                         constraints  \n",
       "0  Keep BinaryWeightConstraintMax(max_binary_digi...  \n",
       "1  Validate GPU memory against peak usage before ...  \n",
       "2  Monitor for overfitting; stop early if val los...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommendations_df = suggest_hyperparameters(model_config, training_config, config_history, results_df)\n",
    "\n",
    "if not recommendations_df.empty:\n",
    "    display(Markdown(\"### Recommended Hyperparameter Sweeps\"))\n",
    "\n",
    "    display(recommendations_df)\n",
    "\n",
    "else:\n",
    "    display(Markdown(\"No immediate hyperparameter adjustments detected beyond current configuration.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48cb52a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Insight Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Best validation loss 0.1598 at epoch 30."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Validation plateau range over last window: 0.0085."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Train/val gap at final epoch: 0.0435."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Cumulative training time logged: 62.3 seconds."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Mean absolute residual across sampled predictions: 3.3062."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- 95th percentile residual norm: 25.3330."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- Hyperparameter sweep targets: learning_rate, batch_size, epochs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "insight_items: List[str] = []\n",
    "\n",
    "if not results_df.empty:\n",
    "    final_row = results_df.iloc[-1]\n",
    "\n",
    "    best_row = results_df.loc[results_df[\"val_loss\"].idxmin()]\n",
    "\n",
    "    insight_items.append(f\"Best validation loss {best_row['val_loss']:.4f} at epoch {int(best_row['epoch'])}.\")\n",
    "\n",
    "    insight_items.append(f\"Validation plateau range over last window: {(results_df.tail(5)['val_loss'].max() - results_df.tail(5)['val_loss'].min()):.4f}.\")\n",
    "\n",
    "    insight_items.append(f\"Train/val gap at final epoch: {final_row['train_val_gap']:.4f}.\")\n",
    "\n",
    "    insight_items.append(f\"Cumulative training time logged: {results_df['epoch_time'].sum():.1f} seconds.\")\n",
    "\n",
    "if residual_metrics:\n",
    "    insight_items.append(f\"Mean absolute residual across sampled predictions: {residual_metrics['mae']:.4f}.\")\n",
    "\n",
    "    insight_items.append(f\"95th percentile residual norm: {residual_metrics['residual_norm_p95']:.4f}.\")\n",
    "\n",
    "if not recommendations_df.empty:\n",
    "    suggested = \", \".join(recommendations_df[\"parameter\"].unique())\n",
    "\n",
    "    insight_items.append(f\"Hyperparameter sweep targets: {suggested}.\")\n",
    "\n",
    "missing_artifacts = artifact_status.loc[~artifact_status[\"exists\"] & artifact_status[\"critical\"]]\n",
    "\n",
    "if not missing_artifacts.empty:\n",
    "    missing_list = \", \".join(missing_artifacts[\"artifact\"].tolist())\n",
    "\n",
    "    insight_items.append(f\"Critical artifacts missing: {missing_list}.\")\n",
    "\n",
    "if not insight_items:\n",
    "    insight_items.append(\"Insufficient data to derive insights.\")\n",
    "\n",
    "display(Markdown(\"### Insight Summary\"))\n",
    "\n",
    "for item in insight_items:\n",
    "    display(Markdown(f\"- {item}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c46cd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Validation Checklist"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "critical_artifacts_present    True\n",
       "config_history_entries           1\n",
       "loss_records                  2400\n",
       "results_records                 60\n",
       "residual_samples               256\n",
       "recommendations                  3\n",
       "figures_exported                 6\n",
       "latest_checkpoint_epoch         59\n",
       "Name: notebook_validation, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_notebook_smoke_test() -> Dict[str, Any]:\n",
    "    \"\"\"Validate that core notebook stages complete without exceptions.\"\"\"\n",
    "    status = {\n",
    "        \"critical_artifacts_present\": bool(artifact_status.loc[artifact_status[\"critical\"] & ~artifact_status[\"exists\"]].empty),\n",
    "        \"config_history_entries\": int(len(config_history)),\n",
    "        \"loss_records\": int(len(loss_records)),\n",
    "        \"results_records\": int(len(results_df)),\n",
    "        \"residual_samples\": int(len(residuals_df)),\n",
    "        \"recommendations\": int(len(recommendations_df)),\n",
    "        \"figures_exported\": len(list(paths[\"figures_dir\"].glob(\"*.png\"))),\n",
    "        \"latest_checkpoint_epoch\": int(checkpoint_meta[\"epoch\"]) if checkpoint_meta else None\n",
    "    }\n",
    "\n",
    "    return status\n",
    "\n",
    "\n",
    "smoke_test_status = run_notebook_smoke_test()\n",
    "\n",
    "display(Markdown(\"### Validation Checklist\"))\n",
    "\n",
    "display(pd.Series(smoke_test_status, name=\"notebook_validation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5177634",
   "metadata": {},
   "source": [
    "## Actionable Next Steps\n",
    "\n",
    "- Re-run the training pipeline after trialing the proposed learning-rate, dropout, and batch-size combinations; capture new config snapshots for comparison.\n",
    "- Promote saved figures under `training_output/analysis/figures/` into experiment reports or dashboards.\n",
    "- Extend this notebook with automated sweeps (GridSearch or Bayesian optimization) once additional configuration diversity is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa43bb3",
   "metadata": {},
   "source": [
    "### Reuse Tips\n",
    "\n",
    "- Parameterize `sample_size` within `compute_predictions` to scale residual analysis for larger datasets.\n",
    "- Import this notebook’s helper functions via `%run experiment_analysis_framework.ipynb` inside future analysis notebooks for rapid setup.\n",
    "- Store additional diagnostics (e.g., feature importance, SHAP values) within the `analysis` directory for cross-experiment benchmarking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
