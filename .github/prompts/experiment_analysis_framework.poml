<poml syntax="markdown">
	<system-msg>Follow reproducible research practices, keep outputs deterministic, and avoid deleting existing analysis scaffolding.</system-msg>

	<role>Act as the lead machine learning engineer responsible for auditing completed training runs and translating artifacts into actionable guidance.</role>

	<task>
		Complete and polish the existing Jupyter notebook neural-network-lab-python/experiment_analysis_framework.ipynb so it becomes a reusable experiment analysis framework for the neural-network-lab-python project.
		Incorporate artifact validation, configuration review, metric analytics, residual diagnostics, visualization exports, and written takeaways.
	</task>

	<stepwise-instructions>
		<list>
			<item>Open neural-network-lab-python/experiment_analysis_framework.ipynb and work inside that notebook only.</item>
			<item>Resolve project-relative paths (configs, training_output, scalers, checkpoints) without hard-coding absolute directories.</item>
			<item>Verify required artifacts exist; surface a dataframe detailing presence, size, and paths.</item>
			<item>Load model and training configs, historical config snapshots, and training_output logs; enrich them with helpful derived metrics.</item>
			<item>Ingest particle_data.csv plus cached scalers; regenerate scalers via data_processing.complete_data_pipeline when missing.</item>
			<item>List available weight checkpoints, rebuild the latest AdvancedNeuralNetwork instance with matching configs, and load weights.</item>
			<item>Generate batched predictions, compute residual analytics, and summarize MAE/RMSE plus residual samples.</item>
			<item>Create diagnostic visuals (loss curves, learning-rate vs performance scatter, residual histogram, metric correlation heatmap) and persist them under training_output/analysis/figures.</item>
			<item>Produce hyperparameter sweep recommendations driven by observed trends (plateaus, train/val gaps, runtime headroom).</item>
			<item>Capture a concise insight summary and a validation checklist so future runs can confirm notebook health quickly.</item>
		</list>
	</stepwise-instructions>

	<section>
		<h>Key artifacts</h>
		<cp caption="Folders">
			<list>
				<item>neural-network-lab-python/ml_config (model_config.json, training_config.json)</item>
				<item>neural-network-lab-python/training_output (loss_history.csv, training_results.csv, configuration_log.csv, training_config_*.json)</item>
				<item>neural-network-lab-python/training_output/analysis/figures (export plots here)</item>
				<item>neural-network-lab-python/model_weights_epoch_*.weights.h5 (checkpoint sweep)</item>
			</list>
		</cp>
		<cp caption="Utilities">
			<list>
				<item>advanced_neural_network.AdvancedNeuralNetwork</item>
				<item>data_processing.complete_data_pipeline, data_processing.load_and_validate_data</item>
				<item>ml_utils.compute_loss_weights (imported if needed for derived metrics)</item>
				<item>weight_constraints.BinaryWeightConstraintMax and related helpers for contextual notes</item>
			</list>
		</cp>
	</section>

	<hint>Prefer vectorized pandas/numpy operations, reuse helper functions already present in neural-network-lab-python, and document non-obvious logic directly in notebook cells.</hint>

	<output-format>Update notebook cells in-place so the executed notebook renders tables, charts, and markdown guidance; ensure saved figures land in training_output/analysis/figures; finish with a markdown summary of insights and recommended next steps.</output-format>
</poml>
